---
title: "factorial_analysis"
format: html
editor: visual
---

## Introduction

PCA (Principal Component Analysis) is a dimensionality reduction technique used in data analysis and machine learning. It helps you to reduce the number of features in a dataset while keeping the most important information (variance).

The main goals are to reduce the number of variables, to visualize high-dimensional data in 2D or 3D, to detect patterns, clusters and outliers, remove noise and redundant information.

For example, if you get a data set with 10 correlated variables, PCA can reduce it to 2 or 3 components that explains 90% of the variance and makes it easier to visualize.

To realize a PCA, you need first to standardize the data (center and scale variables), to show how the variables vary together with a covariance matrix, to calculate eigenvalues and eigenvectors, to sort the components by decreasing values (the first components explain the most variance) and to project the data on the new axes.
