[
  {
    "objectID": "EDO_estimation.html",
    "href": "EDO_estimation.html",
    "title": "EDO Estimation of parameters : the logistic growth",
    "section": "",
    "text": "This document aims to be a roadmap to estimate the parameters of a logistic growth from a population: from the data simulation to the estimation of the parameters. The following document will thus be organized in two parts : the data simulation and the estimation of the parameters."
  },
  {
    "objectID": "EDO_estimation.html#general-theory",
    "href": "EDO_estimation.html#general-theory",
    "title": "EDO Estimation of parameters : the logistic growth",
    "section": "General theory",
    "text": "General theory\n\nLeast squares\n\nDefinition\nOne of the most used methods to assess the quality of a model is the least squares method, also known as mean square error method (MSE). It quantifies how the simulated data match with the real ones by measuring the gap between the simulated and the real points (Cornillon and Matzner-L√∏ber (2007)). This gap is estimated with the following formula:\n\\[\n\\text{MSE} = \\sum_{i}^{}(Y_{i}-\\hat{Y})^{2}\\\\\\hat{Y} = \\text{mean value of the data set}\\\\Y_{i} = \\text{value of the individual i}\n\\]\nA good model minimizes the MSE. Graphically, this means that the vertical distance between each simulated point and its corresponding observed value is as small as possible.\n\n\nSpecific aspects\nThe MSE is one of the most common method to assess the quality of a model. However, it has some limitations that may call its use into question. First, as it compares the simulated data and the observed ones point by point, the presence of outliers can strongly deviate the MSE estimation. Moreover, this estimation method assumes a linear relation between the variables. Therefore, if the relation between the variables is not linear, the MSE may not reflect the true performance of the model.\n\n\n\nMaximum likelihood\n\nDefinition\nLikelihood corresponds to the probability of observing the data, knowing the parameters \\(\\theta\\) (Fisher (1922)). The likelihood function is as follows : \\[\nL(\\theta) = \\prod_{i=1}^n f(x_i , \\theta)\n\\] In this function, \\(x_i\\) corresponds to the observations and \\(f(x_i,\\theta)\\) corresponds to the probability density function of the random variable \\(X\\).\nThe maximum likelihood method consists in determining the estimated parameters \\(\\hat\\theta\\) that maximize the likelihood function: \\[\n\\hat\\theta = \\arg\\max_\\theta L(\\theta)\n\\] Maximizing \\(L(\\theta)\\) means finding the parameter values that make the data most plausible under the chosen model.\n\n\nSpecific aspects\nIf the errors of the data are independent and identically distributed, this method is equivalent to the least squares method :\n\\[\n\\hat{\\theta} = \\arg\\max_{\\theta} L(\\theta) = \\arg\\min_{\\theta} SCE(\\theta)\n\\] We prefer to work with the logarithm of the likelihood function \\(L(\\theta)\\), as it converts products into sums: \\[\nLL(\\theta) = ln(L(\\theta)) = \\sum_{i=1}^n lnf(x_i,\\theta)\n\\]"
  },
  {
    "objectID": "EDO_estimation.html#implementation-of-the-two-methods",
    "href": "EDO_estimation.html#implementation-of-the-two-methods",
    "title": "EDO Estimation of parameters : the logistic growth",
    "section": "Implementation of the two methods",
    "text": "Implementation of the two methods\nWe first need to redefine a function of the model we want to fit (without noise this time).\n\n\nCode\nlogistic &lt;- function(t, r, K, y0) {\n  K / (1 + ((K - y0) / y0) * exp(-r * t))\n}\n\n\n\nLeast squares\nWe need a function that compute the sum of the squared errors between the data and the model prediction y given a x.\n\n\nCode\n# NB : theta is a vector of parameters\nSSE &lt;- function(theta) {\n  r &lt;- theta[1]\n  K &lt;- theta[2]\n  y0 &lt;- theta[3]\n  mod_pred &lt;- sapply(time, logistic, r = r, K = K, y0 = y0)\n  return(sum((sim_data - mod_pred)**2))\n}\n\n\nWe now have to find a way to modify the parameters iteratively to find the best ones : the set of parameters \\(\\theta\\) that minimize the sum of squared errors. Thankfully, there are several functions implemented in R to do so. We‚Äôll use optim(), based on a gradient descent algorithm. We need to specify initial guess on the parameters to initialize the gradient descent algorithm. We‚Äôll take biologically meaningful parameters as initial guess.\n\n\nCode\nig_r &lt;- 1\nig_K &lt;- 75\nig_y0 &lt;- 2\nfitted_params_SSE &lt;- optim(c(ig_r, ig_K, ig_y0), SSE)$par\nprint(fitted_params_SSE)\n\n\n[1]   0.4142634 116.5507131  12.1070075\n\n\nFor practicality, or for some EDO models that are not explicitly solvable (i. e. we can‚Äôt find a unique solution to the Cauchy problem), we can locally and numerically solve in the same time we calculate the likelihood. This alternative is used in the next part. We use the function ode() from the package deSolve to do so.\n\n\nCode\nlibrary(deSolve)\n\n\n\n\nCode\nlogistic_ODE =function(t,N,parametre){\n  r=parametre[1]\n  K=parametre[2]\n  dNdt = r*(1-N/K)*N\n  list(c(dNdt))\n}\n\n\n\n\nMaximum likelihood\n\n\nCode\nMMV &lt;- function(theta){\n  r1 &lt;- theta[1]\n  K1 &lt;- theta[2]\n  N0 &lt;- theta[3]\n  sol = ode(y = N0, times = time, func = logistic_ODE, parms = c(r1, K1))\n  mod_pred &lt;- sol[, 2]\n  loglik = dnorm(sim_data, mean = mod_pred, sd = error, log = TRUE)\n  return(sum(loglik))\n}\n\n\n\n\nCode\nig_r &lt;- 0.1\nig_K &lt;- 100\nig_y0 &lt;- 1\nfitted_params_MMV &lt;- optim(c(ig_r, ig_K, ig_y0), MMV, control=list(fnscale=-1))$par\nprint(fitted_params_MMV)"
  },
  {
    "objectID": "EDO_estimation.html#data-visualization-simulated-dynamics-with-estimated-trends",
    "href": "EDO_estimation.html#data-visualization-simulated-dynamics-with-estimated-trends",
    "title": "EDO Estimation of parameters : the logistic growth",
    "section": "Data visualization : simulated dynamics with estimated trends",
    "text": "Data visualization : simulated dynamics with estimated trends\nAs we could expect on this kind of data, the estimated parameters are almost the same with the two methods, The two estimated trends we show on the following graph are even indistinguishable."
  },
  {
    "objectID": "instructions.html",
    "href": "instructions.html",
    "title": "Stats Reminder Project - Instructions",
    "section": "",
    "text": "Team project for groups of 3 students. Create examples demonstrating statistical/mathematical methods applied to ecological questions.\nRepository: https://github.com/MarieEtienne/stats-reminder\n\n\n\n\n\n\nDeliverables\n\n\n\nEach team creates 1 example among one of the major theme:\n\nLinear models\nDifferential equations\n\nMultivariate analysis\n\nEach student should devote time to the review process ass well\nThe repository will close on December 1st at 1PM and only the work merged on master will be reviewed and evaluated.\nFinal mark for this assignment will consider\n\nMastering git workflow (commit, pull push , handling conflict, Pull Request, optimmaly rebase to have a clean history)\nTaking part of the reviewing process to increase global quality of the project\n\nDuring the last lab on git, November 5th, students will have a test to evaluate the overall understanding of git process\nThe final grad will be based on both evaluation"
  },
  {
    "objectID": "instructions.html#sec-overview",
    "href": "instructions.html#sec-overview",
    "title": "Stats Reminder Project - Instructions",
    "section": "",
    "text": "Team project for groups of 3 students. Create examples demonstrating statistical/mathematical methods applied to ecological questions.\nRepository: https://github.com/MarieEtienne/stats-reminder\n\n\n\n\n\n\nDeliverables\n\n\n\nEach team creates 1 example among one of the major theme:\n\nLinear models\nDifferential equations\n\nMultivariate analysis\n\nEach student should devote time to the review process ass well\nThe repository will close on December 1st at 1PM and only the work merged on master will be reviewed and evaluated.\nFinal mark for this assignment will consider\n\nMastering git workflow (commit, pull push , handling conflict, Pull Request, optimmaly rebase to have a clean history)\nTaking part of the reviewing process to increase global quality of the project\n\nDuring the last lab on git, November 5th, students will have a test to evaluate the overall understanding of git process\nThe final grad will be based on both evaluation"
  },
  {
    "objectID": "instructions.html#sec-requirements",
    "href": "instructions.html#sec-requirements",
    "title": "Stats Reminder Project - Instructions",
    "section": "Project requirements",
    "text": "Project requirements\n\nContent\nEach .qmd example must include:\n\nClear ecological question with real/realistic data\nProper cross-references: sections (@sec-methods), figures (@fig-plot), tables (@tbl-results) or equations (@eq-model)\nCitations and bibliography\nWell-documented code and results\n\n\n\nGit Workflow\n\nOne branch per example: team-[names]-[method]-[description]\nUpdate _quarto.yml to include your examples in the website structure (see Section¬†3.3)\nOptimally Rebase before PR to ensure linear history (see Section¬†3.4)\nPR requirements (see Section¬†4.2):\n\n‚úÖ No merge conflicts\n‚úÖ Automated checks pass\n‚úÖ One peer review\n‚úÖ At least one discussion thread"
  },
  {
    "objectID": "instructions.html#sec-workflow",
    "href": "instructions.html#sec-workflow",
    "title": "Stats Reminder Project - Instructions",
    "section": "Git Workflow",
    "text": "Git Workflow\n\nSetup\n# Clone repository\ngit clone https://github.com/MarieEtienne/stats-reminder.git\ncd stats-reminder\n\n# Create team branch\ngit switch -b teamA\ngit push origin teamA\n\n\nCreate one branch per task\n# From your team branch, create example branches\ngit switch teamA\ngit switch -b teamA-intro\n\n# Work on your .qmd file\ngit add linear_model_teamA.qmd\ngit commit -m \"Add linear model example\"\n....\ngit fetch origin teamA\ngit rebase teamA \n\n# If conflicts: resolve, then\ngit add &lt;resolved-files&gt;\ngit rebase --continue\n\n# switch to team branch and update the branch with this neaw linear history\ngit switch teamA\ngit merge teamA-intro\n\n\nUpdating _quarto.yml\nAdd your examples to the website structure:\nwebsite:\n  navbar:\n    left:\n      - text: \"Team Examples\"\n        menu:\n          - text: \"Team Smith\"\n            menu:\n              - text: \"Plant Growth (Linear)\"\n                href: linear_model_teamA.qmd\n              - text: \"Predator-Prey (Diff Eq)\"\n                href: team-smith-diffeq-predator.qmd\n\n\n\nUpdate Before PR\n\n\n\n\n\n\nWarning\n\n\n\nAlways rebase on master before creating PR to ensure clean linear history and avoid conflicts.\n\n\ngit switch teamA\ngit switch -c teamA_PR #create a new branch to avoid destruction\n\n# Fetch and rebase\ngit fetch origin master\ngit rebase origin/master\n\n# If conflicts: resolve, then\ngit add &lt;resolved-files&gt;\ngit rebase --continue\n\n# push teamA_PR and ask for PR in github, there should be no conflict\ngit push origin teamA_PR"
  },
  {
    "objectID": "instructions.html#sec-pull-requests",
    "href": "instructions.html#sec-pull-requests",
    "title": "Stats Reminder Project - Instructions",
    "section": "Pull Requests",
    "text": "Pull Requests\n\nCreating a PR\n\nGo to repository ‚Üí Pull requests ‚Üí New pull request\nBase: master, Compare: teamA_PR\nWrite clear description (method, question, team)\n\n\n\nPR Requirements\nAll must be met before merge:\n\n‚úÖ No conflicts (rebase if needed, see Section¬†3.4)\n‚úÖ Automated checks pass (builds website successfully)\n‚úÖ One review from peer/instructor\n‚úÖ One discussion thread (respond to reviewer comments)\n\nAfter merge, the website automatically deploys to GitHub Pages.\nBe careful that, history in teamA and teamA_PR differ, and teamA_PR is the one to be merged. So if you want to add more contents to your project, remove local and remote teamA branch (and teamA_PR once merge into master) and starts a new branch from the current master branch"
  },
  {
    "objectID": "instructions.html#sec-markdown",
    "href": "instructions.html#sec-markdown",
    "title": "Stats Reminder Project - Instructions",
    "section": "Cross-References & Citations",
    "text": "Cross-References & Citations\n\nCross-References\n## Methods {#sec-methods}\n\nThe model (@eq-linear) uses data shown in @fig-scatter and @tbl-summary.\n\n$$ y = \\beta_0 + \\beta_1 x $$ {#eq-linear}\n\n```{r}\n#| label: fig-scatter\n#| fig-cap: \"Relationship between variables\"\nplot(x, y)\n```\n\nAs described in @sec-methods...\n\n\nCitations\nCreate references.bib:\n@article{smith2020,\n  author = {Smith, J.},\n  title = {Statistical Methods},\n  journal = {Ecology},\n  year = {2020}\n}\nIn your YAML:\nbibliography: references.bib\nIn text:\nAccording to @smith2020, the method..."
  },
  {
    "objectID": "instructions.html#sec-rules",
    "href": "instructions.html#sec-rules",
    "title": "Stats Reminder Project - Instructions",
    "section": "Important Rules",
    "text": "Important Rules\n\n\n\n\n\n\nImportant\n\n\n\n\nMaster is protected - you cannot push directly\nUse rebase not merge (see Section¬†3.4) as much as possible, that is the good practice\nPass all checks before requesting merge"
  },
  {
    "objectID": "instructions.html#sec-troubleshooting",
    "href": "instructions.html#sec-troubleshooting",
    "title": "Stats Reminder Project - Instructions",
    "section": "Common Issues",
    "text": "Common Issues\nBuild failing: Check logs for syntax errors in .qmd, missing packages, broken cross-references, or invalid _quarto.yml.\nCan‚Äôt push to master: Expected! Create a branch instead (see Section¬†3.2)."
  },
  {
    "objectID": "instructions.html#sec-checklist",
    "href": "instructions.html#sec-checklist",
    "title": "Stats Reminder Project - Instructions",
    "section": "Checklist",
    "text": "Checklist\nBefore submitting PR:\n\n_quarto.yml updated\nCross-references used throughout\nCitations included\nNo conflicts\nRebased on master\nPR created with clear description\nChecks passing\nReview requested"
  },
  {
    "objectID": "instructions.html#sec-resources",
    "href": "instructions.html#sec-resources",
    "title": "Stats Reminder Project - Instructions",
    "section": "Resources",
    "text": "Resources\n\nQuarto Cross-References\nGit Rebase Tutorial\nCreating Pull Requests\n\nQuestions? Check GitHub Issues or contact the instructor. Good luck! üöÄ"
  },
  {
    "objectID": "Linear_Model_1.html",
    "href": "Linear_Model_1.html",
    "title": "GENERAL LINEAR MODEL",
    "section": "",
    "text": "We present here, a reminder sheet on the General Linear Model (GLM) and its specific features. Its use will be illustrated with an example applied to ecological data on penguins from Gorman, Williams, and Fraser (2014) .\n\n\n\n\n\n\n\nNote\n\n\n\nThe concepts covered in this reminder sheet are taken from our Master‚Äôs lectures, written by Outreman (n.d.) and then taught by Masson (n.d.) . During these courses, we learned how to explore data and then analyze it using this type of model.\n\n\n\n\n\nThe objective of the GLM is to explain a dependent variable as a function of independent explanatory variables measured on statistical units from a sample of a population. This type of model is generally constructed as follows:\n\n\\[Y = Œ≤*X + Œµ\\]\n\\(Y\\) is the response (dependent) variable to be explained. \\(X\\) is an explanatory (independent) variable that can explain \\(Y\\). There can be several explanatory variables in the model. Œ≤ represents a coefficient, placed in front of the \\(X\\) variables, to measure their effect on the response variable. Œµ represents the errors in the model, i.e.¬†what the model cannot explain.\n\n\n\nThere are three general types of linear models:\n\nLinear regression\nAnalysis of variance (ANOVA)\nAnalysis of variance-covariance (ANCOVA)\n\nThey each have their own specific characteristics and depend on the nature of the independent variables \\(X\\), which can be quantitative or qualitative. The response variable \\(Y\\) is always quantitative.\nLinear regression is used when we want to determine whether a linear relationship exists between the response variable \\(Y\\) and one or more quantitative \\(X\\) variables (then called covariates).\nANOVA is used when the explanatory variables \\(X\\) are qualitative (then called factors). These qualitative \\(X\\) variables often have multiple categories (levels).\n\nANCOVA is used when we want to model the variable \\(Y\\) as a function of several \\(X\\) variables, which can be qualitative and quantitative.\n\n\nAnother important aspect to consider is that for this type of model to be valid, three conditions must be met:\n\n\nthe model residuals must follow a normal distribution\nhomoscedasticity (homogeneity of the variance of the residuals) must be respected\nthe residuals are independent\n\nThese conditions are systematically verified after modelling : the verification will be illustrated in the following example."
  },
  {
    "objectID": "Linear_Model_1.html#generalities",
    "href": "Linear_Model_1.html#generalities",
    "title": "GENERAL LINEAR MODEL",
    "section": "",
    "text": "The objective of the GLM is to explain a dependent variable as a function of independent explanatory variables measured on statistical units from a sample of a population. This type of model is generally constructed as follows:\n\n\\[Y = Œ≤*X + Œµ\\]\n\\(Y\\) is the response (dependent) variable to be explained. \\(X\\) is an explanatory (independent) variable that can explain \\(Y\\). There can be several explanatory variables in the model. Œ≤ represents a coefficient, placed in front of the \\(X\\) variables, to measure their effect on the response variable. Œµ represents the errors in the model, i.e.¬†what the model cannot explain."
  },
  {
    "objectID": "Linear_Model_1.html#types-of-general-linear-models",
    "href": "Linear_Model_1.html#types-of-general-linear-models",
    "title": "GENERAL LINEAR MODEL",
    "section": "",
    "text": "There are three general types of linear models:\n\nLinear regression\nAnalysis of variance (ANOVA)\nAnalysis of variance-covariance (ANCOVA)\n\nThey each have their own specific characteristics and depend on the nature of the independent variables \\(X\\), which can be quantitative or qualitative. The response variable \\(Y\\) is always quantitative.\nLinear regression is used when we want to determine whether a linear relationship exists between the response variable \\(Y\\) and one or more quantitative \\(X\\) variables (then called covariates).\nANOVA is used when the explanatory variables \\(X\\) are qualitative (then called factors). These qualitative \\(X\\) variables often have multiple categories (levels).\n\nANCOVA is used when we want to model the variable \\(Y\\) as a function of several \\(X\\) variables, which can be qualitative and quantitative.\n\n\nAnother important aspect to consider is that for this type of model to be valid, three conditions must be met:\n\n\nthe model residuals must follow a normal distribution\nhomoscedasticity (homogeneity of the variance of the residuals) must be respected\nthe residuals are independent\n\nThese conditions are systematically verified after modelling : the verification will be illustrated in the following example."
  },
  {
    "objectID": "Linear_Model_1.html#import-useful-libraries",
    "href": "Linear_Model_1.html#import-useful-libraries",
    "title": "GENERAL LINEAR MODEL",
    "section": "Import useful libraries",
    "text": "Import useful libraries\nHere we import the libraries we will use during the analysis.\n\n\nCode\nlibrary(MASS)\nlibrary(corrplot)\n\n\ncorrplot 0.95 loaded"
  },
  {
    "objectID": "Linear_Model_1.html#data-import",
    "href": "Linear_Model_1.html#data-import",
    "title": "GENERAL LINEAR MODEL",
    "section": "Data import",
    "text": "Data import\nFirstly, we need to import the data, explore it, and see if there are any NA values, outliers, and so on. The data is accessible via the package palmerpenguins by Horst, Hill, and Gorman (2020).\n\n\nCode\n# Data import \nlibrary(palmerpenguins) \ndata(\"penguins\") \n\n# Change categorical variables as factor \npenguins$sex&lt;-as.factor(penguins$sex) \npenguins$species&lt;-as.factor(penguins$species)\n\n# Check for presence of missing values \ncolSums(is.na(penguins))\n\n\n          species            island    bill_length_mm     bill_depth_mm \n                0                 0                 2                 2 \nflipper_length_mm       body_mass_g               sex              year \n                2                 2                11                 0 \n\n\nCode\nsummary(penguins$sex)\n\n\nfemale   male   NA's \n   165    168     11 \n\n\nThere are NA values in the dataset. Two rows contain missing values for all variables, except species. Values are missing for the variable sex in nine additional rows. There are different ways to process NA values. We decide to delete the two rows where almost all information is missing. Then, one option would be to replace the other missing values for the sex variable by ‚Äúunknown‚Äù to specify that we don‚Äôt know whether the individual is a male or a female and to create a new level for this variable. However, with this option, the group whose sex is unknown would be underrepresented compared to male and female groups. As it seems interesting to test whether being a female or a male has an influence on the body mass of penguins, having rows where the sex of individuals is unknown is not really useful and could add noise to the analysis. Therefore, we decide to delete all rows containing NA values. Moreover, the rows including NA values only represented about 3% of the dataset.\n\n\nCode\n# Check for presence of missing values\npenguins&lt;-na.omit(penguins)\ncolSums(is.na(penguins))\n\n\n          species            island    bill_length_mm     bill_depth_mm \n                0                 0                 0                 0 \nflipper_length_mm       body_mass_g               sex              year \n                0                 0                 0                 0 \n\n\nWe now have handled NA values and can continue to explore the data before implementing the model to answer our question."
  },
  {
    "objectID": "Linear_Model_1.html#data-exploration",
    "href": "Linear_Model_1.html#data-exploration",
    "title": "GENERAL LINEAR MODEL",
    "section": "Data exploration",
    "text": "Data exploration\nData exploration is always the first step before analysis and model creation. This step is essential for identifying the structure of variables and checking for outliers, correlations, unbalanced distributions that could bias the results of the analysis.\n\n1. Outliers and distribution of the dependent variable (\\(Y\\))\n\\(Y\\) (i.e body_mass_g ) is a continuous quantitative variable. Let‚Äôs take a look at its distribution, using the following graphs.\n\nCode\npar(mfrow=c(2,2),      \n    mar=c(4,4,2,1),           \n    bg=\"gray95\",              \n    col.axis=\"gray20\",      \n    col.lab=\"gray20\",     \n    col.main=\"gray20\",     \n    cex.axis=0.9,      \n    cex.lab=1) \ncol_transp &lt;- adjustcolor(\"aquamarine3\", alpha.f=0.5)\n\n# Boxplot \nboxplot(penguins$body_mass_g,         \n        col=col_transp, border=\"gray30\",         \n        ylab='Body Mass (g)',         \n        main = 'Boxplot',         \n        notch=TRUE)\n\n# Cleveland plot \ndotchart(penguins$body_mass_g,          \n         pch=16, col=col_transp,          \n         xlab='Body Mass (g)',          \n         main = 'Cleveland plot',          \n         cex=0.8)\n\n# Histogram \nhist(penguins$body_mass_g,      \n     col=col_transp, \n     border=\"white\",      \n     xlab=\"Body Mass (g)\",      \n     main = 'Histogram',      \n     breaks=20)\n\n# Quantile-Quantile plot \nqqnorm(penguins$body_mass_g, pch=16, col=col_transp, xlab='', ylab='',main=\"QQ plot\") \nqqline(penguins$body_mass_g, col='red', lwd=2)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure¬†1\n\n\n\nBased on the Boxplot, Cleveland plot and Histogram (Figure¬†1), it seems that there are no outliers in the \\(Y\\) variable body_mass_g. With the Q-Q plot, the data appears to follow a Gaussian distribution. However, \\(Y\\) normality is not a required assumption for our model. Keep in mind that we will need to check something about normality later on : the model residuals must follow a normal distribution in the case of a linear model.\n\n\n2. Outliers and Distributions of Quantitative Predictors (\\(X\\))\nWe also take a look at the distribution of \\(Xs\\), using the same graphs.\n\nCode\n#Don't show the code \npar(mfrow=c(2,2),      \n    mar=c(4,4,2,1),           \n    bg=\"gray95\",              \n    col.axis=\"gray20\",      \n    col.lab=\"gray20\",      \n    col.main=\"gray20\",      \n    cex.axis=0.9,      \n    cex.lab=1) \ncol_transp &lt;- adjustcolor(\"darkgreen\", alpha.f=0.5)  \n\n# Bill lenght  \n# Boxplot \nboxplot(penguins$bill_length_mm,         \n        col=col_transp, border=\"gray30\",         \n        ylab='Bill Length',         \n        main = 'Boxplot',         \n        notch=TRUE) \n# Cleveland plot \ndotchart(penguins$bill_length_mm,          \n         pch=16,          \n         col=col_transp,          \n         xlab='Bill Length',          \n         main = 'Cleveland plot') \n# Histogram \nhist(penguins$bill_length_mm,      \n     col=col_transp,      \n     xlab=\"Bill Length\",      \n     main=\"Histogram\") \n# Quantile-Quantile plot \nqqnorm(penguins$bill_length_mm,        \n       pch=16,col=col_transp,xlab='',         \n       main = 'QQ plot') \nqqline(penguins$bill_length_mm,col='red',lwd=2)\n\n\nCode\n# Bill depth\n# Boxplot \nboxplot(penguins$bill_depth_mm,         \n        col=col_transp, border=\"gray30\",         \n        ylab='Bill Depth',         \n        main = 'Boxplot',         \n        notch=TRUE) \n# Cleveland plot \ndotchart(penguins$bill_depth_mm,          \n         pch=16,          \n         col=col_transp,          \n         xlab='Bill Depth',          \n         main = 'Cleveland plot') \n# Histogram \nhist(penguins$bill_depth_mm,      \n     col=col_transp,     \n     xlab=\"Bill Depth\",      \n     main=\"Histogram\") \n# Quantile-Quantile plot \nqqnorm(penguins$bill_depth_mm,        \n       pch=16,        \n       col=col_transp,xlab='',        \n       main = 'QQ plot') \nqqline(penguins$bill_depth_mm,col='red',lwd=2)\n\n\nCode\n# Flipper lenght  \n# Boxplot \nboxplot(penguins$flipper_length_mm,         \n        col=col_transp, border=\"gray30\",         \n        ylab='Flipper Length',         \n        main = 'Boxplot',         \n        notch=TRUE) \n# Cleveland plot \ndotchart(penguins$flipper_length_mm,          \n         pch=16,          \n         col=col_transp,          \n         xlab='Flipper Length',          \n         main = 'Cleveland plot') \n# Histogram \nhist(penguins$flipper_length_mm,      \n     col=col_transp,      \n     xlab=\"Flipper Length\",      \n     main=\"Histogram\") \n# Quantile-Quantile plot \nqqnorm(penguins$flipper_length_mm,        \n       pch=16,        \n       col=col_transp,xlab='',        \n       main = 'QQ plot') \nqqline(penguins$flipper_length_mm,col='red',lwd=2)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure¬†2\n\n\n\nThere appear to be no outliers for any of the quantitative variables.\nLet‚Äôs describe what we observe while looking at the graphs in Figure¬†2. From the Cleveland plot, for the bill length variable, we can observe two distinct clusters which might be related to sexual dimorphism. For the bill depth, 3 clusters are observed on the Cleveland Plot : this variable might be related to the difference of bill depth between species. For flipper length, the Cleveland plot also reveals three distinct clusters. All these variables seem to follow a Gaussian distribution. Visualizing the distributions of the quantitative \\(X\\) variables allows us to formulate hypotheses regarding species differences and sexual dimorphism.\n\n\n3. Number of Levels and Individuals per Level of Qualitative Predictors (\\(X\\))\n\n\nCode\nsummary(penguins$species) \n\n\n   Adelie Chinstrap    Gentoo \n      146        68       119 \n\n\nCode\nsummary(penguins$sex)\n\n\nfemale   male \n   165    168 \n\n\nFor the species variable, Chinstrap is a bit under-represented in comparison to other species. We will keep the variable for the model as it may capture important differences between groups. For the sex variable, the number of observations is almost equivalent for the male and female groups.\n\n\n4. Analysis of the Potential Relationships Between \\(Y\\) and the \\(Xs\\)\nNow, we can explore the potential relationship between the response variable \\(Y\\) (body_mass_g) and the \\(Xs\\) variables. Keep in mind that this part of the analysis is based on graphs and doesn‚Äôt tell us if the relationships between variables are significant or not.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure¬†3\n\n\n\nLooking at these graphs (Figure¬†3), there appears to be a positive linear relationship between body mass and other quantitative variables. A sexual dimorphism is observed : females tend to have a lower body mass than males. In addition, there may be species differences : Gentoo penguins appear to have higher body mass compared to Adelie and Chinstrap penguins, which have similar body mass measurements.\n\n\n5. Analysis of possible interactions between both independent variables\nThis section aims to check for potential interaction effects between the two qualitative variables. To do so, all combinations of their categories must be present in the data.\n\n\nCode\ntable(penguins$species, penguins$sex) \n\n\n           \n            female male\n  Adelie        73   73\n  Chinstrap     34   34\n  Gentoo        58   61\n\n\nAll categories are present and well balanced across the factors, allowing us to test for potential interactions between them.\n\n\nCode\nboxplot(penguins$body_mass_g~penguins$sex*penguins$species, varwidth = TRUE, ylab = \"Body Mass\", col='green4', main = \"\",cex.axis=0.7)\n\n\n\n\n\n\n\n\n\nMales appear to have a higher body mass than females for the three species. The difference between males and females may vary a little depending on the species. There may be a small interaction between the tow factors sex and species.\nThen, we also check for potential interactions between explanatory quantitative variables and explanatory qualitative variables, using the following graphs.\n\nCode\npar(mfrow=c(3,2)) \n# Interactions between Bill Length & Sex \nplot(penguins$body_mass_g~penguins$bill_length_mm,type='n',ylab = \"Body Mass\",xlab=\"Bill Length\") \npoints(penguins$body_mass_g[penguins$sex==\"male\"]~penguins$bill_length_mm[penguins$sex==\"male\"],pch=16,col='#E69F00') \npoints(penguins$body_mass_g[penguins$sex==\"female\"]~penguins$bill_length_mm[penguins$sex==\"female\"],pch=17,col='#CC79A7')  \n\n# Interactions between Bill Length & Species \nplot(penguins$body_mass_g~penguins$bill_length_mm,type='n',ylab = \"Body Mass\",xlab=\"Bill Length\") \npoints(penguins$body_mass_g[penguins$species==\"Adelie\"]~penguins$bill_length_mm[penguins$species==\"Adelie\"],pch=15,col='#FDE725') \npoints(penguins$body_mass_g[penguins$species==\"Chinstrap\"]~penguins$bill_length_mm[penguins$species==\"Chinstrap\"],pch=16,col='#35B779') \npoints(penguins$body_mass_g[penguins$species==\"Gentoo\"]~penguins$bill_length_mm[penguins$species==\"Gentoo\"],pch=17,col='#31688E')\n\n# Interactions between Bill Depth & Sex \nplot(penguins$body_mass_g~penguins$bill_depth_mm,type='n',ylab = \"Body Mass\",xlab=\"Bill Depth\")\npoints(penguins$body_mass_g[penguins$sex==\"male\"]~penguins$bill_depth_mm[penguins$sex==\"male\"],pch=16,col='#E69F00') \npoints(penguins$body_mass_g[penguins$sex==\"female\"]~penguins$bill_depth_mm[penguins$sex==\"female\"],pch=17,col='#CC79A7')  \n\n# Interactions between Bill Depth & Species \nplot(penguins$body_mass_g~penguins$bill_depth_mm,type='n',ylab = \"Body Mass\",xlab=\"Bill Depth\") \npoints(penguins$body_mass_g[penguins$species==\"Adelie\"]~penguins$bill_depth_mm[penguins$species==\"Adelie\"],pch=15,col='#FDE725') \npoints(penguins$body_mass_g[penguins$species==\"Chinstrap\"]~penguins$bill_depth_mm[penguins$species==\"Chinstrap\"],pch=16,col='#35B779') \npoints(penguins$body_mass_g[penguins$species==\"Gentoo\"]~penguins$bill_depth_mm[penguins$species==\"Gentoo\"],pch=17,col='#31688E')\n\n# Interactions between Flipper Length & Sex \nplot(penguins$body_mass_g~penguins$flipper_length_mm,type='n',ylab = \"Body Mass\",xlab=\"Flipper Length\") \npoints(penguins$body_mass_g[penguins$sex ==\"male\"]~penguins$flipper_length_mm[penguins$sex==\"male\"],pch=16,col='#E69F00') \npoints(penguins$body_mass_g[penguins$sex==\"female\"]~penguins$flipper_length_mm[penguins$sex==\"female\"],pch=17,col='#CC79A7')  \n\n# Interactions between Flipper Length & Species \nplot(penguins$body_mass_g~penguins$flipper_length_mm,type='n',ylab = \"Body Mass\",xlab=\"Flipper Length\") \npoints(penguins$body_mass_g[penguins$species==\"Adelie\"]~penguins$flipper_length_mm[penguins$species==\"Adelie\"],pch=15,col='#FDE725') \npoints(penguins$body_mass_g[penguins$species==\"Chinstrap\"]~penguins$flipper_length_mm[penguins$species==\"Chinstrap\"],pch=16,col='#35B779') \npoints(penguins$body_mass_g[penguins$species==\"Gentoo\"]~penguins$flipper_length_mm[penguins$species==\"Gentoo\"],pch=17,col='#31688E')\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure¬†4\n\n\n\nHere are our observations regarding possible interactions, based on the graphs of Figure¬†4 :\nBill length and sex : there is a possible interaction. For some values of bill length, body mass is higher for males than females but for some values the opposite is true and females have a higher body mass than males.\nBill length and species : there are three color clusters that do not appear to mix on the graph. Individuals of the Gentoo species appear to have a higher body mass than the other species, but sometimes slightly lower depending on bill length values. A small interaction is possible.\nBill depth and sex : there appears to be no interaction between bill depth and sex. The relation between body mass and bill depth is the same for males and females and males body mass is higher than females body mass.\nBill depth and species : there appears to be no interaction between bill depth and species. The relation between body mass and bill depth observed previously during the data exploration is the same and the Gentoo species still stands out in terms of body mass : individuals of the Gentoo species still appear to have a higher body mass than the other species.\nFlipper length and sex : there is a possible interaction. Body mass appears to increase with flipper length but for some values of flipper length, females can have a higher body mass than males.\nFlipper length and species : there appears to be no interaction between flipper length and species. The relation between body mass and bill length observed previously during the data exploration is the same regardless the species and the Gentoo species still stands out in terms of body mass, which remains higher than the body of the other species on the graph.\nThese are only observations. For the moment, we don‚Äôt know which interactions are significant. This will be tested afterwards.\n\n\n6. Check for collinearity between predictors (\\(Xs\\))\nCollinearity should be avoided in modelling. Indeed, it can affect the modelling and the significance of the variables in the model, which affects the conclusions. Let‚Äôs check how the explanatory variables are related (Figure¬†5).\n\nCode\n# Checking collinearity between continuous independent variables\nplot(penguins[,3:5],pch=16,col='darkolivegreen4')\n\n\nCode\nM&lt;-cor(penguins[,3:5])\ncorrplot.mixed(M,upper=\"square\",lower.col=\"black\", tl.col=\"black\",cl.cex = 0.8,tl.cex = 0.7,number.cex =0.8)\n\n\nCode\n# Checking collinearity between categorical and continuous independent variables\npar(mfrow=c(2,3))\n#Bill Length and Sex\nboxplot(penguins$bill_length_mm~penguins$sex, varwidth = TRUE, ylab = \"Bill Length\", xlab = \"Sex\", col='grey', main = \"\")\n#Bill Depth and Sex\nboxplot(penguins$bill_depth_mm~penguins$sex, varwidth = TRUE, ylab = \"Bill Depth\", xlab = \"Sex\", col='grey', main = \"\")\n#Flipper Length and Sex\nboxplot(penguins$flipper_length_mm~penguins$sex, varwidth = TRUE, ylab = \"Flipper Length\", xlab = \"Sex\", col='grey', main = \"\")\n#Bill Length and Species\nboxplot(penguins$bill_length_mm~penguins$species, varwidth = TRUE, ylab = \"Bill Length\", xlab = \"Species\", col='grey', main = \"\")\n#Bill Depth and Species\nboxplot(penguins$bill_depth_mm~penguins$species, varwidth = TRUE, ylab = \"Bill Depth\", xlab = \"Species\", col='grey', main = \"\")\n#Flipper Length and Species\nboxplot(penguins$flipper_length_mm~penguins$species, varwidth = TRUE, ylab = \"Flipper Length\", xlab = \"Species\", col='grey', main = \"\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure¬†5\n\n\n\nThis verification of collinearity between \\(Xs\\) revealed a positive correlation between Flipper Length and Bill Length. The coefficient is below the threshold of 0.7, so we will not exclude any of these variables.\nNote : In some cases, there may be a strong correlation between a specific variable and some other variables, with a high correlation coefficient (above 0.7, which is the threshold set in most cases). This situation can lead you to exclude this specific variable to avoid collinearity but you always need to justify your choice.\nAs for the other variables : For bill length, bill depth and flipper length, we observe a small difference between males and females. It appears that Adelie penguins have a shorter bill length than to the two other species. It appears that Gentoo penguins have a smaller bill depth and bigger flipper length than the other species."
  },
  {
    "objectID": "CA.html",
    "href": "CA.html",
    "title": "What is a CA and how to use it ?",
    "section": "",
    "text": "A Correspondence Analysis (CA), or Analyse Factorielle de Correspondance (AFC) in French, is a multivariate statistical method used to measure the distance between different profiles in your data, or the discrepancy between the data and the chi-square \\(\\chi¬≤\\) independence hypothesis. This hypothesis (also called the null hypothesis H0) implies that the 2 variables studied are independent.\nThe values can be quantitative, qualitative or semi-qualitative. It is usually applied to contingency tables or when you have a table with data about species abundance in different places and another one with data about the ecology of those same places.\nJust like in the PCA, we will be looking at the orthogonal axes that maximize the inertia. The parameter used is the \\(\\chi¬≤\\) distance : this distance is calculated between 2 rows or 2 columns. The CA gives a weight to each profile, proportional to the abundance of the profile.\nThe columns and lines have a symmetrical role, so you‚Äôll have the same results in both directions.\nTo use it you‚Äôll need to pay attention to certain things :\n- all values need to be positive (which shouldn‚Äôt be a problem if it‚Äôs a contingency table),\n- if you have rare species, it may change the shape of your results significantly. It‚Äôs not always a bad thing, just something you need to be aware of.\nTwo R packages can be used to perform CA : ade4 (Dray and Dufour (2007)) and FactoMineR (L√™, Josse, and Husson (2008))."
  },
  {
    "objectID": "CA.html#ecological-context",
    "href": "CA.html#ecological-context",
    "title": "What is a CA and how to use it ?",
    "section": "Ecological context",
    "text": "Ecological context\nA study was conducted in 2022 on the permanent wetlands of the municipality of Grabels (34), as part of a Municipal Biodiversity Atlas (GEB (2023)). The aim was to characterize the state of these environments using bioindicator species : benthic macroinvertebrates (Figure¬†1). This taxon, which is sensitive to pollution, can be used to study water quality.\n\nImports\n\n\n\n\n\n\n\n\n\n\n\n(a) Libellulidae\n\n\n\n\n\n\n\n\n\n\n\n(b) Physidae\n\n\n\n\n\n\n\nFigure¬†1: Example of two families of benthic macroinvertebrates\n\n\n\nIn this study, the standardised I2M2 protocol of the Water Framework Directive (European Parliament (2014)) was adapted to a context of ponds and very shallow watercourses.\nTwo streams (the Rieu Querelle and the Verdanson), permanent ponds (Ruche, Terrain de Foot and Foot2) and an artificial water source (Bassin) were sampled and the macroinvertebrates collected were identified. Each wetland was sampled at several randomly selected points (Zi), and three replicas were made at each point (Zi_j).\nThe purpose of this analysis is to study the species assemblages depending of the site. In this context, the CA is one of the right choices."
  },
  {
    "objectID": "CA.html#packages",
    "href": "CA.html#packages",
    "title": "What is a CA and how to use it ?",
    "section": "Packages",
    "text": "Packages\n\n\nCode\nrm(list = ls())\nrequiredPackages &lt;- c(\"dplyr\",\"readr\", \"stringi\", \"ggplot2\", \"vegan\", \n                      \"tidyr\", \"gridtext\", \"ggtext\")\nfor(package in requiredPackages){ #Installs packages if not yet installed\n  if(!requireNamespace(package, quietly = TRUE))\n    install.packages(package)\n}\nlibrary(dplyr)\nlibrary(readr)\nlibrary(stringi)\nlibrary(FactoMineR)\nlibrary(ade4)\nlibrary(ggplot2)\nlibrary(vegan)\nlibrary(tidyr)\nlibrary(factoextra)\nlibrary(gridtext)\nlibrary(ggtext)\nlibrary(knitr)"
  },
  {
    "objectID": "CA.html#data",
    "href": "CA.html#data",
    "title": "What is a CA and how to use it ?",
    "section": "Data",
    "text": "Data\n\n\nCode\n# Import data\nmacroinv &lt;- read.csv(\"ABC_macroinv.csv\", header = TRUE, \n                     fileEncoding = \"latin1\", \n                     sep = \";\")\n\nclassification &lt;- read_delim(\"classif_macroinv.csv\", delim = \";\", \n                             col_names = FALSE, \n                             locale = locale(encoding = \"latin1\"),\n                             name_repair = \"minimal\")\n\n# Replace colnames in both dataframes\ncolnames(macroinv) &lt;- colnames(macroinv) %&gt;%\n                  stri_trans_general(\"Latin-ASCII\") %&gt;% \n                  gsub(\"\\\\.\", \"_\", .) %&gt;%\n                  gsub(\"[^A-Za-z0-9_]\", \"\", .)\n\nclassification &lt;- classification %&gt;%\n  mutate(across(everything(), \\(x)\n                x %&gt;%\n                  stri_trans_general(\"Latin-ASCII\") %&gt;% \n                  gsub(\" \", \"_\", .) %&gt;%\n                  gsub(\"[^A-Za-z0-9_]\", \"\", .)))\n\n# Rotate classification tabs\nclassification &lt;- classification %&gt;% \n  t() %&gt;% \n  data.frame()\n\n\nIn each sample (each row), macroinvertebrates have been identified at the family level (Table¬†1), and the CA analysis will be performed at the taxonomic level.\n\n\nCode\nkable(head(macroinv[,1:10]), \"html\")\n\n\n\n\nTable¬†1: Overview of the dataset\n\n\n\n\n\n\nEchantillon\nZH\nAcariforme_hydracarien\nNiphargidae\nTriops\nGammaridae\nAstacidae\nAtyidae\nAsellidae\nCambaridae\n\n\n\n\nZ1_1\nRuche\n0\n0\n1\n0\n0\n0\n0\n0\n\n\nZ1_2\nRuche\n0\n0\n6\n0\n0\n0\n0\n0\n\n\nZ1_3\nRuche\n0\n0\n0\n0\n0\n0\n0\n0\n\n\nZ1_1\nTerrain_foot\n0\n0\n13\n0\n0\n0\n4\n0\n\n\nZ1_2\nTerrain_foot\n0\n0\n4\n0\n0\n0\n5\n0\n\n\nZ1_3\nTerrain_foot\n0\n0\n2\n0\n0\n0\n2\n0\n\n\n\n\n\n\n\n\nHowever, the taxonomic level of the order was also taken in most cases (Coleoptera, Odonata, etc.) in order to be able to group together the numerous identified families and allow an ecological interpretation (Table¬†2). Other families were grouped at the class level (Bivalves, Gastropods, etc.) and the paraphyletic group of Crustaceans was kept.\n\n\nCode\nkable(head(classification[,1:2]), \"html\", col.names = c(\"Order\", \"Family\"))\n\n\n\n\nTable¬†2: Correspondence between taxonomic levels of macroinvertebrates families and orders\n\n\n\n\n\n\n\nOrder\nFamily\n\n\n\n\nX1\nArachnides\nAcariformehydracarien\n\n\nX2\nCrustaces\nNiphargidae\n\n\nX3\nCrustaces_branchiop\nTriops\n\n\nX4\nCrustaces_amphipod\nGammaridae\n\n\nX5\nCrustaces_decapod\nAstacidae\n\n\nX6\nCrustaces_decapod\nAtyidae\n\n\n\n\n\n\n\n\n\nRemove species absent from the sampling\nSpecies absent from all surveys (empty columns) or present in only one sample were removed to prevent double absences from impacting the analysis.\n\n\nCode\n#check each specie count\nspecies_sum &lt;- colSums(macroinv[,-c(1,2)])\n\n#keep only names of species with &lt;1 occurences\nspecies_keep &lt;- names(species_sum[species_sum &gt; 1])\n\n#create reduced dataframe\nmacroinv_red &lt;- macroinv[, c(names(macroinv)[1:2], species_keep)]"
  },
  {
    "objectID": "CA.html#data-exploration",
    "href": "CA.html#data-exploration",
    "title": "What is a CA and how to use it ?",
    "section": "Data exploration",
    "text": "Data exploration\n\n\nCode\nmacroinv_red %&gt;% \n  group_by(ZH, Echantillon) %&gt;% \n  ggplot(., aes(x = ZH, fill = ZH)) +  \n  geom_bar() + \n  theme_bw() +\n  xlab(\"**Wetland**\") + \n  ylab(\"**Number of replicates**\") +\n  theme(axis.text.x = element_markdown(angle = 45, vjust = 1, \n                                       hjust = 1, size = 11), \n        axis.text.y = element_markdown(size = 11),\n        axis.title = element_markdown(size = 13),\n        legend.position = \"none\")\n\n\n\n\n\n\n\n\nFigure¬†2: Number of replicates per wetland\n\n\n\n\n\nA different number of samples was taken in each wetland (see Figure¬†2), depending on their size. For small wetlands (less than 20m¬≤), such as Ruche or Foot2, it was decided to adjust the number of sampling points in order to limit the ecological impact on these environments. For watercourses such as the Rieu Querelle and the Verdanson, sampling points were distributed to cover the upstream-downstream gradient, with different habitats present.\n\n\nCode\nmacroinv_red %&gt;% \n  group_by(ZH) %&gt;% \n  pivot_longer(cols = c(3:40), names_to = \"Familles\", values_to = \"Abondance\") %&gt;%\n  ggplot(., aes(x = Echantillon, y = Abondance, fill = Familles)) +\n  geom_bar(stat = \"identity\") +\n  facet_wrap(~ ZH) + \n  xlab(\"**Sample**\") + \n  ylab(\"**Number of individuals by sample**\") +\n  theme_bw() + \n  labs(fill = \"**Family**\") + \n  theme(axis.text.x = element_markdown(angle = 90, vjust = 1, hjust = 1), \n        axis.text.y = element_markdown(size = 11),\n        axis.title = element_markdown(size = 13),\n        legend.title = element_markdown())\n\nmacroinv_red %&gt;% \n  group_by(ZH) %&gt;% \n  pivot_longer(cols = c(3:40), names_to = \"Family\", values_to = \"Abondance\") %&gt;%\n  left_join(., classification, by = c(\"Family\" = \"X2\")) %&gt;%\n  ggplot(., aes(x = Echantillon, y = Abondance, fill = X1)) +\n  geom_bar(stat = \"identity\") +\n  facet_wrap(~ ZH) + \n  xlab(\"**Sample**\") + \n  ylab(\"**Number of individuals by sample**\") +\n  theme_bw() + \n  labs(fill = \"**Order**\") + \n  theme(axis.text.x = element_markdown(angle = 90, vjust = 1, hjust = 1), \n        axis.text.y = element_markdown(size = 11),\n        axis.title = element_markdown(size = 13),\n        plot.title = element_markdown(hjust = 0.5, size = 15),\n        legend.title = element_markdown())\n\n\n\n\n\n\n\n\n\n\n\n\n(a) Family level\n\n\n\n\n\n\n\n\n\n\n\n\n\n(b) Order level\n\n\n\n\n\n\n\nFigure¬†3: Abundance of individuals per macroinvertebrate taxonomic level for each sample per wetland\n\n\n\n\nFigure¬†3 shows the number of individuals sampled by family (Figure¬†3 (a)) and by order (Figure¬†3 (b)) for each sample.\nSome taxa are present in large quantities (e.g., Bivalves in Ruche).\nSome orders are very generalist and present in all wetlands (e.g., Diptera, Gastropoda, Bivalvia). Odonata are also represented in all sites, except in the Bassin. Other orders have more specific ecological preferences and are more sensitive to pollution, such as Trichoptera and Plecoptera. The low representation of the latter could be explained by their ecological preference for rocks in streams rather than ponds."
  },
  {
    "objectID": "CA.html#ca-with-factominer",
    "href": "CA.html#ca-with-factominer",
    "title": "What is a CA and how to use it ?",
    "section": "CA with FactoMineR",
    "text": "CA with FactoMineR\n\n\nCode\n#First CA with the reduced data set\nCA &lt;- CA(macroinv_red[,-c(1,2)], axes = c(1,2))\n#plot(CA$eig[,2], type = \"h\")\n\n\n\n\n\n\n\n\nFigure¬†4: CA with the FactoMineR package\n\n\n\n\n\nHere we can see our first CA (Figure¬†4) using the FactoMineR package. The first two axes are displayed. These are the ones that explain the most inertia in the data set, 14,56% and 14,02 as we can see in the parenthesis.\nThe position of the families and sites on the graph indicate how similar they are to each other and how the affect the axis. The more close together they are the more similar they are according to the axes displayed. If they are very far away from the center, they play a bigger role in the contribution to the axis.\nCA allows to see species and sites contribution to the main axis (Table¬†3, Figure¬†5). Here we only show the species contribution and which ones contribute significantly.\n\nCode\n#Selection of the species that contribute significantly to axes one and two\nwhich_contrib_high1 &lt;- which(CA$col$contrib[,1] &gt;= 100/nrow(CA$col$contrib))\nwhich_contrib_high2 &lt;- which(CA$col$contrib[,2] &gt;= 100/nrow(CA$col$contrib))\n\nkable(CA$col$contrib[which_contrib_high1, ], \"html\")\nkable(CA$col$contrib[which_contrib_high2, ], \"html\")\n\n\n\n\nTable¬†3: Species that contribute significantly to Axis 1-2\n\n\n\n\n\n\n\n(a) Species that contribute significantly to axe 1\n\n\n\n\n\n\nDim 1\nDim 2\nDim 3\nDim 4\nDim 5\n\n\n\n\nAsellidae\n3.680245\n0.0953079\n0.0754097\n28.3995886\n5.2119085\n\n\nBivalve\n68.867884\n8.7892169\n0.3125365\n0.0920696\n0.0793127\n\n\nThaunaleidae\n12.359512\n78.6994068\n0.2334673\n3.0135863\n0.1551988\n\n\nCulicidae\n5.331786\n2.5103813\n9.2840921\n1.7645808\n30.1538840\n\n\n\n\n\n\n\n\n\n\n\n\n\n(b) Species that contribute significantly to axe 2\n\n\n\n\n\n\nDim 1\nDim 2\nDim 3\nDim 4\nDim 5\n\n\n\n\nBivalve\n68.867884\n8.789217\n0.3125365\n0.0920696\n0.0793127\n\n\nSimulidae\n1.958174\n3.539633\n0.0035563\n4.4930038\n1.4898874\n\n\nThaunaleidae\n12.359512\n78.699407\n0.2334673\n3.0135863\n0.1551988\n\n\n\n\n\n\n\n\n\n\n\nTo check if they contribute significantly to the axis we look at their contribution. If it is greater than the sum of all contributions divided by the number of species we consider that the contribution is significant. Here (Table¬†3) we can see that four families contribute significantly to the construction of the first axis and three families for the second one. Without surprise, Thaunaleidae contributes to both of them, Bivalve also appears in both. Then Culicidae and Asellidae contribute significantly to the first axis and Simulidae to the second axis.\n\n\nCode\n# BONUS : visualize axis contribution\n\nfviz_contrib(CA, choice = \"col\", axes = 1, top = Inf)  # contributions Axis 1\nfviz_contrib(CA, choice = \"col\", axes = 2, top = Inf)  # contributions Axis 2\n\n\n\n\n\n\n\n\n\n\n\n\n(a) Species contribution to axe 1\n\n\n\n\n\n\n\n\n\n\n\n\n\n(b) Species contribution to axe 2\n\n\n\n\n\n\n\nFigure¬†5: Species contribution to Axis 1-2\n\n\n\n\nHere (Figure¬†5) is another way of presenting the contributions. The red line represents the threshold for the signicance of the contribution.\nFactoMineR is not the only package that can be used for a CA. Here are a few examples of functions that can be useful in the ade4 package.\nWe noticed that Thaunaleidae are only present in one of the sites, a bassin, and it is dragging the CA. In this next section we will also look at the CA without the odd bassin."
  },
  {
    "objectID": "CA.html#ca-with-ade4",
    "href": "CA.html#ca-with-ade4",
    "title": "What is a CA and how to use it ?",
    "section": "CA with ade4",
    "text": "CA with ade4\nWhen using the ade4 package we need to specify nf, it defines the number of axes in the CA constructed : it is calculated by taking minimum(number of columns, number of rows) - 1 (here 38 - 1 = 37)\n\n\nCode\nCA_ade4 &lt;- dudi.coa(macroinv_red[,-c(1,2)], scannf = FALSE, nf = 37)\n\n\nCA_ade4_sansbassin &lt;- dudi.coa(macroinv_red[-c(27,28,29), -c(1,2)], \n                               scannf = FALSE, nf = 37)\n\n\nAfter studying the contribution to each axis we can look at how much information is contained in each axis : the inertia.\n\nInertia explained\nPercentage of inertia explained according to the axes :\n\nCode\npourcentage &lt;- CA_ade4$eig/sum(CA_ade4$eig)*100\nkable(round(pourcentage[1:10],2),'html',col.names = \"With bassin\")\npourcentage_sansbassin &lt;- CA_ade4_sansbassin$eig/sum(CA_ade4_sansbassin$eig)*100\nkable(round(pourcentage_sansbassin[1:10],2),'html',col.names = \"Without bassin\")\n\n\n\n\nTable¬†4: Inertia explained by axis\n\n\n\n\n\n\n\n(a) With the bassin\n\n\n\n\n\nWith bassin\n\n\n\n\n14.56\n\n\n14.02\n\n\n12.06\n\n\n10.33\n\n\n8.13\n\n\n4.99\n\n\n4.76\n\n\n4.20\n\n\n3.98\n\n\n2.79\n\n\n\n\n\n\n\n\n\n\n\n(b) Without the bassin\n\n\n\n\n\nWithout bassin\n\n\n\n\n16.75\n\n\n13.95\n\n\n12.16\n\n\n9.44\n\n\n5.80\n\n\n5.57\n\n\n4.86\n\n\n4.62\n\n\n3.23\n\n\n3.06\n\n\n\n\n\n\n\n\n\n\n\nHere we only show the first ten axes. We can see that the first axis explains more inertia when we remove the bassin, 16.75% versus 14.56% (Table¬†4).\nCumulative inertia :\n\nCode\ninertie_cumulee &lt;- data.frame(axes = 1:37, inertie = cumsum(pourcentage))\ninertie_cumulee_sansbassin &lt;- data.frame(axes = 1:36, inertie = cumsum(pourcentage_sansbassin))\n\nggplot(inertie_cumulee) +\n  aes(y = inertie, x = axes) +\n  geom_col() +\n  theme_bw()\n\nggplot(inertie_cumulee_sansbassin) +\n  aes(y = inertie, x = axes) +\n  geom_col() +\n  theme_bw()\n\n\n\n\n\n\n\n\n\n\n\n\n(a) With Bassin samples\n\n\n\n\n\n\n\n\n\n\n\n(b) Without Bassin samples\n\n\n\n\n\n\n\nFigure¬†6: Cumulative eigenvalues associates to CA dimensions\n\n\n\nIt is interesting to look at the cumulative inertia to choose how many axis are interesting to keep. It is common to keep the first one to three or the ones that explain up to 50% of the inertia. But in ecology it can be hard to get to that percentage so it‚Äôs okay if the inertia is not that high.\nHere we can see that when we remove the bassin the axis cumulatively explain more inertia (Figure¬†6)."
  },
  {
    "objectID": "CA.html#exploration-of-the-ca",
    "href": "CA.html#exploration-of-the-ca",
    "title": "What is a CA and how to use it ?",
    "section": "Exploration of the CA",
    "text": "Exploration of the CA\n\n\nCode\nscatter(CA_ade4, posieig = \"none\")\n\n\nNULL\n\n\nCode\ns.label(CA_ade4$li, xax = 1, yax = 2, boxes = FALSE)\ns.label(CA_ade4$co, xax = 1, yax = 2, boxes = FALSE)\n\n\n\n\n\n\n\n\n\n\n\n\n(a) Sites and families together\n\n\n\n\n\n\n\n\n\n\n\n(b) Only sites\n\n\n\n\n\n\n\n\n\n\n\n\n\n(c) Only families\n\n\n\n\n\n\n\nFigure¬†7: CA projection with ade4 package\n\n\n\n\nThe first two axes explain \\(28.58%\\) of the total inertia, with approximately \\(14%\\) for each axis (Figure¬†6). Although this is not a large proportion, such values are not uncommon in ecological datasets. Axis 1 represents essentially a Bivalve gradient, with Bivalve contributing \\(69%\\), followed by Thaumaleidae (\\(12%\\)), Culicidae (\\(5.3%\\)), and Asellidae (\\(3.7%\\)) (Table¬†3). Axis 2 is mainly explained by Thaumaleidae (\\(79%\\)), with smaller yet notable contributions from Bivalve (\\(8.8%\\)) and Simuliidae (\\(3.5%\\)), as we can see on Table¬†3.\nThe high contribution of Bivalve may be explained by the fact that, unlike the other taxa (at the family level), it refers to a class and therefore represents a much broader group. This could account for the prevalence of various Bivalve individuals across some sampling stations (e.g.¬†between 62 and 700 individuals in ‚ÄúRuche‚Äù samples), and consequently, its dominant role in shaping Axis 1.\nThe \\(79%\\) contribution of Thaumaleidae likely reflects its high density in three stations (‚ÄúBassin‚Äù), a peculiar environment where only Thaumaleidae were found, while they were nearly absent from other sites. This group thus stretches Axis 2. ‚ÄúBassin‚Äù environnement was a cemented artificial pound which is hard to colonize for most organisms other than Thaumaleidae. Indeed, this taxon belongs to the Diptera order, very tolerant to pollution (Vivier, P. (1970)) and ubiquitous (I. (1927)).\nRegarding the correspondances between stations and species, the analysis shows - as expected - a proximity between Thaumaleidae and stations 28, 27 and 29, which are the stations it was almost exclusively sampled from. It could therefore be interesting to redo the analysis without those 3 stations to remove the high correlation between these ‚ÄúBassin‚Äù samples and Thaumaleidae.\n\n\nCode\nscatter(CA_ade4_sansbassin)\n\n\n\n\n\n\n\n\n\nCode\n#we can see things more clearly when we remove the bassin\n\n\n\n\nCode\n# Link samples position (CA$li = rows) on CA axis and the wetlands -------------\nCA_ade4_ligne_ZH &lt;- merge(CA_ade4$li, macroinv_red$ZH, by=0)\n\nCA_ade4_sansbassin_ligne_ZH &lt;- merge(CA_ade4_sansbassin$li, macroinv_red$ZH, by=0)\n\n# Link species position (CA$co = columns) on CA axis and the family / order ----\nCA_ade4_col_ZH &lt;- data.frame(CA_ade4$co) %&gt;% \n  mutate(\"Family\" = rownames(.)) %&gt;%\n  left_join(., classification, by = c(\"Family\" = \"X2\"))\n\nCA_ade4_sansbassin_col_ZH &lt;- data.frame(CA_ade4_sansbassin$co) %&gt;% \n  mutate(\"Family\" = rownames(.)) %&gt;%\n  left_join(., classification, by = c(\"Family\" = \"X2\"))\n\n\nPlot CA for the lines, dim 1 and 2, colour depends on the water source type :\n\n\nCode\nggplot(data = CA_ade4_ligne_ZH) +\n  aes(x = Axis1, y = Axis2, color = y) +\n  geom_point() +\n  geom_hline(yintercept = 0) +\n  geom_vline(xintercept = 0) +\n  xlab(\"**CA Axis 1**\") + \n  ylab(\"**CA Axis 2**\") +\n  labs(color = \"**Wetland**\") +\n  theme_bw() + \n  theme(axis.text.x = element_markdown(vjust = 1, hjust = 1, size = 11), \n        axis.text.y = element_markdown(size = 11),\n        axis.title = element_markdown(size = 13),\n        legend.title = element_markdown(size = 13), \n        legend.text = element_markdown(size = 13),\n        legend.position = \"top\")\n\nggplot(data = CA_ade4_sansbassin_ligne_ZH) +\n  aes(x = Axis1, y = Axis2, color = y) +\n  geom_point() +\n  geom_hline(yintercept = 0) +\n  geom_vline(xintercept = 0) +\n  xlab(\"**CA Axis 1**\") + \n  ylab(\"**CA Axis 2**\") +\n  theme_bw() + \n  theme(axis.text.x = element_markdown(vjust = 1, hjust = 1, size = 11), \n        axis.text.y = element_markdown(size = 11),\n        axis.title = element_markdown(size = 13),\n        legend.position = \"none\") \n\n\n\n\n\n\n\n\n\n\n\n\n(a) CA with Bassin samples\n\n\n\n\n\n\n\n\n\n\n\n\n\n(b) CA without Bassin samples\n\n\n\n\n\n\n\nFigure¬†8: Samples position on Axis 1 and 2 of the CA, depending on wetland\n\n\n\n\nTo help us interpret the graph, it can be useful to colour the points depending on an ecological variable.\nIn Figure¬†8, the points correspond to the projection of the samples onto the two axes of the CA. The position of each sampling point corresponds to the barycenter (average) of the coordinates of the species present at that site. We can see that the sites coming from the same wetland are more or less grouped together meaning that the groups of families present in each of them are similar. It is not surprising because the ecological conditions are usually similar in one type of wetland.\nPlot CA for the lines, dim 1 and 2, colour depends on the order :\n\n\nCode\nggplot(data = CA_ade4_col_ZH) +\n  aes(x = Comp1, y = Comp2, color = X1) +\n  geom_point() +\n  geom_hline(yintercept = 0) +\n  geom_vline(xintercept = 0) +\n  xlab(\"**CA Axis 1**\") + \n  ylab(\"**CA Axis 2**\") +\n  labs(color = \"**Order**\") +\n  theme_bw() + \n  theme(axis.text.x = element_markdown(vjust = 1, hjust = 1, size = 11), \n        axis.text.y = element_markdown(size = 11),\n        axis.title = element_markdown(size = 13),\n        legend.title = element_markdown(size = 13), \n        legend.text = element_markdown(size = 13),\n        legend.position = \"top\")\n\nggplot(data = CA_ade4_sansbassin_col_ZH) +\n  aes(x = Comp1, y = Comp2, color = X1) +\n  geom_point() +\n  geom_hline(yintercept = 0) +\n  geom_vline(xintercept = 0) +\n  xlab(\"**CA Axis 1**\") + \n  ylab(\"**CA Axis 2**\") +\n  theme_bw() + \n  theme(axis.text.x = element_markdown(vjust = 1, hjust = 1, size = 11), \n        axis.text.y = element_markdown(size = 11),\n        axis.title = element_markdown(size = 13),\n        legend.position = \"none\") \n\n\n\n\n\n\n\n\n\n\n\n\n(a) CA with Bassin samples\n\n\n\n\n\n\n\n\n\n\n\n\n\n(b) CA without Bassin samples\n\n\n\n\n\n\n\nFigure¬†9: Species position on Axis 1 and 2 of the CA, depending on wetland\n\n\n\n\nIn Figure¬†9, the points correspond to the projection of the families onto the two axes of the CA. The position of each family corresponds to the barycenter (average) of the coordinates of the sites where this species was present. (je crois que je comprends pas bien cette phrase)\n\nTable value\n\n\nCode\ntable.value(macroinv_red[,-c(1,2)][order(CA_ade4$li[,1]),\n                                   order(CA_ade4$co[,1])],\n            grid = T, csize = 0.5, clabel.col = 0.6)\ntable.value(macroinv_red[,-c(1,2)][order(CA_ade4_sansbassin$li[,1]),\n                                   order(CA_ade4_sansbassin$co[,1])], \n            grid = T, csize = 0.5, clabel.col = 0.6)\n\n\n\n\n\n\n\n\n\n\n\n\n(a) With Bassin samples\n\n\n\n\n\n\n\n\n\n\n\n\n\n(b) Without Bassin samples\n\n\n\n\n\n\n\nFigure¬†10: Data reorganized according to the CA results\n\n\n\n\nThis table value shows presence and abundance, each square representing the presence of a family in a site. The square size varies with abundance of the family. On the first table (Figure¬†10 (a)) - which includes the 3 bassin stations - we can see that the presence profils are highly impacted by the peculiar macroinvertebrate composition of said stations.\nWhen we get rid of these stations (Figure¬†10 (b)), it reveals presence patterns that couldn‚Äôt be seen. The most obvious is the bivalve presence in the first sations, which is likely due to their prevalence in ‚ÄúRuche‚Äù stations. The graph also shows that the presence of Culicidae is similar in all stations. For Physidae, we observe the same tendency although they are not present on the station ‚ÄúRieu_Querelle‚Äù. Some species are only present in a few, or even a single station. That is the case for Hydrobiidae which are only present in one sample, ‚ÄúFoot_2‚Äù. Finally, Baetidae‚Äôs presence is really high on the ‚ÄúVerdanson‚Äù Stations.\n\n\nSpecies distribution\nWe can look at how each species is distributed on the CA in the first two axis. It can help us visualize how much influence they have on the axis.\n\n\nCode\npar(mfrow = c(2, 2))\ns.distri(CA_ade4_sansbassin$li, macroinv_red[-c(27,28,29), 26], cell = 1.5, \n         sub = colnames(macroinv_red[26]), csub = 2) #rare family\ns.distri(CA_ade4_sansbassin$li, macroinv_red[-c(27,28,29), 36], cell = 1.5, \n         sub = colnames(macroinv_red[36]), csub = 2) #rare family\ns.distri(CA_ade4$li, macroinv_red[, 22], cell = 1.5,\n         sub = colnames(macroinv_red[22]), csub = 2) #common family\ns.distri(CA_ade4_sansbassin$li, macroinv_red[-c(27,28,29), 5], cell = 1.5, \n         sub = colnames(macroinv_red[5]), csub = 2) #family very abundant in 1 station\n\n\n\n\n\n\n\n\nFigure¬†11: Species distribution in samples on Axis 1 and 2 of the CA\n\n\n\n\n\nFigure¬†11 shows the distribution of the different families across the sites. Each point corresponds to the coordinates of a site. The points connected to each other correspond to all the points where the family is present. Their barycenter (average of the site positions) corresponds to the position of the family on the CA projections in Figure¬†9.\nThe barycenter corresponds to the average of the sampled environmental conditions where the family is present (i.e.¬†the central position of the ecological niche).\nThe size of the ellipse corresponds to the width of the ecological niche. A generalist family will tend to be present at the center of the CA with a large ellipse, while a more specialized family, present in a few site, will have a smaller ellipse (e.g., Thaunaleidae).\nHowever, for abundance data (as here), the barycenter is attracted to sites where the family is present in greater numbers (e.g., Bivalves in Ruche).\n\n\nSites distribution\nSimilarly, we can project the distribution of sites. Each point corresponds to the coordinates of a family. For a given site, the families present on that site are connected, and the barycenter of these families‚Äô coordinates form the site‚Äôs position in the CA (Figure¬†8)\nThe size of the ellipses can be interpreted as the alpha diversity (i.e., species richness) present at a site : the larger the ellipse, the more families it will contain."
  },
  {
    "objectID": "Penguins_chapter.html",
    "href": "Penguins_chapter.html",
    "title": "Exploration donn√©es sur les manchots",
    "section": "",
    "text": "Pourquoi manchot se traduit Penguins en anglais ?\n(O)&gt; ( ) W\n(O)&gt; ( ) W\n(O)&gt; ( ) W\n\nlibrary(tidyverse)\n\n‚îÄ‚îÄ Attaching core tidyverse packages ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ tidyverse 2.0.0 ‚îÄ‚îÄ\n‚úî dplyr     1.1.4     ‚úî readr     2.1.6\n‚úî forcats   1.0.0     ‚úî stringr   1.5.2\n‚úî ggplot2   4.0.1     ‚úî tibble    3.3.0\n‚úî lubridate 1.9.4     ‚úî tidyr     1.3.1\n‚úî purrr     1.1.0     \n‚îÄ‚îÄ Conflicts ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ tidyverse_conflicts() ‚îÄ‚îÄ\n‚úñ dplyr::filter() masks stats::filter()\n‚úñ dplyr::lag()    masks stats::lag()\n‚Ñπ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\nles magnifiques pingouins : (O)&gt; ( ) W\n\ndata &lt;- read.table(\"penguins_raw.csv\", sep = \",\" , header = TRUE)\n\nA citation Alston and Rick (2021)\n\nReferences\n\n\nAlston, Jesse M, and Jessica A Rick. 2021. ‚ÄúA Beginner‚Äôs Guide to Conducting Reproducible Research.‚Äù Bulletin of the Ecological Society of America 102 (2): 1‚Äì14."
  },
  {
    "objectID": "PCA.html",
    "href": "PCA.html",
    "title": "Principal Component Analysis",
    "section": "",
    "text": "Principal Component Analysis (PCA) is a dimension reduction technique widely used in data analysis and machine learning for simplifying complex datasets. It helps us understand high-dimensional data by reducing the number of variables we need to consider while keeping as much of the original information as possible.\nThe main goals are to reduce the number of variables into a new set of uncorrelated variables called principal components, to visualize high-dimensional data in 2D or 3D, to detect patterns, clusters and outliers, and to remove noise and redundant information. For example, if you get a data set with 10 correlated variables, PCA can reduce it to 2 or 3 principal components that explains 90% of the variance and makes it easier to visualize.\nThe PCA, values have to be quantitative, and organized in a n x p matrix with p observations and n variables\nWe will be using the R package FactoMineR (L√™, Josse, and Husson (2008))."
  },
  {
    "objectID": "PCA.html#eye-size-evolution-in-spider",
    "href": "PCA.html#eye-size-evolution-in-spider",
    "title": "Principal Component Analysis",
    "section": "Eye size evolution in spider",
    "text": "Eye size evolution in spider\nOur example is based on the article Chong (2024). This study examines how eye size evolves in spiders, which possess up to four pairs of eyes of variable sizes. Researchers analyzed 1,098 individuals from 39 species and supplemented their data with approximately 474 additional species.\nThe researchers measured four different eye pairs simultaneously. PCA reduces this 4-dimensional dataset into interpretable components, making it easier to visualize and understand patterns.\n\nspiders &lt;-read.delim(\"S2_WolffData-Curated.txt\",header = TRUE, stringsAsFactors = TRUE) #data importation\nsummary(spiders)\n\n                                 terminal              Family   \n Actinopodidae_Actinopus_insignis    :  1   Araneidae     : 24  \n Actinopodidae_Missulena_granulosa   :  1   Linyphiidae   : 21  \n Agelenidae_Agelena_labyrinthica     :  1   Theridiidae   : 20  \n Agelenidae_Barronopsis_barrowsi     :  1   Salticidae    : 17  \n Agelenidae_Draconarius_cangshanensis:  1   Tetragnathidae: 17  \n Agelenidae_Eratigena_atrica         :  1   Thomisidae    : 16  \n (Other)                             :467   (Other)       :358  \n       CW              AME              ALE              PME        \n Min.   : 0.240   Min.   :0.0000   Min.   :0.0000   Min.   :0.0000  \n 1st Qu.: 1.090   1st Qu.:0.0600   1st Qu.:0.0800   1st Qu.:0.0800  \n Median : 2.000   Median :0.1100   Median :0.1200   Median :0.1200  \n Mean   : 2.453   Mean   :0.1434   Mean   :0.1535   Mean   :0.1471  \n 3rd Qu.: 3.000   3rd Qu.:0.1700   3rd Qu.:0.1900   3rd Qu.:0.1800  \n Max.   :16.000   Max.   :0.9900   Max.   :0.8000   Max.   :0.7400  \n                                                                    \n      PLE            builder           orbweb          hanging      \n Min.   :0.0000   Min.   :0.0000   Min.   :0.0000   Min.   :0.0000  \n 1st Qu.:0.0856   1st Qu.:0.0000   1st Qu.:0.0000   1st Qu.:0.0000  \n Median :0.1300   Median :1.0000   Median :0.0000   Median :0.0000  \n Mean   :0.1556   Mean   :0.5074   Mean   :0.1163   Mean   :0.3784  \n 3rd Qu.:0.1900   3rd Qu.:1.0000   3rd Qu.:0.0000   3rd Qu.:1.0000  \n Max.   :0.7000   Max.   :1.0000   Max.   :1.0000   Max.   :1.0000  \n                                                                    \n     guild     visual.incl.static visual.pursuit       active      \n Min.   :1.0   Min.   :0.0000     Min.   :0.0000   Min.   :0.0000  \n 1st Qu.:3.0   1st Qu.:0.0000     1st Qu.:0.0000   1st Qu.:0.0000  \n Median :3.0   Median :0.0000     Median :0.0000   Median :0.0000  \n Mean   :3.6   Mean   :0.1332     Mean   :0.1015   Mean   :0.1831  \n 3rd Qu.:4.0   3rd Qu.:0.0000     3rd Qu.:0.0000   3rd Qu.:0.0000  \n Max.   :6.0   Max.   :1.0000     Max.   :1.0000   Max.   :1.0000  \n                                                   NA's   :107     \n    Largest          Smallest           rAME              rALE        \n Min.   :0.0200   Min.   :0.0000   Min.   :0.00000   Min.   :0.00000  \n 1st Qu.:0.1000   1st Qu.:0.0500   1st Qu.:0.04255   1st Qu.:0.05333  \n Median :0.1500   Median :0.0900   Median :0.05882   Median :0.06875  \n Mean   :0.1935   Mean   :0.1046   Mean   :0.06448   Mean   :0.07310  \n 3rd Qu.:0.2200   3rd Qu.:0.1300   3rd Qu.:0.07692   3rd Qu.:0.08602  \n Max.   :0.9900   Max.   :0.5000   Max.   :0.38462   Max.   :0.23077  \n                                                                      \n      rPME              rPLE            rLargest         rSmallest      \n Min.   :0.00000   Min.   :0.00000   Min.   :0.02273   Min.   :0.00000  \n 1st Qu.:0.05128   1st Qu.:0.05446   1st Qu.:0.06587   1st Qu.:0.03550  \n Median :0.06548   Median :0.06859   Median :0.08036   Median :0.04808  \n Mean   :0.06981   Mean   :0.07316   Mean   :0.09051   Mean   :0.04734  \n 3rd Qu.:0.08520   3rd Qu.:0.08696   3rd Qu.:0.10000   3rd Qu.:0.06015  \n Max.   :0.28794   Max.   :0.18750   Max.   :0.38462   Max.   :0.18235  \n                                                                        \n      rvar                var           \n Min.   :0.000e+00   Min.   :0.0000000  \n 1st Qu.:7.308e-05   1st Qu.:0.0001667  \n Median :1.587e-04   Median :0.0005667  \n Mean   :7.930e-04   Mean   :0.0036358  \n 3rd Qu.:4.614e-04   3rd Qu.:0.0020667  \n Max.   :2.152e-02   Max.   :0.0927333  \n                                        \n\nhead(spiders)\n\n                              terminal        Family    CW  AME  ALE  PME  PLE\n1     Actinopodidae_Actinopus_insignis Actinopodidae  5.40 0.16 0.40 0.24 0.32\n2    Actinopodidae_Missulena_granulosa Actinopodidae 11.00 0.25 0.25 0.20 0.25\n3      Agelenidae_Agelena_labyrinthica    Agelenidae  3.60 0.28 0.26 0.22 0.24\n4      Agelenidae_Barronopsis_barrowsi    Agelenidae  1.90 0.15 0.15 0.15 0.15\n5 Agelenidae_Draconarius_cangshanensis    Agelenidae  3.06 0.15 0.20 0.18 0.20\n6          Agelenidae_Eratigena_atrica    Agelenidae  4.10 0.26 0.27 0.23 0.24\n  builder orbweb hanging guild visual.incl.static visual.pursuit active Largest\n1       1      0       0     1                  0              0      0    0.40\n2       1      0       0     1                  0              0      0    0.25\n3       1      0       0     2                  0              0      0    0.28\n4       1      0       0     2                  0              0      0    0.15\n5       1      0       0     2                  0              0      0    0.20\n6       1      0       0     2                  0              0      0    0.27\n  Smallest       rAME       rALE       rPME       rPLE   rLargest  rSmallest\n1     0.16 0.02962963 0.07407407 0.04444444 0.05925926 0.07407407 0.02962963\n2     0.20 0.02272727 0.02272727 0.01818182 0.02272727 0.02272727 0.01818182\n3     0.22 0.07777778 0.07222222 0.06111111 0.06666667 0.07777778 0.06111111\n4     0.15 0.07894737 0.07894737 0.07894737 0.07894737 0.07894737 0.07894737\n5     0.15 0.04901961 0.06535948 0.05882353 0.06535948 0.06535948 0.04901961\n6     0.23 0.06341463 0.06585366 0.05609756 0.05853659 0.06585366 0.05609756\n         rvar         var\n1 3.65798e-04 0.010666667\n2 5.16529e-06 0.000625000\n3 5.14403e-05 0.000666667\n4 0.00000e+00 0.000000000\n5 5.96281e-05 0.000558333\n6 1.98295e-05 0.000333333\n\n\nThe raw data set is composed of 473 observations of 24 variables ."
  },
  {
    "objectID": "PCA.html#data-preprocessing",
    "href": "PCA.html#data-preprocessing",
    "title": "Principal Component Analysis",
    "section": "Data preprocessing",
    "text": "Data preprocessing\nWe don‚Äôt want to analyze all species so we just keep the families. Also we keep relative variables instead of absolute ones in order to be able to compare spider families with different sizes.\nDescription of the quantitative variables :\n\nrAME : relative Anterior Median Eyes (colored in yellow in Figure¬†1)\nrALE : relative Anterior Lateral Eyes (colored in red in Figure¬†1)\nrPME : relative Posterior Median Eyes (colored in blue in Figure¬†1)\nrPLE : relative Posterior Lateral Eyes (colored in green in Figure¬†1)\n\n\n\n\n\n\n\n\n\nFigure¬†1: Typical arrangements of spider eyes and their modification across spider families\n\n\n\n\n\n\nspiders &lt;- read.delim(\"S2_WolffData-Curated.txt\", header = TRUE, stringsAsFactors = TRUE)\nspiders &lt;- spiders[c(\"Family\",\"rAME\",\"rALE\",\"rPME\",\"rPLE\")] #selection of variables\nspiders &lt;- na.omit(spiders)\n\nThe PCA methodology begins by standardizing the data (center and scale variables)\n\nspiders$rALE &lt;- (spiders$rALE-mean(spiders$rALE))/sd(spiders$rALE)\nspiders$rAME &lt;- (spiders$rAME-mean(spiders$rAME))/sd(spiders$rAME)\nspiders$rPLE &lt;- (spiders$rPLE-mean(spiders$rPLE))/sd(spiders$rPLE)\nspiders$rPME &lt;- (spiders$rPME-mean(spiders$rPME))/sd(spiders$rPME)\nsummary(spiders) #all means are equal to 0\n\n            Family         rAME              rALE              rPME        \n Araneidae     : 24   Min.   :-1.2774   Min.   :-2.4207   Min.   :-2.3562  \n Linyphiidae   : 21   1st Qu.:-0.4344   1st Qu.:-0.6547   1st Qu.:-0.6253  \n Theridiidae   : 20   Median :-0.1120   Median :-0.1442   Median :-0.1462  \n Salticidae    : 17   Mean   : 0.0000   Mean   : 0.0000   Mean   : 0.0000  \n Tetragnathidae: 17   3rd Qu.: 0.2465   3rd Qu.: 0.4277   3rd Qu.: 0.5196  \n Thomisidae    : 16   Max.   : 6.3423   Max.   : 5.2207   Max.   : 7.3626  \n (Other)       :358                                                        \n      rPLE        \n Min.   :-2.5659  \n 1st Qu.:-0.6560  \n Median :-0.1602  \n Mean   : 0.0000  \n 3rd Qu.: 0.4839  \n Max.   : 4.0103"
  },
  {
    "objectID": "PCA.html#packages",
    "href": "PCA.html#packages",
    "title": "Principal Component Analysis",
    "section": "Packages",
    "text": "Packages\n\nlibrary(FactoMineR) #to realize the PCA\nlibrary(factoextra) #to visualize data\n\nLoading required package: ggplot2\n\n\nWelcome! Want to learn more? See two factoextra-related books at https://goo.gl/ve3WBa\n\nlibrary(ggplot2) #to plot the results"
  },
  {
    "objectID": "PCA.html#pca-analysis",
    "href": "PCA.html#pca-analysis",
    "title": "Principal Component Analysis",
    "section": "PCA Analysis",
    "text": "PCA Analysis\nWe use the PCA function from FactoMineR (L√™, Josse, and Husson (2008)). Through a linear algebra decomposition called the singular value decomposition (SVD), PCA identifies orthogonal directions in the data space‚Äîthe principal components‚Äîordered by the amount of variance they explain, with the first component capturing the maximum variance, the second capturing the next highest variance while being uncorrelated with the first, and so on.\n\nres.pca &lt;- PCA(spiders,\n               scale.unit = FALSE,    # already centered-reduced\n               quali.sup = 1, # \"Family\" is qualitative and illustrative\n               graph = FALSE)\n\nThe output of the PCA() is a list of several components :\n\n$eig (Eigenvalues)\n\nA matrix containing eigenvalues, percentage of variance, and cumulative percentage of variance for each principal component\n\n$var (Results for Variables)\n\n$var$coord: Coordinates (correlations) of variables with principal components\n$var$cor: Correlations between variables and dimensions (same as coord for standardized PCA)\n$var$cos2: Quality of representation - squared cosine values showing how well variables are represented on each dimension\n$var$contrib: Contributions of variables to each dimension (in percentage)\n\n$ind¬†(Results for Individuals/Observations)\n\n$ind$coord: Coordinates of individuals on the principal components\n$ind$cos2: Quality of representation of individuals on each dimension\n$ind$contrib: Contributions of individuals to each dimension\n$ind$dist: Squared distance of individuals to the origin\n\n$call¬†(Call Information)\n\nContains information about the function call\n\n$svd¬†(Singular Value Decomposition)\n\nContains the raw SVD components (if you want to have a deeper mathematical understanding of PCA)\n\n\n\nInterpretation tips :\n\nCoordinates indicate the position of a variable or individual on a dimension.\n\nFor Variables :\n\nCoordinates = correlation between the variable and the principal component, it measures the strength and direction of the relationship\n\nFor Individuals :\n\nCoordinates = position of the individual on the axis (score), it measures the relative position of the individual\n\n\nContributions indicate the weight of a variable or individual in the construction of the dimension.\n\nFor variables it measures the relative importance in constructing the axes\nFor individuals it measures the individual‚Äôs influence\n\nCos¬≤ values range from 0 to 1 and measures how much information about an element is preserved when we project it onto the principal components. When close to 1, it‚Äôs a good representation. Only well projected variables can be interpreted !"
  },
  {
    "objectID": "PCA.html#data-visualisation-and-interpretation",
    "href": "PCA.html#data-visualisation-and-interpretation",
    "title": "Principal Component Analysis",
    "section": "Data visualisation and interpretation",
    "text": "Data visualisation and interpretation\nTo visualize the results from the PCA, we can analyse the percentage of inertia explained by the principal components through the graph of inertia.\n\nres.pca$eig\n\n       eigenvalue percentage of variance cumulative percentage of variance\ncomp 1  2.4713096              61.913635                          61.91364\ncomp 2  0.9667296              24.219444                          86.13308\ncomp 3  0.3841774               9.624784                          95.75786\ncomp 4  0.1693267               4.242137                         100.00000\n\nfviz_eig(res.pca, ylim = c(0, 100), geom='bar', main='Percentage of inertia explained by axes')\n\nWarning in geom_bar(stat = \"identity\", fill = barfill, color = barcolor, :\nIgnoring empty aesthetic: `width`.\n\n\n\n\n\n\n\n\n\n\n\n(a) Table of eigenvalue and percentage of variance\n\n\n\n\n\n\nFigure¬†2: Percentage of inertia explained by axes\n\n\n\n\nThe two first axis explain more than 86% of the total variance so only two main components are selected for the analysis. The first dimension explains 61.9% of the variance while the second dimension explains 24.2% of the variance.\nOnly well projected variables and individuals can be interpreted. The sum of cos2 on Dim.1 and Dim.2 should be around 1.\n\nres.pca$var$cos2\n\n         Dim.1      Dim.2        Dim.3       Dim.4\nrAME 0.3649931 0.51987186 0.1099967401 0.005138294\nrALE 0.7625624 0.01511613 0.1922797407 0.030041770\nrPME 0.4674557 0.42280707 0.0824978808 0.027239329\nrPLE 0.8815342 0.01098269 0.0002169861 0.107266100\n\nhead(res.pca$ind$cos2)\n\n      Dim.1        Dim.2        Dim.3       Dim.4\n1 0.5718158 0.0092466126 4.162814e-01 0.002656177\n2 0.9693135 0.0286383335 8.082148e-05 0.001967393\n3 0.1528857 0.7973347485 4.610207e-03 0.045169352\n4 0.8723660 0.0002976105 9.319961e-02 0.034136780\n5 0.9176860 0.0008392141 5.859037e-02 0.022884419\n6 0.7853358 0.1852413189 3.558803e-03 0.025864108\n\nProjection quality of variables and individuals\n\nThe variables and individuals are well projected and can be interpreted.\nWe can also see how the variables contribute to the the two principal components.\n\nres.pca$var$contrib\n\n        Dim.1     Dim.2       Dim.3     Dim.4\nrAME 14.73799 53.662655 28.57122394  3.028128\nrALE 30.79137  1.560330 49.94391220 17.704384\nrPME 18.87531 43.643350 21.42850257 16.052833\nrPLE 35.59532  1.133665  0.05636129 63.214655\n\nfviz_pca_var(res.pca,\n             col.var = \"contrib\",\n             gradient.cols = c(\"blue\", \"yellow\", \"red\"),\n             repel = TRUE,\n             title = \"PCA variable correlation plot\") #show how relative eyed sizes are correlated\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\n‚Ñπ Please use `linewidth` instead.\n‚Ñπ The deprecated feature was likely used in the ggpubr package.\n  Please report the issue at &lt;https://github.com/kassambara/ggpubr/issues&gt;.\n\n\n\n\n\n\n\n\n\n\n\n(a) Table of contribution of variables to the axes\n\n\n\n\n\n\nFigure¬†3: Contribution of variables to the axes\n\n\n\n\nAll variables are contributing a lot to the first axis. However, lateral eyes (rALE and rPLE) explain the best the axis with contributions higher than 30%. On the other hand, medium eyes (rAME and rPME) explain the second axis with contributions respectively equal to 54% and 44%.\nWe can also plot the individuals into principal component space.\n\nfviz_pca_ind(res.pca,\n             geom.ind = \"point\",\n             label = \"none\",\n             habillage = spiders$Family, #to see if a family looks to contribute more to the axis\n             legend = \"none\",\n             repel = TRUE,\n             pointshape = 19)\n\n\n\n\n\n\n\nFigure¬†4: Scatterplot of individuals on the two main axes\n\n\n\n\n\nThe individuals are mainly distributed along the first axis which can be interpreted as a gradient of variation in lateral eye size. Individuals are also concentrated around zero which means that a majority of spiders has similar eye proportions.\nBecause there are 106 families of species, we will concentrate only on the first height most frequent family in order to have a clearer vision.\n\ntop_families &lt;- names(sort(table(spiders$Family), decreasing = TRUE))[1:8] #only frequent families to have a clearer graph\nspiders_sub &lt;- subset(spiders, Family %in% top_families)\nres.pca2 &lt;- PCA(spiders_sub, scale.unit = FALSE, quali.sup = 1, graph = FALSE)\nfviz_pca_ind(res.pca2, habillage = spiders_sub$Family, \n             #palette = \"Dark2\", \n             #repel = TRUE,\n             select.ind = list(name = NULL, cos2 = NULL, contrib = NULL),\n             label=\"none\"\n             )\n\n\n\n\n\n\n\nFigure¬†5: Scatterplot of individuals of the first height most frequent family on the two main axes\n\n\n\n\n\nGraph of contributions by individuals :\n\n#res.pca$ind$contrib\n\n#Axis 1\n\ntop10_ind &lt;- order(res.pca$ind$contrib[,1], decreasing = TRUE)[1:10] #the 10 individuals contributing the most to the first axis\n\ntop10_ind_fam &lt;- data.frame(\n  Individual = rownames(spiders)[top10_ind],\n  Family = spiders$Family[top10_ind],\n  Contribution = res.pca$ind$contrib[top10_ind, 1]\n) #families associated to the individuals contributing the most\n\ntop10_ind_fam\n\n    Individual        Family Contribution\n394        394   Theridiidae     4.001470\n321        321    Salticidae     3.920528\n317        317    Salticidae     2.994396\n324        324    Salticidae     2.670138\n313        313    Salticidae     2.336463\n314        314    Salticidae     2.251339\n20          20      Anapidae     2.048994\n316        316    Salticidae     2.026889\n280        280 Physoglenidae     1.891939\n315        315    Salticidae     1.884911\n\n#Axis 2\ntop10_ind_2 &lt;- order(res.pca$ind$contrib[,2], decreasing = TRUE)[1:10] #the 10 individuals contributing the most to the first axis\n\ntop10_ind_fam_2 &lt;- data.frame(\n  Individual = rownames(spiders)[top10_ind_2],\n  Family = spiders$Family[top10_ind_2],\n  Contribution = res.pca$ind$contrib[top10_ind_2, 2]\n) #families associated to the individuals contributing the most\n\ntop10_ind_fam_2\n\n    Individual            Family Contribution\n321        321        Salticidae     7.381965\n105        105        Deinopidae     6.570819\n315        315        Salticidae     5.036677\n316        316        Salticidae     4.664661\n317        317        Salticidae     4.484055\n314        314        Salticidae     4.393568\n326        326        Salticidae     3.579762\n313        313        Salticidae     2.859800\n104        104     Cycloctenidae     2.774391\n359        359 Symphytognathidae     2.429119\n\n# Axis 1\nhead(sort(res.pca$ind$contrib[,1], decreasing = TRUE), 10)\n\n     394      321      317      324      313      314       20      316 \n4.001470 3.920528 2.994396 2.670138 2.336463 2.251339 2.048994 2.026889 \n     280      315 \n1.891939 1.884911 \n\n# Axis 2\nhead(sort(res.pca$ind$contrib[,2], decreasing = TRUE), 10)\n\n     321      105      315      316      317      314      326      313 \n7.381965 6.570819 5.036677 4.664661 4.484055 4.393568 3.579762 2.859800 \n     104      359 \n2.774391 2.429119 \n\n\nWhen we visualise families, it looks like individuals from the Salticidae are atypical individuals because they are far on the first axis. In fact, looking at the contributions just above, those individuals have the highest contributions. For the first and the second axis, 7 out of 10 individuals are in the family Salticidae.\n\n\n\n\nFigure 2 ‚Äî Family Salticidae contributing the most to explained variance."
  },
  {
    "objectID": "PCA.html#conclusion",
    "href": "PCA.html#conclusion",
    "title": "Principal Component Analysis",
    "section": "Conclusion",
    "text": "Conclusion\nAccording to Figure¬†3, the first axis is positively correlated with the relative size of both the anterior and posterior lateral eyes (the red and green ones in Figure¬†1). For the second axis, there seems to be an antagonistic relationship between the anterior and posterior eyes.\nThis provides information about how eye sizes evolve together. However, from an ecological perspective, it would be interesting to study whether body size or spider activity is linked to eye size, as done in the original article Chong (2024). For example, we could test whether nocturnal spider species have larger eyes than diurnal ones.\nWe performed a PCA to visualize the relationships between variables. The goal was also to reduce the dimensionality of the dataset. However, since our dataset includes only four variables, it is not the most suitable example to demonstrate the advantages of factorial analysis."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Statistics to explore environmental questions",
    "section": "",
    "text": "This website is produced by the M2 MODE student during year 2025-2026 as part of their assignment in the Online Collaborative Resources course.\nThey were asked to produce collaboratively different illustrations on ecological data for different statistical and mathematical models.\nJust click on one of the three menus on top right side of this page to visit their work. They have used up to data version control workflows to produce this website using git Github, Pull Request, Code review. A set of good practices to help them producible research in the futur.\nThe website is fully generated using Continuous Integration (CI) based on Github Action."
  },
  {
    "objectID": "EDO_LOKTA_VOLTERA.html",
    "href": "EDO_LOKTA_VOLTERA.html",
    "title": "EDO pr√©dation",
    "section": "",
    "text": "## Packages\nsuppressPackageStartupMessages({\n  library(ggplot2)\n  library(dplyr)\n  library(tidyr)\n})\n\nMAIN QUESTION : How can we model the evolution of the dynamics between lynxes and hares ?\nINTRODUCTION :\nWhen having a dynamic system modeled by an Ordinary Differential Equation (ODE), we usually can‚Äôt find a mathematical solution. Thus, we have 2 options : a numerical approach and a qualitative one. Here, we will focus on the latter, that is to say qualitatively predict the evolution (in terms of behavior) of N(t) (the number of the population at time t), in particular asymptotically.\nLooking at lynx and hare pelts from the Hudson‚Äôs Bay Company‚Äôs (fur-collecting) trappers‚Äô hunts over a 90-year period, we see that the number of hare and lynx pelts is correlated. If we assume that the number of pelts collected is proportional to the total population, then we arrive at the conclusion that the hare and lynx population is correlated with a phase shift of a few years for the lynx (Elton & Nicholson, 1942).\nWhat is the intuition behind this? Lynxes need hares to survive, and so the lynx population can only grow if the hare population grows. There‚Äôs a time lag: when the lynx population is low, the hare population begins to grow. The lynxes then begin to have food again, and will then grow again and begin to massacre a large part of the hare population, only to run out of food. Then the cycle begins again.\n\n\n\n\n\n\n\n\n\nLogistic Prey-Predator model (in a limited environment) :\n\\[\n\\begin{cases}\n\\frac{dN}{dt}=r_1N(1-\\frac{N}{K})-b_1NP \\\\\n\\frac{dP}{dt}=-r_2P+b_2NP\n\\end{cases}\n\\]\nThe parameters are the following ones (they are all positive :) ) :\n\n\n\nParameters\nMeaning\n\n\n\n\n\\(r_{1}\\)\ngrowth rate of preys‚Äô population\n\n\n\\(r_{2}\\)\ndeath rate of predators‚Äô population\n\n\n\\(b_{1}\\)\npredation efficiency\n\n\n\\(b_{2}\\)\npredation yield\n\n\n\\({K}\\)\nbiotic capacity\n\n\n\nIn such conditions, we expect the populations dynamics to evolve in different ways according to parameters value and initials conditions (the size of both population). We can relatively easily assume that a big predator‚Äôs population paired with a high predation efficiency would lead prey‚Äôs population to go extinct and, shortly after, predator‚Äôs population is expected to follow the same dynamic. The question we may now ask ourselves is the following :\nHow would the system evolve according to parameters and initials conditions variation?\nThis is where qualitative analysis steps in. But first let‚Äôs do a little bit of math.\nEquilibrium points and isoclines\nLet‚Äôs start with a bit of vocabulary, in qualitative analysis we call equilibrium points all values of N for which the derivative is 0. Mathematically it‚Äôs expressed as following : \\[\n\\frac{dN}{dt}=0\\;\\Longleftrightarrow\\;f(N^{*})=0 \\\\\n\\]\n\\[\n\\text{with}\\;\\ \\frac{dN}{dt}=f(N)\n\\]\nFor equation system such as Lotka-Volterra it would be as following : \\[\n\\begin{cases} \\frac{dN_{1}}{dt}=0 \\\\ \\frac{dN_{2}}{dt}=0 \\end{cases} \\;\\Longleftrightarrow\\; \\begin{cases} f_{1}(N1^{*},N2^{*})=0 \\\\ f_{2}(N1^{*},N2^{*})=0 \\end{cases}\\\\\n\\]\n\\[\n\\text{with}\\;\\ \\begin{cases} \\frac{dN_{1}}{dt}=f_{1}(N1,N2) \\\\ \\frac{dN_{2}}{dt}=f_{2}(N1,N2) \\end{cases}\n\\] Those equilibrium points carry the information about the population sizes at which the system does not change. They can be either locally asymptotically stable (LAS), unstable (repeller) and in the case the system has more than one differential equation, saddle points may appear. Around LAS points, system will go towards the equilibrium, around repeller points, system will tend to move away from equilibrium. As for saddle points, depending on the area the system will go toward or away the equilibrium\nIn contrast to equilibrium points, where all derivative must be equal to zero, isoclines correspond to lines for which an equation of the system is individually equal to zero. Mathematically it‚Äôs expressed as following :\n\\[\n*\\text{Isoclines $N_{1}$ :} \\\\\n\\frac{dN_{1}}{dt}=0 \\;\\Longleftrightarrow\\; f_{1}(N1,N2)=0 \\\\\n\\]\n\\[\n\\text{Isoclines $N_{2}$ :}\\\\\n\\frac{dN_{2}}{dt}=0\\;\\Longleftrightarrow\\; f_{2}(N1,N2)=0 \\\\\n\\]\n\\[\n\\text{With}\\;\\begin{cases} \\frac{dN_{1}}{dt}=f_{1}(N1,N2) \\\\ \\frac{dN_{2}}{dt}=f_{2}(N1,N2) \\end{cases}\n\\]\nPlotting those isoclines on a phase plane allows us to identify some areas where the system may evolve in different ways. We can then examine the behavior of each population in the previously defined area , allowing to characterize the system overall behavior.\nAll of that is analytically calculable for some systems of differential equation system (including Lotka-Volterra logistic), but lazy as we are, we will focus on numerically approximate those solutions.\nNumerical approximation of equilibrium points and phase plane\nThe first step to numerical approximation of equilibrium points and drawing a phase plan is to define the function, following the syntaxe below. We also define some parameter values for our function.\n\nProiepred&lt;- function(t, y, parameters) {\n  # Here we define the initial condition from the vector\n  # The order of initial condition must be the following : y=c(prey,predator)\n  N &lt;- y[1]\n  P &lt;- y[2]\n  # Here we define the parameter from the vector\n  # The order must be the following : parameters=c(r1,r2,b1,b2,K)\n  r1 &lt;- parameters[1]\n  r2 &lt;- parameters[2]\n  b1 &lt;- parameters[3]\n  b2 &lt;- parameters[4]\n  K &lt;- parameters[5]\n  # On impl√©mente nos √©quations diff√©rentielles\n  dPop &lt;- numeric(2)\n  dPop[1] &lt;- r1*N*(1-N/K) - b1*N*P\n  dPop[2] &lt;- - r2*P + b2*N*P\n  list(dPop)\n}\n#On d√©finit nos param√®tres\nparameters1 &lt;- c(r1 = 0.5, r2 = 0.3, b1 = 0.02, b2 = 0.01,K=50)\n\nNow that the function is defined, we can use the package ‚ÄòphaseR‚Äô to draw a phase plan and draw the isocline using function flowField and nullclines.\n\n# Loading the library\nlibrary(phaseR)\n# Defining the limit for the studied window by flowField\nxlim &lt;- c(0, 50)\nylim &lt;- c(0, 50)  \n\n\n# Generating a phase plan for our equation \nflowField(\n  deriv = Proiepred,\n  xlim = xlim,\n  ylim = ylim,\n  parameters = parameters1,\n  system=\"two.dim\",\n  add=FALSE,\n  tend=100, xlab=\"Prey\", ylab=\"Predator\"\n  )\n# Generating the isoclines for our equation\nnullclines(Proiepred,xlim=c(-10,100),ylim=c(-10,100),parameters = parameters1, points = 500,add.legend = FALSE,add = TRUE)\ntrajectory(Proiepred,y0=c(40,40),tlim=c(0,100),parameters=parameters1)\n\n\n\n\n\n\n\n\n\nsimul_traj(N_0= 40,\n           P_0= 40,\n           t_end= 50,\n           pas= 1,\n           r1= 0.5,\n           b1= 0.02,\n           r2= 0.3,\n           b2= 0.01,\n           K= 50)\n\n\n\n\n\n\n\n\nFrom this graphic we could already interpret the isoclines and the equilibrium point. We can also use the function findEquilibrium to discuss those equilibrium points. We can approximate the equilibrium points from the graphic, looking at the intersect of isoclines.\n# Approximating the equilibrium point around the isocline intersection at (0,0)\neq0 &lt;- findEquilibrium(Proiepred, y0 = c(N=0, P=0), parameters = parameters1)\n# Approximating the equilibrium point around the isocline intersection at (30,15)\neq1 &lt;- findEquilibrium(Proiepred, y0 = c(N=30, P=15), parameters = parameters1)\n# Approximating the equilibrium point around the isocline intersection at (50,0)\neq2 &lt;- findEquilibrium(Proiepred, y0 = c(N=50, P=0), parameters = parameters1)\n\n\n$eq0_classification\n[1] \"Saddle\"\n\n$eq1_classification\n[1] \"Stable focus\"\n\n$eq2_classification\n[1] \"Saddle\"\n\n\nWe can now see that there is three equilibrium points for the Lotka-Volterra logistic function, two of them are saddle : (0,0) , (50, 0). The equilibrium points at (30,10) is a stable point, both population will tend to stabilize around the third equlibrium point as time goes on.\nWe may now question ourselves, what is the impact of initial parameters for our system?\nLet‚Äôs repeat the process but with different parameters values :)\n\n# Defining the limit for the studied window by flowField\nparameters2 &lt;- c(r1 = 0.5, r2 = 0.3, b1 = 0.02, b2 = 0.01,K=25)\nxlim &lt;- c(0, 50)  # N\nylim &lt;- c(0, 50)  # P\nflowField(\n  deriv = Proiepred,\n  xlim = xlim,\n  ylim = ylim,\n  parameters = parameters2,\n  system=\"two.dim\",\n  add=FALSE,\n  tend=100, xlab=\"Prey\", ylab=\"Predator\"\n  )\nnullclines(Proiepred,xlim=c(-10,100),ylim=c(-10,100),parameters = parameters2, points = 500,add.legend = FALSE,add = TRUE)\ntrajectory(Proiepred,y0=c(40,40),tlim=c(0,100),parameters=parameters2)\n\n\n\n\n\n\n\n\n\nsimul_traj(N_0= 40,\n           P_0= 40,\n           t_end= 50,\n           pas= 1,\n           r1= 0.5,\n           b1= 0.02,\n           r2= 0.3,\n           b2= 0.01,\n           K= 25)\n\n\n\n\n\n\n\n\nAfter changing the parameter values, it now appears that there is only two equilibrium points! But what about their stability?\n\neq0 &lt;- findEquilibrium(Proiepred, y0 = c(N=0, P=0), parameters = parameters2)\neq1 &lt;- findEquilibrium(Proiepred, y0 = c(N=25, P=0), parameters = parameters2)\n\n\n\n$eq0_classification\n[1] \"Saddle\"\n\n$eq1_classification\n[1] \"Stable node\"\n\n\nThe equilibrium point at (0,0) is still a saddle point, both population aren‚Äôt supposed to go extinct. But the second equilibrium point changed a lot, it is a saddle point, with predator going towards extinction.\nWhat truly change here?\nWhen going from the first set of parameters to the second we changed a ratio, we went from r2 &lt; K*b2 to r2&gt;K*b2. Phrased differently, we went from a situation where the natural loss in predator population was less than what is gained if the prey population is at the maximum of environmental capacity to a situation where the natural loss exceeds the gain.\nWhen doing numerical approximation of a system, it is important to consider the variation induced by the parameters values. In order to do so, the best way remain the analytic approach.\nBonus : We lied !! In the end, for those who are interested, we are going to describe the analytic approach.\nTo do so, we will introduce the Jacobian Matrix (Fun Fact : it was named after Carl Gustav Jacobi, an important 19th century mathematician who added huge contributions to the field of linear algebra).\nThis matrix is composed of the first-order partial derivatives of a multivariable function. The formula for the Jacobian Matrix is the following :\n\\[\n\\begin{equation}\nJac(N_1, N_2) =\n\\begin{pmatrix}\n\\frac{\\partial f_1}{\\partial N_1} & \\frac{\\partial f_1}{\\partial N_2} \\\\\n\\frac{\\partial f_2}{\\partial N_1} & \\frac{\\partial f_2}{\\partial N_2}\n\\end{pmatrix}\n\\end{equation}\n\\]\nIn contrast with the previous part where we had 2 equations, here we have 4 terms in the matrix, in particular 4 partial derivatives. After finding the fixed points, by resolving the equations detailed in the first part, now we can easily replace the values of \\(N1^{*}\\) and \\(N2^{*}\\) in the Jacobian Matrix and then study the stability of the fixed points.\nIn the analytic approach, the stability of a fixed point (\\(N1^{*}\\), \\(N2^{*}\\)) is related to the signs of the real parts of the eigenvalues ‚Äã‚Äãof \\(Jac(N1^{*},N2^{*})\\):\n\n(\\(N1^{*}\\), \\(N2^{*}\\)) is locally asymptotically stable (LAS) if all its eigenvalues are (with real parts) &lt;0\n(\\(N1^{*}\\), \\(N2^{*}\\)) is unstable otherwise, including:\nrepulsor if all eigenvalues ‚Äã‚Äãare (with real parts) &gt;0\nsaddle point if some eigenvalues are (with real parts) &lt;0 and the others (with real parts) &gt;0.\n\nBecause the matrix \\(Jac(N1^{*},N2^{*})\\) is of dimension 2, it has exactly two eigenvalues and we can calculate the Trace (sum of the eigenvalues ) and the Determinant (product of the eigenvalues) of the Jacobian Matrix which will help us to determine the stability of the fixed points. If a Jacobian Matrix is defined as followed :\n\\[\n\\begin{equation}\nJac(N_1^*, N_2^*) =\n\\begin{pmatrix}\na & b \\\\\nc & d\n\\end{pmatrix}\n\\end{equation}\n\\]\nThe Trace and the Determinant correspond to : ùëáùëüùëéùëêùëí = ùëé + ùëë and ùê∑ùëíùë° = ùëéùëë ‚àí ùëèùëê.\nIn particular,\n\n(\\(N1^{*}\\), \\(N2^{*}\\)) is locally asymptotically stable (LAS) if Trace &lt;0 and Det &gt;0.\n(\\(N1^{*}\\), \\(N2^{*}\\)) is repulsor if Trace &gt; 0 and Det &gt;0.\n(\\(N1^{*}\\), \\(N2^{*}\\)) is saddle point if Det &lt; 0 (whatever the Trace).\n\nLet‚Äôs apply the analytic approach to the logistic Prey-Predator Model, shall we ?\nOur system admits 3 fixed points : (\\({0}\\),\\({0}\\)), (\\({K}\\),\\({0}\\)) and (\\(N^{*}\\), \\(P^{*}\\)) where : \\[\n(N^*, P^*) =\n\\left(\n\\frac{r_2}{b_2},\\;\n\\frac{r_1}{b_1} \\left( 1 - \\frac{r_2}{b_2 K} \\right)\n\\right)\n\\]\nAfter calculating the partial derivatives in the Jacobian Matrix :\n\\[\n\\begin{equation}\nJac(N,P) =\n\\begin{pmatrix}\n(r_1(1 - \\frac{N}{K})-b_1P)-r_1\\frac{N}{K}  & -b_1N \\\\\nb_2P & -r_2 + b_2N\n\\end{pmatrix}\n\\end{equation}\n\\]\nNow we can obtain a Jacobian Matrix for each fixed point :\n\\[\n\\begin{equation}\nJac(0,0) =\n\\begin{pmatrix}\nr_1 & 0 \\\\\n0 & -r_2\n\\end{pmatrix}\n\\end{equation}\n\\]\nFor the first one, we can easily determine the eigenvalues because it is a diagonal matrix, so the eigenvalues are on the diagonal. \\({r_1}\\) &gt; 0 and \\({-r_2}\\) &lt;0, so (\\({0}\\),\\({0}\\)) is a saddle point.\n\\[\n\\begin{equation}\nJac(K,0) =\n\\begin{pmatrix}\n-r_1 & -b_1K \\\\\n0 & -r_2 + b_2K\n\\end{pmatrix}\n\\end{equation}\n\\]\nHere, we have a triangular matrix, so the eigenvalues are also on the diagonal. \\({-r_1}\\) &lt; 0 and \\({-r_2 + b_2K}\\) &lt; 0 if \\({r_2}\\) &gt; \\({b_2K}\\) which makes (\\({K}\\),\\({0}\\)) a LAS and a saddle point otherwise.\nFor the last fixed point (\\(N^{*}\\), \\(P^{*}\\)), \\(r_1(1 - \\frac{N^{*}}{K})-b_1P^{*}\\) = 0 (see the definition of the isocline \\(N\\) : \\(\\frac{dN}{dt} = 0\\) ) because \\({N^{*}}\\) is different from 0.\nThus, the last Jacobian matrix is written as :\n\\[\n\\begin{equation}\nJac(N^{*},P^{*}) =\n\\begin{pmatrix}\n-r_1\\frac{N^{*}}{K} & -b_1N^{*} \\\\\nb_2P & 0\n\\end{pmatrix}\n\\end{equation}\n\\]\nFinally, when calculating the trace and the determinant (see the definitions above), we find a negative trace and a positive determinant for \\(N^{*}\\) and \\(P^{*}\\) positive. So, (\\(N^{*}\\), \\(P^{*}\\)) is a LAS when it interests us.\nCONCLUSION :\nThrough this work, we presented a way to qualitatively analyse the dynamics of a Logistic Prey-Predator Model. Depending on the values of the parameters of the ODE, the nature of the fixed points changes and so the trajectories of the size of the populations do. We identified 3 main situations : the total extinction of both populations (unstable because the lower presence of prey allows the population to grow), survival of prey only at their capacity limit K (stable or unstable depending on the capacity of the predators to persist thanks to the potential gains) and the stable coexistence of the 2 species that only exists if predators can maintain themselves. To summarize, the dynamics of the model illustrate both the mutual dependence and ecological regulation between prey and predator.\nAs a doorway, we could also be interested in qualitatively predicting the solution of a system of more than 2 equations that could model more complex phenomenon (like epidemiological models SIR or SEIR). The definitions of LAS and unstable (repulsor and saddle points) would remain valid but the calculations would be more complicated. Also, we would look at the Routh-Hurwitz criteria in addition of the trace and the determinant and the representation of isoclines and field portraits would be less obvious."
  },
  {
    "objectID": "Linear_Model_2.html",
    "href": "Linear_Model_2.html",
    "title": "GENERALIZED LINEAR MIXED MODEL",
    "section": "",
    "text": "We present here a reminder sheet on Generalized Linear Mixed Models (GLMMs) and its specific features. Its use will be illustrated through a study applied on badgers from Walker et al. (2009) .\n\n\n\n\n\n\n\nNote\n\n\n\nThe concepts covered in this reminder sheet are taken from our Master‚Äôs lectures and tutorials, written by Outreman (n.d.) and taught by Masson (n.d.) .\n\n\n\n\nGeneral Linear Models are traditionally used to describe the relationship between a continuous response (\\(Y\\)) and one or more explanatory variables (\\(X_{1}\\),\\(X_{2}\\)‚Ä¶\\(X_{p}\\)). They rely on three main assumptions : independence of residuals, normality of residuals and homogeneity of variances (homoscedasticity). However, in many fields (ecology, epidemiology, etc), the response variable (\\(Y\\)) is discrete, for example it can take the form of counts, binary outcomes (presence/absence), and so on.\nApplying a General Linear Model to this type of data is problematic for two main reasons:\n\nFor discrete responses, the variance of \\(Y\\) typically depends on its mean-variance relationship. As a result, the variance is not constant across observations, directly invalidating the assumption of homogeneity.\nFitting a General Linear Model to count data also leads to negative predicted values and non-normal residuals, which are not interpretable given the nature of the response variable.\n\nIn short, General Linear Models are not well-suited for discrete responses. Hence, we need specific tools to analyse discrete response data. These are Generalized Linear Models (GLMs).\n\n\n\nA Generalized Linear Model extends the classical linear model through three steps:\n\nAssumption of the distribution : the distribution of the response variable \\(Y_{i}\\) is assumed to belong to a certain distribution law (e.g.¬†Poisson, Binomial, Gamma)\nSpecification of the systematic part : This is the linear function of the explanatory variables (the linear predictor called \\(\\eta\\))\nThe link function (\\(g\\)) : This defines the relationship between the expected mean value of \\(Y_{i}\\) and the systematic part \\(\\eta\\).\n\nA Generalized Linear Model can be written as : \\[g(\\mu_{y})= \\alpha+ \\beta_{1}.X{i1}+ \\beta_{2}.X{i2}+\\beta_{3}.X{i3}+...\\beta_{p}.X{ip} = \\eta \\]\nThe linear predictor \\(\\eta\\), emerges from the linear model as a sum of the terms for each of the \\(p\\) parameters. This is not a direct value of \\(Y\\). The value of \\(\\eta\\) is obtained by transforming the value of \\(Y\\) by the link function, and the predicted value of \\(Y\\) is obtained by applying the inverse link function to \\(\\eta\\).\n\n\n\nDepending on the sampling design or the experimental setup, independence of residuals is not respected as some statistical units are related. To account for this dependence structure, we can include random effects in the model.\n\nThe resulting model, called Generalized Linear Mixed Model (GLMM) extends the Generalized Linear Model by adding these random effects alongside the fixed effects. Therefore, GLMMs allow us to model both the relationship between predictors, responses and the non-independence in the data."
  },
  {
    "objectID": "Linear_Model_2.html#generalities",
    "href": "Linear_Model_2.html#generalities",
    "title": "GENERALIZED LINEAR MIXED MODEL",
    "section": "",
    "text": "General Linear Models are traditionally used to describe the relationship between a continuous response (\\(Y\\)) and one or more explanatory variables (\\(X_{1}\\),\\(X_{2}\\)‚Ä¶\\(X_{p}\\)). They rely on three main assumptions : independence of residuals, normality of residuals and homogeneity of variances (homoscedasticity). However, in many fields (ecology, epidemiology, etc), the response variable (\\(Y\\)) is discrete, for example it can take the form of counts, binary outcomes (presence/absence), and so on.\nApplying a General Linear Model to this type of data is problematic for two main reasons:\n\nFor discrete responses, the variance of \\(Y\\) typically depends on its mean-variance relationship. As a result, the variance is not constant across observations, directly invalidating the assumption of homogeneity.\nFitting a General Linear Model to count data also leads to negative predicted values and non-normal residuals, which are not interpretable given the nature of the response variable.\n\nIn short, General Linear Models are not well-suited for discrete responses. Hence, we need specific tools to analyse discrete response data. These are Generalized Linear Models (GLMs)."
  },
  {
    "objectID": "Linear_Model_2.html#structure-of-a-generalized-linear-model",
    "href": "Linear_Model_2.html#structure-of-a-generalized-linear-model",
    "title": "GENERALIZED LINEAR MIXED MODEL",
    "section": "",
    "text": "A Generalized Linear Model extends the classical linear model through three steps:\n\nAssumption of the distribution : the distribution of the response variable \\(Y_{i}\\) is assumed to belong to a certain distribution law (e.g.¬†Poisson, Binomial, Gamma)\nSpecification of the systematic part : This is the linear function of the explanatory variables (the linear predictor called \\(\\eta\\))\nThe link function (\\(g\\)) : This defines the relationship between the expected mean value of \\(Y_{i}\\) and the systematic part \\(\\eta\\).\n\nA Generalized Linear Model can be written as : \\[g(\\mu_{y})= \\alpha+ \\beta_{1}.X{i1}+ \\beta_{2}.X{i2}+\\beta_{3}.X{i3}+...\\beta_{p}.X{ip} = \\eta \\]\nThe linear predictor \\(\\eta\\), emerges from the linear model as a sum of the terms for each of the \\(p\\) parameters. This is not a direct value of \\(Y\\). The value of \\(\\eta\\) is obtained by transforming the value of \\(Y\\) by the link function, and the predicted value of \\(Y\\) is obtained by applying the inverse link function to \\(\\eta\\)."
  },
  {
    "objectID": "Linear_Model_2.html#from-generalized-linear-model-to-generalized-linear-mixed-model",
    "href": "Linear_Model_2.html#from-generalized-linear-model-to-generalized-linear-mixed-model",
    "title": "GENERALIZED LINEAR MIXED MODEL",
    "section": "",
    "text": "Depending on the sampling design or the experimental setup, independence of residuals is not respected as some statistical units are related. To account for this dependence structure, we can include random effects in the model.\n\nThe resulting model, called Generalized Linear Mixed Model (GLMM) extends the Generalized Linear Model by adding these random effects alongside the fixed effects. Therefore, GLMMs allow us to model both the relationship between predictors, responses and the non-independence in the data."
  },
  {
    "objectID": "Linear_Model_2.html#data-import",
    "href": "Linear_Model_2.html#data-import",
    "title": "GENERALIZED LINEAR MIXED MODEL",
    "section": "Data import",
    "text": "Data import\n\n\nCode\n# library import\nlibrary(corrplot)\nlibrary(lme4)\nlibrary(rsq)\n\n\nLet‚Äôs import the dataset and tansform some variables into factors for the analysis. We also check for missing values.\n\n\nCode\n# Dataset import\ndataBadger &lt;- read.table(\"Badger.txt\", dec=\".\", header = TRUE)\n\n# Change categorical variables to factors\ndataBadger$season&lt;-as.factor(dataBadger$season)\ndataBadger$accessible_feed_store_present&lt;-as.factor(dataBadger$accessible_feed_store_present)\ndataBadger$accessible_cattle_house_present&lt;-as.factor(dataBadger$accessible_cattle_house_present)\ndataBadger$accessible_feed_present&lt;-as.factor(dataBadger$accessible_feed_present)\ndataBadger$grass_silage&lt;-as.factor(dataBadger$grass_silage)\ndataBadger$cereal_silage&lt;-as.factor(dataBadger$cereal_silage)\ndataBadger$hay_straw&lt;-as.factor(dataBadger$hay_straw)\ndataBadger$cereal_grains&lt;-as.factor(dataBadger$cereal_grains)\ndataBadger$concentrates&lt;-as.factor(dataBadger$concentrates)\ndataBadger$sugar_beet&lt;-as.factor(dataBadger$sugar_beet)\ndataBadger$molasses&lt;-as.factor(dataBadger$molasses)\n\n# Check for presence of missing values\ncolSums(is.na(dataBadger))\n\n\n                             ID                            year \n                              0                               0 \n                         season                       farm_code \n                              0                               0 \n                         survey                   signs_in_yard \n                              0                               0 \n              N_setts_in_fields                     N_buildings \n                              0                               0 \n     N_cattle_in_buildings_yard   accessible_feed_store_present \n                              0                               0 \naccessible_cattle_house_present         accessible_feed_present \n                              0                               0 \n                   grass_silage                   cereal_silage \n                              0                               0 \n                      hay_straw                   cereal_grains \n                              0                               0 \n                   concentrates                      sugar_beet \n                              0                               0 \n                       molasses \n                              0 \n\n\nThere are no missing value in the dataset."
  },
  {
    "objectID": "Linear_Model_2.html#data-exploration",
    "href": "Linear_Model_2.html#data-exploration",
    "title": "GENERALIZED LINEAR MIXED MODEL",
    "section": "Data exploration",
    "text": "Data exploration\nBefore carrying out any statistical modeling, it is essential to perform a thorough data exploration. This step helps identify potential issues such as outliers, collinearity, or imbalanced distributions that could bias the results or invalidate model assumptions.\n\n1. Outliers and Distribution of \\(Y\\)\nSince \\(Y\\) is a binary variable, it does not have a continuous distribution. Instead, we inspect the frequency of each category (0 and 1) to check for imbalance in the response variable.\n\n\nCode\n# Number of 0 and 1 in Y\ntable(dataBadger$signs_in_yard)\n\n\n\n  0   1 \n233  45 \n\n\n\n\n2. Outliers and distributions of quantitative predictors (\\(X\\))\nFor continuous independent variables, it is important to:\n\nDetect potential outliers (e.g., extreme or erroneous values)\nVisualize the shape of the distribution (e.g., normal, skewed, multimodal)\nAssess whether transformations (e.g., log, square root) might be needed before modeling\n\nThe following visualizations help achieve this:\n\nCleveland dot plots: to identify potential outliers\nHistograms: to visualize the overall distribution\nQ-Q plots: to assess normality assumptions\n\n\n\nCode\npar(mfrow=c(3,3))\n\n# Number of badger setts on farm\n# Cleveland plot\ndotchart(dataBadger$N_setts_in_fields,pch=16,col='aquamarine3',xlab='Number of setts')\n# Histogram\nhist(dataBadger$N_setts_in_fields,col='aquamarine3',xlab=\"Number of setts\",main=\"\")\n# Quantile-Quantile plot\nqqnorm(dataBadger$N_setts_in_fields,pch=16,col='aquamarine3',xlab='')\nqqline(dataBadger$N_setts_in_fields,col='pink1')\n\n# Number of buildings on farm\n# Cleveland plot\ndotchart(dataBadger$N_buildings,pch=16,col='aquamarine3',xlab='Number of buildings')\n# Histogram\nhist(dataBadger$N_buildings,col='aquamarine3',xlab=\"Number of buildings\",main=\"\")\n# Quantile-Quantile plot\nqqnorm(dataBadger$N_buildings,pch=16,col='aquamarine3',xlab='')\nqqline(dataBadger$N_buildings,col='pink1')\n\n# Number of cattle housed in buildings on farm\n# Cleveland plot\ndotchart(dataBadger$N_cattle_in_buildings_yard,pch=16,col='aquamarine3',xlab='Number of cattle')\n# Histogram\nhist(dataBadger$N_cattle_in_buildings_yard,col='aquamarine3',xlab=\"Number of cattle\",main=\"\")\n# Quantile-Quantile plot\nqqnorm(dataBadger$N_cattle_in_buildings_yard,pch=16,col='aquamarine3',xlab='')\nqqline(dataBadger$N_cattle_in_buildings_yard,col='pink1')\n\n\n\n\n\n\n\n\n\nThe exploratory plots show that all three quantitative variables (number of setts, number of buildings, and number of cattle) display right-skewed distributions, with most farms having relatively low values and a few having much higher ones. No extreme or abnormal outliers are clearly visible, although some high values are present, especially for the number of cattle. The Q-Q plots confirm that none of these variables follow a normal distribution.\n\n\n2. Categorical variables: number of levels and individuals per level\nFor categorical variables (factors), it is important to examine the number of levels (categories) and the number of observations in each level. This helps identify potential issues such as:\n\nLevels with very few observations (which may cause estimation problems in statistical models)\nHighly unbalanced distributions between categories\nUnexpected or erroneous category labels\n\nThe following code summarizes the distribution of individuals across levels for each categorical predictor:\n\n\nCode\n# Factor season\nsummary(dataBadger$season)\n\n\n 1  2  3  4 \n70 67 69 72 \n\n\nCode\n# Factor accessible_feed_store_present\nsummary(dataBadger$accessible_feed_store_present)\n\n\n  0   1 \n 49 229 \n\n\nCode\n# Factor accessible_cattle_house_present \nsummary(dataBadger$accessible_cattle_house_present )\n\n\n  0   1 \n 91 187 \n\n\nCode\n# Factor feed\nsummary(dataBadger$accessible_feed_present)\n\n\n  0   1 \n 47 231 \n\n\nCode\n# Factor grass\nsummary(dataBadger$grass_silage)\n\n\n  0   1 \n171 107 \n\n\nCode\n# Factor cereal_silage\nsummary(dataBadger$cereal_silage)\n\n\n  0   1 \n199  79 \n\n\nCode\n# Factor straw\nsummary(dataBadger$hay_straw)\n\n\n  0   1 \n107 171 \n\n\nCode\n# Factor grains\nsummary(dataBadger$cereal_grains)\n\n\n  0   1 \n165 113 \n\n\nCode\n# Factor concentrates\nsummary(dataBadger$concentrates)\n\n\n  0   1 \n142 136 \n\n\nCode\n# Factor sugar_beet\nsummary(dataBadger$sugar_beet)\n\n\n  0   1 \n255  23 \n\n\nMost factors are binary, with varying levels of balance between categories. For example, variables such as accessible_feed_store_present, accessible_cattle_house_present, and accessible_feed_present display moderate imbalance, with one category being more frequent than the other. The season variable has four well-represented levels, each containing a similar number of observations, which ensures adequate variability for analysis. Overall, the categorical predictors appear suitable for modelling.\n\n\n3. Analysis of the potential relationships between \\(Y\\) and the \\(X\\)s\nTo gain preliminary insight into the relationships between the response variable (signs_in_yard) and the predictors, both quantitative and categorical variables were explored graphically.\nScatterplots were used to visualize how badger activity varies with continuous predictors such as the number of setts, number of buildings and number of cattle housed. These visual analyses provide a first impression of potential patterns, dependencies, or nonlinear relationships that may influence badger activity on farms.\n\n\nCode\npar(mfrow=c(1,3))\n# Number of setts\nplot(dataBadger$signs_in_yard~dataBadger$N_setts_in_fields,pch=16,col='aquamarine3',xlab='Number of setts',ylab='Presence of a sign of badger activity')\n\n# Number of buildings\nplot(dataBadger$signs_in_yard~dataBadger$N_buildings,pch=16,col='aquamarine3',xlab='Number of buildings',ylab='Presence of a sign of badger activity')\n\n# Number of cattle housed in buildings\nplot(dataBadger$signs_in_yard~dataBadger$N_cattle_in_buildings_yard,pch=16,col='aquamarine3',xlab='Number of cattle',ylab='Presence of a sign of badger activity')\n\n\n\n\n\n\n\n\n\nCode\npar(mfrow=c(2,5))\n# Factor season\nmosaicplot(dataBadger$signs_in_yard~dataBadger$season\n           ,color=c('aquamarine3','pink1')\n           ,main=\"Activity & Season\")\n\n# Factor feed store\nmosaicplot(dataBadger$signs_in_yard~dataBadger$accessible_feed_store_present\n           ,color=c('aquamarine3','pink1')\n           ,main=\"Activity & Feed store\")\n\n# Factor accessible_cattle_house_present \nmosaicplot(dataBadger$signs_in_yard~dataBadger$accessible_cattle_house_present\n           ,color=c('aquamarine3','pink1')\n           ,main=\"Activity & cattle house\")\n\n# Factor feed\nmosaicplot(dataBadger$signs_in_yard~dataBadger$accessible_feed_present\n           ,color=c('aquamarine3','pink1')\n           ,main=\"Activity & feed\")\n# Factor grass\nmosaicplot(dataBadger$signs_in_yard~dataBadger$grass_silage\n           ,color=c('aquamarine3','pink1')\n           ,main=\"Activity & Grass\")\n# Factor cereal_silage\nmosaicplot(dataBadger$signs_in_yard~dataBadger$cereal_silage\n           ,color=c('aquamarine3','pink1')\n           ,main=\"Activity & Cereal silage\")\n# Factor straw\nmosaicplot(dataBadger$signs_in_yard~dataBadger$hay_straw\n           ,color=c('aquamarine3','pink1')\n           ,main=\"Activity & Straw\")\n# Factor grains\nmosaicplot(dataBadger$signs_in_yard~dataBadger$cereal_grains\n           ,color=c('aquamarine3','pink1')\n           ,main=\"Activity & Grains\")\n# Factor concentrates\nmosaicplot(dataBadger$signs_in_yard~dataBadger$concentrates\n           ,color=c('aquamarine3','pink1')\n           ,main=\"Activity & Concentrates\")\n# Factor sugar_beet\nmosaicplot(dataBadger$signs_in_yard~dataBadger$sugar_beet\n           ,color=c('aquamarine3','pink1')\n           ,main=\"Activity & Sugar beet\")\n\n\n\n\n\n\n\n\n\nThese visual analyses provide an initial understanding of how badger activity may relate on farm characteristics. Based on the scatterplots, there appears to be no clear linear relationship between badger activity and the number of setts, buildings, or cattle, although activity tends to be slightly more frequent on farms with more setts or larger number of cattle. The mosaic plots complement this by revealing possible associations between activity and certain categorical management factors, such as the presence of feed stores, cattle housing, or specific feeding practices.\n\n\n4. Analysis of possible interactions between both independent variables\nHere, given the large number of predictors, we choose not to include interactions in modelling.\n\n\n5. Check for collinearity between predictors (\\(X\\)s)\nTo avoid multicollinearity issues during modelling, the relationships among predictor variables were examined. This step includes:\n\nEvaluating correlations between the quantitative variables\nAssessing potential overlap between categorical factors\nExploring whether categorical predictors influence quantitative ones through boxplots\n\nGiven the large number of predictors, only key results are summarized below.\n\n\nCode\n# We represent plot for each continuous covariate pairs\nplot(dataBadger[7:9],pch=16,col='aquamarine3')\n\n\n\n\n\n\n\n\n\nCode\n# We calculate correlation between each pair of covariate\nM&lt;-cor(dataBadger[7:9])\ncorrplot.mixed(M,upper=\"square\",lower.col=\"black\", tl.col=\"black\",cl.cex = 0.8,tl.cex = 0.7,number.cex =0.8)\n\n\n\n\n\n\n\n\n\nA moderate positive correlation (r ‚âà 0.52) is observed between the number of buildings and the number of cattle in the yard, suggesting a slight interdependence between these two variables. In contrast, the number of setts in fields shows almost no correlation with the others (r close to 0). Overall, no strong collinearity is detected, allowing these predictors to be retained for further modelling without major redundancy concerns.\nWe could also check collinearity between categorical independent variables and between between categorical and quantitative independent variables (mostly using boxplots), but we don‚Äôt give the details here."
  },
  {
    "objectID": "Linear_Model_2.html#building-the-model",
    "href": "Linear_Model_2.html#building-the-model",
    "title": "GENERALIZED LINEAR MIXED MODEL",
    "section": "Building the model",
    "text": "Building the model\nThe best model is identified using a backward selection procedure. This model selection method is based on the Akaike Information Criterion (AIC), which allows to take into account both the goodness of fit and the complexity of the model. Starting with the full model, the function drop1 is used to evaluate each predictor‚Äôs contribution to the AIC. The predictor whose removal leads to the smallest AIC is then removed and the model is refitted without this variable. The selection stops when the candidate model has the lowest AIC.\n\n\nCode\nmod&lt;-glmer(signs_in_yard~N_setts_in_fields\n              + N_buildings\n              + N_cattle_in_buildings_yard\n              + season\n              + accessible_feed_store_present\n              + accessible_cattle_house_present\n              + accessible_feed_present\n              + grass_silage\n              + cereal_silage\n              + hay_straw\n              + cereal_grains\n              + concentrates\n              + sugar_beet\n              + (1|farm_code)  #random effect\n              ,data=dataBadger\n              ,family=binomial) #for the binomial distribution\n\n\nWarning in checkConv(attr(opt, \"derivs\"), opt$par, ctrl = control$checkConv, :\nModel failed to converge with max|grad| = 0.63965 (tol = 0.002, component 1)\n\n\n\n\nCode\n#Backward selection procedure based on AIC\ndrop1(mod,test=\"Chi\") # We remove season\n\n\nSingle term deletions\n\nModel:\nsigns_in_yard ~ N_setts_in_fields + N_buildings + N_cattle_in_buildings_yard + \n    season + accessible_feed_store_present + accessible_cattle_house_present + \n    accessible_feed_present + grass_silage + cereal_silage + \n    hay_straw + cereal_grains + concentrates + sugar_beet + (1 | \n    farm_code)\n                                npar    AIC     LRT  Pr(Chi)   \n&lt;none&gt;                               183.86                    \nN_setts_in_fields                  1 191.63  9.7760 0.001768 **\nN_buildings                        1 182.97  1.1161 0.290759   \nN_cattle_in_buildings_yard         1 182.21  0.3496 0.554326   \nseason                             3 179.14  1.2815 0.733535   \naccessible_feed_store_present      1 182.62  0.7571 0.384246   \naccessible_cattle_house_present    1 182.06  0.2058 0.650093   \naccessible_feed_present            1 181.84 -0.0124 1.000000   \ngrass_silage                       1 181.83 -0.0232 1.000000   \ncereal_silage                      1 182.29  0.4289 0.512509   \nhay_straw                          1 183.04  1.1869 0.275951   \ncereal_grains                      1 182.28  0.4252 0.514352   \nconcentrates                       1 181.98  0.1249 0.723745   \nsugar_beet                         1 183.06  1.2054 0.272248   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nCode\nmod1&lt;-glmer(signs_in_yard~N_setts_in_fields\n              + N_buildings\n              + N_cattle_in_buildings_yard\n              + accessible_feed_store_present\n              + accessible_cattle_house_present\n              + accessible_feed_present\n              + grass_silage\n              + cereal_silage\n              + hay_straw\n              + cereal_grains\n              + concentrates\n              + sugar_beet\n              + (1|farm_code)\n              ,data=dataBadger\n              ,family=binomial)\n\ndrop1(mod1,test=\"Chi\") # We remove concentrates\n\n\nSingle term deletions\n\nModel:\nsigns_in_yard ~ N_setts_in_fields + N_buildings + N_cattle_in_buildings_yard + \n    accessible_feed_store_present + accessible_cattle_house_present + \n    accessible_feed_present + grass_silage + cereal_silage + \n    hay_straw + cereal_grains + concentrates + sugar_beet + (1 | \n    farm_code)\n                                npar    AIC     LRT  Pr(Chi)   \n&lt;none&gt;                               179.14                    \nN_setts_in_fields                  1 187.01  9.8762 0.001674 **\nN_buildings                        1 178.18  1.0424 0.307266   \nN_cattle_in_buildings_yard         1 177.59  0.4509 0.501920   \naccessible_feed_store_present      1 177.71  0.5744 0.448513   \naccessible_cattle_house_present    1 177.17  0.0291 0.864544   \naccessible_feed_present            1 177.16  0.0228 0.879894   \ngrass_silage                       1 177.15  0.0057 0.940075   \ncereal_silage                      1 177.65  0.5057 0.477006   \nhay_straw                          1 178.56  1.4247 0.232635   \ncereal_grains                      1 177.38  0.2417 0.622987   \nconcentrates                       1 177.14 -0.0003 1.000000   \nsugar_beet                         1 178.32  1.1765 0.278070   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nCode\nmod2&lt;-glmer(signs_in_yard~N_setts_in_fields\n              + N_buildings\n              + N_cattle_in_buildings_yard\n              + accessible_feed_store_present\n              + accessible_cattle_house_present\n              + accessible_feed_present\n              + grass_silage\n              + cereal_silage\n              + hay_straw\n              + cereal_grains\n              + sugar_beet\n              + (1|farm_code)\n              ,data=dataBadger\n              ,family=binomial)\n\ndrop1(mod2,test=\"Chi\") # We remove accessible_feed_present\n\n\nSingle term deletions\n\nModel:\nsigns_in_yard ~ N_setts_in_fields + N_buildings + N_cattle_in_buildings_yard + \n    accessible_feed_store_present + accessible_cattle_house_present + \n    accessible_feed_present + grass_silage + cereal_silage + \n    hay_straw + cereal_grains + sugar_beet + (1 | farm_code)\n                                npar    AIC    LRT Pr(Chi)   \n&lt;none&gt;                               177.14                  \nN_setts_in_fields                  1 185.06 9.9260 0.00163 **\nN_buildings                        1 176.23 1.0887 0.29677   \nN_cattle_in_buildings_yard         1 175.68 0.5408 0.46209   \naccessible_feed_store_present      1 175.73 0.5926 0.44143   \naccessible_cattle_house_present    1 175.34 0.2050 0.65075   \naccessible_feed_present            1 175.19 0.0564 0.81231   \ngrass_silage                       1 175.24 0.0960 0.75669   \ncereal_silage                      1 175.67 0.5270 0.46789   \nhay_straw                          1 176.57 1.4362 0.23075   \ncereal_grains                      1 175.45 0.3088 0.57844   \nsugar_beet                         1 176.47 1.3289 0.24900   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nCode\nmod3&lt;-glmer(signs_in_yard~N_setts_in_fields\n              + N_buildings\n              + N_cattle_in_buildings_yard\n              + accessible_feed_store_present\n              + accessible_cattle_house_present\n              + grass_silage\n              + cereal_silage\n              + hay_straw\n              + cereal_grains\n              + sugar_beet\n              + (1|farm_code)\n              ,data=dataBadger\n              ,family=binomial)\n\ndrop1(mod3,test=\"Chi\") # We remove grass_silage\n\n\nSingle term deletions\n\nModel:\nsigns_in_yard ~ N_setts_in_fields + N_buildings + N_cattle_in_buildings_yard + \n    accessible_feed_store_present + accessible_cattle_house_present + \n    grass_silage + cereal_silage + hay_straw + cereal_grains + \n    sugar_beet + (1 | farm_code)\n                                npar    AIC    LRT  Pr(Chi)   \n&lt;none&gt;                               175.19                   \nN_setts_in_fields                  1 182.95 9.7543 0.001789 **\nN_buildings                        1 174.16 0.9674 0.325328   \nN_cattle_in_buildings_yard         1 173.54 0.3478 0.555348   \naccessible_feed_store_present      1 174.31 1.1196 0.290000   \naccessible_cattle_house_present    1 173.33 0.1325 0.715902   \ngrass_silage                       1 173.30 0.1044 0.746582   \ncereal_silage                      1 173.70 0.5039 0.477772   \nhay_straw                          1 174.69 1.4910 0.222067   \ncereal_grains                      1 173.37 0.1773 0.673699   \nsugar_beet                         1 174.34 1.1420 0.285240   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nCode\nmod4&lt;-glmer(signs_in_yard~N_setts_in_fields\n              + N_buildings\n              + N_cattle_in_buildings_yard\n              + accessible_feed_store_present\n              + accessible_cattle_house_present\n              + cereal_silage\n              + hay_straw\n              + cereal_grains\n              + sugar_beet\n              + (1|farm_code)\n              ,data=dataBadger\n              ,family=binomial)\n\ndrop1(mod4,test=\"Chi\") # We remove cattle house\n\n\nSingle term deletions\n\nModel:\nsigns_in_yard ~ N_setts_in_fields + N_buildings + N_cattle_in_buildings_yard + \n    accessible_feed_store_present + accessible_cattle_house_present + \n    cereal_silage + hay_straw + cereal_grains + sugar_beet + \n    (1 | farm_code)\n                                npar    AIC     LRT  Pr(Chi)   \n&lt;none&gt;                               173.30                    \nN_setts_in_fields                  1 181.04  9.7457 0.001797 **\nN_buildings                        1 172.29  0.9936 0.318860   \nN_cattle_in_buildings_yard         1 171.72  0.4227 0.515570   \naccessible_feed_store_present      1 172.31  1.0085 0.315266   \naccessible_cattle_house_present    1 171.24 -0.0602 1.000000   \ncereal_silage                      1 171.66  0.3578 0.549755   \nhay_straw                          1 172.71  1.4087 0.235273   \ncereal_grains                      1 171.38  0.0761 0.782711   \nsugar_beet                         1 172.43  1.1252 0.288803   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nCode\nmod5&lt;-glmer(signs_in_yard~N_setts_in_fields\n              + N_buildings\n              + N_cattle_in_buildings_yard\n              + accessible_feed_store_present\n              + cereal_silage\n              + hay_straw\n              + cereal_grains\n              + sugar_beet\n              + (1|farm_code)\n              ,data=dataBadger\n              ,family=binomial)\n\ndrop1(mod5,test=\"Chi\") # We remove cereal_grains\n\n\nSingle term deletions\n\nModel:\nsigns_in_yard ~ N_setts_in_fields + N_buildings + N_cattle_in_buildings_yard + \n    accessible_feed_store_present + cereal_silage + hay_straw + \n    cereal_grains + sugar_beet + (1 | farm_code)\n                              npar    AIC     LRT   Pr(Chi)    \n&lt;none&gt;                             171.24                      \nN_setts_in_fields                1 180.22 10.9805 0.0009207 ***\nN_buildings                      1 170.49  1.2509 0.2633739    \nN_cattle_in_buildings_yard       1 169.74  0.5023 0.4784721    \naccessible_feed_store_present    1 170.34  1.1036 0.2934846    \ncereal_silage                    1 169.82  0.5805 0.4461350    \nhay_straw                        1 170.70  1.4594 0.2270195    \ncereal_grains                    1 169.55  0.3147 0.5747814    \nsugar_beet                       1 170.58  1.3400 0.2470283    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nCode\nmod6&lt;-glmer(signs_in_yard~N_setts_in_fields\n              + N_buildings\n              + N_cattle_in_buildings_yard\n              + accessible_feed_store_present\n              + cereal_silage\n              + hay_straw\n              + sugar_beet\n              + (1|farm_code)\n              ,data=dataBadger\n              ,family=binomial)\n\ndrop1(mod6,test=\"Chi\") # We remove cereal_silage\n\n\nSingle term deletions\n\nModel:\nsigns_in_yard ~ N_setts_in_fields + N_buildings + N_cattle_in_buildings_yard + \n    accessible_feed_store_present + cereal_silage + hay_straw + \n    sugar_beet + (1 | farm_code)\n                              npar    AIC     LRT   Pr(Chi)    \n&lt;none&gt;                             169.55                      \nN_setts_in_fields                1 178.56 11.0067 0.0009078 ***\nN_buildings                      1 168.98  1.4289 0.2319453    \nN_cattle_in_buildings_yard       1 168.25  0.6961 0.4040841    \naccessible_feed_store_present    1 168.67  1.1201 0.2898895    \ncereal_silage                    1 168.16  0.6100 0.4347724    \nhay_straw                        1 168.92  1.3646 0.2427384    \nsugar_beet                       1 168.66  1.1102 0.2920361    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nCode\nmod7&lt;-glmer(signs_in_yard~N_setts_in_fields\n              + N_buildings\n              + N_cattle_in_buildings_yard\n              + accessible_feed_store_present\n              + hay_straw\n              + sugar_beet\n              + (1|farm_code)\n              ,data=dataBadger\n              ,family=binomial)\n\ndrop1(mod7,test=\"Chi\") # We remove N_cattle_in_buildings_yard\n\n\nSingle term deletions\n\nModel:\nsigns_in_yard ~ N_setts_in_fields + N_buildings + N_cattle_in_buildings_yard + \n    accessible_feed_store_present + hay_straw + sugar_beet + \n    (1 | farm_code)\n                              npar    AIC     LRT  Pr(Chi)   \n&lt;none&gt;                             168.16                    \nN_setts_in_fields                1 176.90 10.7317 0.001053 **\nN_buildings                      1 167.30  1.1334 0.287048   \nN_cattle_in_buildings_yard       1 166.72  0.5593 0.454547   \naccessible_feed_store_present    1 167.22  1.0613 0.302921   \nhay_straw                        1 167.35  1.1842 0.276493   \nsugar_beet                       1 167.58  1.4143 0.234341   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nCode\nmod8&lt;-glmer(signs_in_yard~N_setts_in_fields\n              + N_buildings\n              + accessible_feed_store_present\n              + hay_straw\n              + sugar_beet\n              + (1|farm_code)\n              ,data=dataBadger\n              ,family=binomial)\n\ndrop1(mod8,test=\"Chi\") # We remove accessible_feed_store_present (same AIC as hay_straw, but higher p value)\n\n\nSingle term deletions\n\nModel:\nsigns_in_yard ~ N_setts_in_fields + N_buildings + accessible_feed_store_present + \n    hay_straw + sugar_beet + (1 | farm_code)\n                              npar    AIC     LRT   Pr(Chi)    \n&lt;none&gt;                             166.72                      \nN_setts_in_fields                1 175.95 11.2267 0.0008063 ***\nN_buildings                      1 166.85  2.1303 0.1444105    \naccessible_feed_store_present    1 165.75  1.0249 0.3113523    \nhay_straw                        1 165.75  1.0319 0.3097180    \nsugar_beet                       1 166.00  1.2738 0.2590508    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nCode\nmod9&lt;-glmer(signs_in_yard~N_setts_in_fields\n              + N_buildings\n              + hay_straw\n              + sugar_beet\n              + (1|farm_code)\n              ,data=dataBadger\n              ,family=binomial)\n\ndrop1(mod9,test=\"Chi\") # We remove hay_straw\n\n\nSingle term deletions\n\nModel:\nsigns_in_yard ~ N_setts_in_fields + N_buildings + hay_straw + \n    sugar_beet + (1 | farm_code)\n                  npar    AIC     LRT   Pr(Chi)    \n&lt;none&gt;                 165.75                      \nN_setts_in_fields    1 176.27 12.5238 0.0004018 ***\nN_buildings          1 166.38  2.6306 0.1048194    \nhay_straw            1 164.11  0.3589 0.5490935    \nsugar_beet           1 164.94  1.1864 0.2760633    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nCode\nmod10&lt;-glmer(signs_in_yard~N_setts_in_fields\n              + N_buildings\n              + sugar_beet\n              + (1|farm_code)\n              ,data=dataBadger\n              ,family=binomial)\n\ndrop1(mod10,test=\"Chi\") # We remove sugar_beet\n\n\nSingle term deletions\n\nModel:\nsigns_in_yard ~ N_setts_in_fields + N_buildings + sugar_beet + \n    (1 | farm_code)\n                  npar    AIC     LRT   Pr(Chi)    \n&lt;none&gt;                 164.11                      \nN_setts_in_fields    1 174.41 12.3001 0.0004529 ***\nN_buildings          1 164.63  2.5277 0.1118629    \nsugar_beet           1 163.44  1.3299 0.2488179    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nCode\nmod11&lt;-glmer(signs_in_yard~N_setts_in_fields\n              + N_buildings\n              + (1|farm_code)\n              ,data=dataBadger\n              ,family=binomial)\n\ndrop1(mod11,test=\"Chi\") # We remove N_buildings\n\n\nSingle term deletions\n\nModel:\nsigns_in_yard ~ N_setts_in_fields + N_buildings + (1 | farm_code)\n                  npar    AIC     LRT   Pr(Chi)    \n&lt;none&gt;                 163.44                      \nN_setts_in_fields    1 174.13 12.6888 0.0003679 ***\nN_buildings          1 163.38  1.9409 0.1635723    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nCode\nmod12&lt;-glmer(signs_in_yard~N_setts_in_fields\n              + (1|farm_code)\n              ,data=dataBadger\n              ,family=binomial)\n\ndrop1(mod12,test=\"Chi\") # mod12 is the best model\n\n\nSingle term deletions\n\nModel:\nsigns_in_yard ~ N_setts_in_fields + (1 | farm_code)\n                  npar    AIC    LRT   Pr(Chi)    \n&lt;none&gt;                 163.38                     \nN_setts_in_fields    1 174.57 13.197 0.0002804 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nThere are convergence issues with the first few models, which may be due to their complexity. The best model only retains the number of setts as a fixed effect."
  },
  {
    "objectID": "Linear_Model_2.html#model-coefficients",
    "href": "Linear_Model_2.html#model-coefficients",
    "title": "GENERALIZED LINEAR MIXED MODEL",
    "section": "Model coefficients",
    "text": "Model coefficients\n\n\nCode\nsummary(mod12)\n\n\nGeneralized linear mixed model fit by maximum likelihood (Laplace\n  Approximation) [glmerMod]\n Family: binomial  ( logit )\nFormula: signs_in_yard ~ N_setts_in_fields + (1 | farm_code)\n   Data: dataBadger\n\n      AIC       BIC    logLik -2*log(L)  df.resid \n    163.4     174.3     -78.7     157.4       275 \n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-2.0216 -0.2384 -0.1102 -0.0841  6.4681 \n\nRandom effects:\n Groups    Name        Variance Std.Dev.\n farm_code (Intercept) 4.868    2.206   \nNumber of obs: 278, groups:  farm_code, 36\n\nFixed effects:\n                  Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)        -5.0705     0.9509  -5.332  9.7e-08 ***\nN_setts_in_fields   0.3809     0.1077   3.537 0.000405 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n            (Intr)\nN_stts_n_fl -0.766\n\n\nThe model summary details both the fixed and the random effects. The model can be written as: \\[  logit(presence\\:of\\:badger\\:activity) = -5.07 + 0.38 \\times number\\:of\\:setts\\] The variance associated with the random effect (which corresponds to the variance between farms) is 4.87."
  },
  {
    "objectID": "Linear_Model_2.html#significance-of-the-random-effect",
    "href": "Linear_Model_2.html#significance-of-the-random-effect",
    "title": "GENERALIZED LINEAR MIXED MODEL",
    "section": "Significance of the random effect",
    "text": "Significance of the random effect\nThe significance of the random effect is tested via a bootstrap method: the likelihood of the model including the random effect is compared to the likelihood of 100 models without the random effect.\n\n\nCode\nnBoot &lt;- 100 # number of simulations\nlrStat &lt;- rep(NA, nBoot) # initializes a vector of size 100 to store the likelihood ratio statistic\nft.null &lt;-glm(signs_in_yard~N_setts_in_fields,data=dataBadger,family=binomial(link=logit)) # fits the null model (without the random effect)\nft.alt &lt;- glmer(signs_in_yard~N_setts_in_fields+(1|farm_code),data=dataBadger,family=binomial) # fits the alternate model (with the random effect)\nlrObs &lt;- 2 * logLik(ft.alt) - 2 * logLik(ft.null) # computes the observed likelihood ratio statistic \n\nfor (iBoot in 1:nBoot) # for each simulation\n{\n  dataBadger$signs_in_yardSim &lt;- unlist(simulate(ft.null)) # badger activity is simulated from the distribution corresponding to the null model\n  tryCatch(\n    { # in case the glmm does not converge\n      bNull &lt;-glm(signs_in_yardSim ~ N_setts_in_fields,data=dataBadger,family=binomial(link=logit)) # fits the null model to the simulated data\n      bAlt &lt;- glmer(signs_in_yardSim ~ N_setts_in_fields+(1|farm_code),data=dataBadger,family=binomial) # fits the alternate model to the simulated data\n      lrStat[iBoot] &lt;- 2 * logLik(bAlt) - 2 * logLik(bNull) # computes the likelihood ratio statistic for the resampled data\n    },\n    warning = function(war) { # if there is a warning or an error, the likelihood ratio statistic is NA (to ensure the loop does not stop)\n      lrStat[iBoot] &lt;- NA\n    },\n    error = function(err) {\n      lrStat[iBoot] &lt;- NA\n    }\n  )\n}\n\nmean(lrStat &gt; lrObs, na.rm = TRUE) # Proportion of bootstrap likelihood ratio statistic superior to the observed statistic\n\n\n[1] 0\n\n\nCode\n# It corresponds to the p value\n\nhist(lrStat,xlim = c(0,40), col='aquamarine3', main = \"Histogram of the likelihood ratio statistic\", xlab = \"Likelihood ratio statistic\") # Histogram of the 100 values of likelihood of the simulated model\nabline(v = lrObs, col=\"pink1\", lwd=3, lty=2) # Vertical red line representing the likelihood of the model including the random factor\n\n\n\n\n\n\n\n\n\nAll simulations lead to a likelihood ratio statistic lower than the observed statistic, which suggests that the random effect is highly significant."
  },
  {
    "objectID": "Linear_Model_2.html#part-of-the-variance-explained-by-the-model",
    "href": "Linear_Model_2.html#part-of-the-variance-explained-by-the-model",
    "title": "GENERALIZED LINEAR MIXED MODEL",
    "section": "Part of the variance explained by the model",
    "text": "Part of the variance explained by the model\nThe function rsq from the package rsq computes three pseudo \\(R^2\\), allowing us to separate the variance explained by the fixed effect from the variance explained by the random effect.\n\n\nCode\n# Estimates of deviance explained (library 'rsq')\nrsq(mod12)\n\n\n$model\n[1] 0.5939386\n\n$fixed\n[1] 0.2102993\n\n$random\n[1] 0.3836392\n\n\nThe model explains about 59% of the variance of the data, with 21% due to the fixed effect (the number of setts) and 38% due to the random effect (each individual farm)."
  },
  {
    "objectID": "Linear_Model_2.html#residual-analysis",
    "href": "Linear_Model_2.html#residual-analysis",
    "title": "GENERALIZED LINEAR MIXED MODEL",
    "section": "Residual analysis",
    "text": "Residual analysis\nA GLMM does not require normality of residuals or homogeneity of variance, and the dependance in the data has already been taken into account with the random effect. However, analyzing the residuals allows us to detect an eventual trend which could indicate a problem with the modelization. Pearson residuals are used because they take into account variance heterogeneity.\n\n\nCode\nresid&lt;-residuals(mod12, type=\"pearson\")\n\npar(mfrow=c(1,2))\n# Plotting the residuals against the fitted data\nplot(resid~fitted(mod12)\n      , col='dodgerblue4'\n      , pch=16)\nabline(h = 0)\n\n# Plotting the residuals against the number of setts\nplot(resid~ dataBadger$N_setts_in_fields, \n         pch=16,\n         col=\"dodgerblue4\",\n         ylab = \"Residuals\",\n         xlab = \"Number of Setts\",\n         main = \"\")\nabline(h = 0)\n\n\n\n\n\n\n\n\n\nIn a binomial GLMM, residuals are often difficult to interpret. No defined trend can be identified here."
  },
  {
    "objectID": "Linear_Model_2.html#model-predictions",
    "href": "Linear_Model_2.html#model-predictions",
    "title": "GENERALIZED LINEAR MIXED MODEL",
    "section": "Model predictions",
    "text": "Model predictions\nWe can check if the model is able to accurately predict the presence / absence of activity signs based on the number of setts.\n\n\nCode\nset.seed(9)\nN    &lt;- nrow(dataBadger) # number of observations in the dataset\nPi   &lt;- fitted(mod12) # predicted probabilities that activity = 1\ndataBadger$Ysim &lt;- rbinom(N, size = 1, Pi) # generates a binary outcome for badger activity, drawn from a binomial distribution with Pi as a success probability\n\n# Confusion matrix\nZ &lt;- table(dataBadger$signs_in_yard, dataBadger$Ysim) / N\nrownames(Z) &lt;- c(\"Observed 0\", \"Observed 1\")\ncolnames(Z) &lt;- c(\"Predicted 0\", \"Predicted 1\")\nZ\n\n\n            \n             Predicted 0 Predicted 1\n  Observed 0  0.77338129  0.06474820\n  Observed 1  0.07553957  0.08633094\n\n\nCode\n# Accuracy = proportion of correctly classified observations\nsum(diag(Z))\n\n\n[1] 0.8597122\n\n\nCode\n# To get an average confusion matrix over mutliple predictions, we can repeat for 1000 simulations\nNSim &lt;- 1000                           \ndiagZ &lt;- numeric(NSim) # we store one accuracy value per simulation\nfor (i in 1:NSim) { # for each simulation\n  Ysim &lt;- rbinom(N, size = 1, Pi) # a new simulated response is generated\n  Z&lt;- table(dataBadger$signs_in_yard, Ysim) / N # creates the confusion matrix for this simulation\n  diagZ[i]&lt;-sum(diag(Z)) # computes and stores the accuracy\n  }\n# Boxplot of the accuracy and average accuracy\nboxplot(diagZ, col='dodgerblue4',ylab='#Rate of farms well-classified')\n\n\n\n\n\n\n\n\n\nCode\nmean(diagZ)\n\n\n[1] 0.8821763\n\n\nEach cell of the confusion matrix represents a proportion of the total observations.\n\nThe true negative rate is 77%: it corresponds to farms without badger activity where no activity was predicted\nThe false positive rate is 6.5%: it corresponds to farms without badger activity where activity was incorrectly predicted\nThe true positive rate is 8.6%: it corresponds to farms with badger activity where activity was predicted\nThe false negative rate is 7.6%: it corresponds to farms with badger activity where no activity was predicted\n\nFor this prediction, the overall accuracy was 0.86, which means that 86% of predictions were correct. The average accuracy over 1000 simulations is 0.88."
  },
  {
    "objectID": "r_chapter.html",
    "href": "r_chapter.html",
    "title": "Basic overview of Markdown potentials with R and Quarto",
    "section": "",
    "text": "This chapter is a simple example using R\nYou can import R package using the code\n\nlibrary(tidyverse)\n\n‚îÄ‚îÄ Attaching core tidyverse packages ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ tidyverse 2.0.0 ‚îÄ‚îÄ\n‚úî dplyr     1.1.4     ‚úî readr     2.1.6\n‚úî forcats   1.0.0     ‚úî stringr   1.5.2\n‚úî ggplot2   4.0.1     ‚úî tibble    3.3.0\n‚úî lubridate 1.9.4     ‚úî tidyr     1.3.1\n‚úî purrr     1.1.0     \n‚îÄ‚îÄ Conflicts ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ tidyverse_conflicts() ‚îÄ‚îÄ\n‚úñ dplyr::filter() masks stats::filter()\n‚úñ dplyr::lag()    masks stats::lag()\n‚Ñπ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\nand then describe the purpose of your chapter as well as executing R command.\nYou can also add images\n![Gentoo penguins](images/6123849122_b66af201ea_c.jpg}\nFor example a basic summary of a dataset is given by\n\ndf &lt;- read.table(\"https://gist.githubusercontent.com/slopp/ce3b90b9168f2f921784de84fa445651/raw/4ecf3041f0ed4913e7c230758733948bc561f434/penguins.csv\", sep = \",\" , header = TRUE)\n\nand produce a graph\n\ndf %&gt;% ggplot() +\n    aes(x=species, y = body_mass_g) +\n    geom_boxplot()  \n\nWarning: Removed 2 rows containing non-finite outside the scale range\n(`stat_boxplot()`).\n\n\n\n\n\n\n\n\n\nJust for curiosity, you could add an image of Gentoo penguins\nYou can also add images\n\n\n\n\n\n\nFigure¬†1: Gentoo penguins\n\n\n\nYou can refer to one image using cross-reference. For example, Figure¬†1 is a photo of a gentoo penguin with chicks by Liam Quinn.\nYou can also add reference associated with models. For example, if you want to study how the body mass differ between species you should use a one way analysis of variance as described in Equation¬†1\n\\[Y_{sk} = \\mu + \\alpha_s + E_{sk},\n\\tag{1}\\]\nwhere \\(s\\) standes for species and \\(k\\) denotes each individual.\nA useful citation about reproducible reserach Alston and Rick (2021)\n\n\n\n\nReferences\n\nAlston, Jesse M, and Jessica A Rick. 2021. ‚ÄúA Beginner‚Äôs Guide to Conducting Reproducible Research.‚Äù Bulletin of the Ecological Society of America 102 (2): 1‚Äì14."
  }
]