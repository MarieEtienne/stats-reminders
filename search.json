[
  {
    "objectID": "EDO_estimation.html",
    "href": "EDO_estimation.html",
    "title": "EDO Estimation of parameters : the logistic growth",
    "section": "",
    "text": "This document aims to be a roadmap to estimate the parameters of a logistic growth from a population: from the data simulation to the estimation of the parameters. The following document will thus be organized in two parts : the data simulation and the estimation of the parameters."
  },
  {
    "objectID": "EDO_estimation.html#general-theory",
    "href": "EDO_estimation.html#general-theory",
    "title": "EDO Estimation of parameters : the logistic growth",
    "section": "General theory",
    "text": "General theory\n\nLeast squares\n\nDefinition\nOne of the most used methods to assess the quality of a model is the least squares method, also known as mean square error method (MSE). It quantifies how the simulated data match with the real ones by measuring the gap between the simulated and the real points (@cornillon2007regression). This gap is estimated with the following formula:\n\\[\n\\text{MSE} = \\sum_{i}^{}(Y_{i}-\\hat{Y})^{2}\\\\\\hat{Y} = \\text{mean value of the data set}\\\\Y_{i} = \\text{value of the individual i}\n\\]\nA good model minimizes the MSE. Graphically, this means that the vertical distance between each simulated point and its corresponding observed value is as small as possible.\n\n\nSpecific aspects\nThe MSE is one of the most common method to assess the quality of a model. However, it has some limitations that may call its use into question. First, as it compares the simulated data and the observed ones point by point, the presence of outliers can strongly deviate the MSE estimation. Moreover, this estimation method assumes a linear relation between the variables. Therefore, if the relation between the variables is not linear, the MSE may not reflect the true performance of the model.\n\n\n\nMaximum likelihood\n\nDefinition\nLikelihood corresponds to the probability of observing the data, knowing the parameters \\(\\theta\\) (@fisher1922mathematical). The likelihood function is as follows : \\[\nL(\\theta) = \\prod_{i=1}^n f(x_i , \\theta)\n\\] In this function, \\(x_i\\) corresponds to the observations and \\(f(x_i,\\theta)\\) corresponds to the probability density function of the random variable \\(X\\).\nThe maximum likelihood method consists in determining the estimated parameters \\(\\hat\\theta\\) that maximize the likelihood function: \\[\n\\hat\\theta = \\arg\\max_\\theta L(\\theta)\n\\] Maximizing \\(L(\\theta)\\) means finding the parameter values that make the data most plausible under the chosen model.\n\n\nSpecific aspects\nIf the errors of the data are independent and identically distributed, this method is equivalent to the least squares method :\n\\[\n\\hat{\\theta} = \\arg\\max_{\\theta} L(\\theta) = \\arg\\min_{\\theta} SCE(\\theta)\n\\] We prefer to work with the logarithm of the likelihood function \\(L(\\theta)\\), as it converts products into sums: \\[\nLL(\\theta) = ln(L(\\theta)) = \\sum_{i=1}^n lnf(x_i,\\theta)\n\\]"
  },
  {
    "objectID": "EDO_estimation.html#implementation-of-the-two-methods",
    "href": "EDO_estimation.html#implementation-of-the-two-methods",
    "title": "EDO Estimation of parameters : the logistic growth",
    "section": "Implementation of the two methods",
    "text": "Implementation of the two methods\nWe first need to redefine a function of the model we want to fit (without noise this time).\n\nlogistic &lt;- function(t, r, K, y0) {\n  K / (1 + ((K - y0) / y0) * exp(-r * t))\n}\n\n\nLeast squares\nWe need a function that compute the sum of the squared errors between the data and the model prediction y given a x.\n\n# NB : theta is a vector of parameters\nSSE &lt;- function(theta) {\n  r &lt;- theta[1]\n  K &lt;- theta[2]\n  y0 &lt;- theta[3]\n  mod_pred &lt;- sapply(time, logistic, r = r, K = K, y0 = y0)\n  return(sum((sim_data - mod_pred)**2))\n}\n\nWe now have to find a way to modify the parameters iteratively to find the best ones : the set of parameters \\(\\theta\\) that minimize the sum of squared errors. Thankfully, there are several functions implemented in R to do so. We‚Äôll use optim(), based on a gradient descent algorithm. We need to specify initial guess on the parameters to initialize the gradient descent algorithm. We‚Äôll take biologically meaningful parameters as initial guess.\n\nig_r &lt;- 1\nig_K &lt;- 75\nig_y0 &lt;- 2\nfitted_params_SSE &lt;- optim(c(ig_r, ig_K, ig_y0), SSE)$par\nprint(fitted_params_SSE)\n\n[1]   0.4038295 116.0801331  13.1639033\n\n\nFor practicality, or for some EDO models that are not explicitly solvable (i. e. we can‚Äôt find a unique solution to the Cauchy problem), we can locally and numerically solve in the same time we calculate the likelihood. This alternative is used in the next part. We use the function ode() from the package deSolve to do so.\n\nlibrary(deSolve)\n\n\nlogistic_ODE =function(t,N,parametre){\n  r=parametre[1]\n  K=parametre[2]\n  dNdt = r*(1-N/K)*N\n  list(c(dNdt))\n}\n\n\n\nMaximum likelihood\n\nMMV &lt;- function(theta){\n  r1 &lt;- theta[1]\n  K1 &lt;- theta[2]\n  N0 &lt;- theta[3]\n  sol = ode(y = N0, times = time, func = logistic_ODE, parms = c(r1, K1))\n  mod_pred &lt;- sol[, 2]\n  loglik = dnorm(sim_data, mean = mod_pred, sd = error, log = TRUE)\n  return(sum(loglik))\n}\n\n\nig_r &lt;- 0.1\nig_K &lt;- 100\nig_y0 &lt;- 1\nfitted_params_MMV &lt;- optim(c(ig_r, ig_K, ig_y0), MMV, control=list(fnscale=-1))$par\nprint(fitted_params_MMV)"
  },
  {
    "objectID": "EDO_estimation.html#data-visualization-simulated-dynamics-with-estimated-trends",
    "href": "EDO_estimation.html#data-visualization-simulated-dynamics-with-estimated-trends",
    "title": "EDO Estimation of parameters : the logistic growth",
    "section": "Data visualization : simulated dynamics with estimated trends",
    "text": "Data visualization : simulated dynamics with estimated trends\nAs we could expect on this kind of data, the estimated parameters are almost the same with the two methods, The two estimated trends we show on the following graph are even indistinguishable."
  },
  {
    "objectID": "instructions.html",
    "href": "instructions.html",
    "title": "Stats Reminder Project - Instructions",
    "section": "",
    "text": "Team project for groups of 3 students. Create examples demonstrating statistical/mathematical methods applied to ecological questions.\nRepository: https://github.com/MarieEtienne/stats-reminder\n\n\n\n\n\n\nDeliverables\n\n\n\nEach team creates 1 example among one of the major theme:\n\nLinear models\nDifferential equations\n\nMultivariate analysis\n\nEach student should devote time to the review process ass well\nThe repository will close on December 1st at 1PM and only the work merged on master will be reviewed and evaluated.\nFinal mark for this assignment will consider\n\nMastering git workflow (commit, pull push , handling conflict, Pull Request, optimmaly rebase to have a clean history)\nTaking part of the reviewing process to increase global quality of the project\n\nDuring the last lab on git, November 5th, students will have a test to evaluate the overall understanding of git process\nThe final grad will be based on both evaluation"
  },
  {
    "objectID": "instructions.html#sec-overview",
    "href": "instructions.html#sec-overview",
    "title": "Stats Reminder Project - Instructions",
    "section": "",
    "text": "Team project for groups of 3 students. Create examples demonstrating statistical/mathematical methods applied to ecological questions.\nRepository: https://github.com/MarieEtienne/stats-reminder\n\n\n\n\n\n\nDeliverables\n\n\n\nEach team creates 1 example among one of the major theme:\n\nLinear models\nDifferential equations\n\nMultivariate analysis\n\nEach student should devote time to the review process ass well\nThe repository will close on December 1st at 1PM and only the work merged on master will be reviewed and evaluated.\nFinal mark for this assignment will consider\n\nMastering git workflow (commit, pull push , handling conflict, Pull Request, optimmaly rebase to have a clean history)\nTaking part of the reviewing process to increase global quality of the project\n\nDuring the last lab on git, November 5th, students will have a test to evaluate the overall understanding of git process\nThe final grad will be based on both evaluation"
  },
  {
    "objectID": "instructions.html#sec-requirements",
    "href": "instructions.html#sec-requirements",
    "title": "Stats Reminder Project - Instructions",
    "section": "Project requirements",
    "text": "Project requirements\n\nContent\nEach .qmd example must include:\n\nClear ecological question with real/realistic data\nProper cross-references: sections (@sec-methods), figures (@fig-plot), tables (@tbl-results) or equations (@eq-model)\nCitations and bibliography\nWell-documented code and results\n\n\n\nGit Workflow\n\nOne branch per example: team-[names]-[method]-[description]\nUpdate _quarto.yml to include your examples in the website structure (see Section¬†3.3)\nOptimally Rebase before PR to ensure linear history (see Section¬†3.4)\nPR requirements (see Section¬†4.2):\n\n‚úÖ No merge conflicts\n‚úÖ Automated checks pass\n‚úÖ One peer review\n‚úÖ At least one discussion thread"
  },
  {
    "objectID": "instructions.html#sec-workflow",
    "href": "instructions.html#sec-workflow",
    "title": "Stats Reminder Project - Instructions",
    "section": "Git Workflow",
    "text": "Git Workflow\n\nSetup\n# Clone repository\ngit clone https://github.com/MarieEtienne/stats-reminder.git\ncd stats-reminder\n\n# Create team branch\ngit switch -b teamA\ngit push origin teamA\n\n\nCreate one branch per task\n# From your team branch, create example branches\ngit switch teamA\ngit switch -b teamA-intro\n\n# Work on your .qmd file\ngit add linear_model_teamA.qmd\ngit commit -m \"Add linear model example\"\n....\ngit fetch origin teamA\ngit rebase teamA \n\n# If conflicts: resolve, then\ngit add &lt;resolved-files&gt;\ngit rebase --continue\n\n# switch to team branch and update the branch with this neaw linear history\ngit switch teamA\ngit merge teamA-intro\n\n\nUpdating _quarto.yml\nAdd your examples to the website structure:\nwebsite:\n  navbar:\n    left:\n      - text: \"Team Examples\"\n        menu:\n          - text: \"Team Smith\"\n            menu:\n              - text: \"Plant Growth (Linear)\"\n                href: linear_model_teamA.qmd\n              - text: \"Predator-Prey (Diff Eq)\"\n                href: team-smith-diffeq-predator.qmd\n\n\n\nUpdate Before PR\n\n\n\n\n\n\nWarning\n\n\n\nAlways rebase on master before creating PR to ensure clean linear history and avoid conflicts.\n\n\ngit switch teamA\ngit switch -c teamA_PR #create a new branch to avoid destruction\n\n# Fetch and rebase\ngit fetch origin master\ngit rebase origin/master\n\n# If conflicts: resolve, then\ngit add &lt;resolved-files&gt;\ngit rebase --continue\n\n# push teamA_PR and ask for PR in github, there should be no conflict\ngit push origin teamA_PR"
  },
  {
    "objectID": "instructions.html#sec-pull-requests",
    "href": "instructions.html#sec-pull-requests",
    "title": "Stats Reminder Project - Instructions",
    "section": "Pull Requests",
    "text": "Pull Requests\n\nCreating a PR\n\nGo to repository ‚Üí Pull requests ‚Üí New pull request\nBase: master, Compare: teamA_PR\nWrite clear description (method, question, team)\n\n\n\nPR Requirements\nAll must be met before merge:\n\n‚úÖ No conflicts (rebase if needed, see Section¬†3.4)\n‚úÖ Automated checks pass (builds website successfully)\n‚úÖ One review from peer/instructor\n‚úÖ One discussion thread (respond to reviewer comments)\n\nAfter merge, the website automatically deploys to GitHub Pages.\nBe careful that, history in teamA and teamA_PR differ, and teamA_PR is the one to be merged. So if you want to add more contents to your project, remove local and remote teamA branch (and teamA_PR once merge into master) and starts a new branch from the current master branch"
  },
  {
    "objectID": "instructions.html#sec-markdown",
    "href": "instructions.html#sec-markdown",
    "title": "Stats Reminder Project - Instructions",
    "section": "Cross-References & Citations",
    "text": "Cross-References & Citations\n\nCross-References\n## Methods {#sec-methods}\n\nThe model (@eq-linear) uses data shown in @fig-scatter and @tbl-summary.\n\n$$ y = \\beta_0 + \\beta_1 x $$ {#eq-linear}\n\n```{r}\n#| label: fig-scatter\n#| fig-cap: \"Relationship between variables\"\nplot(x, y)\n```\n\nAs described in @sec-methods...\n\n\nCitations\nCreate references.bib:\n@article{smith2020,\n  author = {Smith, J.},\n  title = {Statistical Methods},\n  journal = {Ecology},\n  year = {2020}\n}\nIn your YAML:\nbibliography: references.bib\nIn text:\nAccording to @smith2020, the method..."
  },
  {
    "objectID": "instructions.html#sec-rules",
    "href": "instructions.html#sec-rules",
    "title": "Stats Reminder Project - Instructions",
    "section": "Important Rules",
    "text": "Important Rules\n\n\n\n\n\n\nImportant\n\n\n\n\nMaster is protected - you cannot push directly\nUse rebase not merge (see Section¬†3.4) as much as possible, that is the good practice\nPass all checks before requesting merge"
  },
  {
    "objectID": "instructions.html#sec-troubleshooting",
    "href": "instructions.html#sec-troubleshooting",
    "title": "Stats Reminder Project - Instructions",
    "section": "Common Issues",
    "text": "Common Issues\nBuild failing: Check logs for syntax errors in .qmd, missing packages, broken cross-references, or invalid _quarto.yml.\nCan‚Äôt push to master: Expected! Create a branch instead (see Section¬†3.2)."
  },
  {
    "objectID": "instructions.html#sec-checklist",
    "href": "instructions.html#sec-checklist",
    "title": "Stats Reminder Project - Instructions",
    "section": "Checklist",
    "text": "Checklist\nBefore submitting PR:\n\n_quarto.yml updated\nCross-references used throughout\nCitations included\nNo conflicts\nRebased on master\nPR created with clear description\nChecks passing\nReview requested"
  },
  {
    "objectID": "instructions.html#sec-resources",
    "href": "instructions.html#sec-resources",
    "title": "Stats Reminder Project - Instructions",
    "section": "Resources",
    "text": "Resources\n\nQuarto Cross-References\nGit Rebase Tutorial\nCreating Pull Requests\n\nQuestions? Check GitHub Issues or contact the instructor. Good luck! üöÄ"
  },
  {
    "objectID": "Linear_Model_1.html",
    "href": "Linear_Model_1.html",
    "title": "GENERAL LINEAR MODEL",
    "section": "",
    "text": "GENERAL INTRODUCTION\nWe present here, a reminder sheet on the General Linear Model (GLM) and its specific features. Its use will be illustrated with an example applied to ecological data on penguins from Gorman (2014) .\n\n\n\n\n\n\nNote : The concepts covered in this reminder sheet are taken from our Master‚Äôs lectures, written by Outreman (n.d.) and then taught by AbelMasson (n.d.) . During these courses, we learned how to explore data and then analyze it using this type of model.\n\n\n\n\nGeneralities\nThe objective of the GLM is to explain a dependent variable as a function of independent explanatory variables measured on statistical units from a sample of a population. This type of model is generally constructed as follows:\n\\[Y = Œ≤*X + Œµ\\]\n\\(Y\\) is the response (dependent) variable to be explained. \\(X\\) is an explanatory (independent) variable that can explain \\(Y\\). There can be several in the model. Œ≤i represents a coefficient, placed in front of the \\(X\\) variables, to measure their effect on the response variable. Œµ represents the errors in the model, i.e.¬†what the model cannot explain.\n\n\nType of General Linear Model\nThere are three general types of linear models:\n\nLinear regression\nAnalysis of variance (ANOVA)\nAnalysis of variance-covariance (ANCOVA)\n\nThey each have their own specific characteristics and depend on the nature of the independent variables \\(X\\), which can be quantitative or qualitative. The response variable \\(Y\\) is always quantitative.\nLinear regression is used when we want to determine whether a linear relationship exists between the response variable \\(Y\\) and one or more quantitative \\(X\\) variables (then called covariates).\nANOVA is used when the explanatory variables \\(X\\) are qualitative (then called factors). These qualitative \\(X\\) variables often have multiple categories (levels).\nANCOVA is used when we want to model the variable \\(Y\\) as a function of several \\(X\\) variables, which can be qualitative and quantitative.\nAnother important aspect to consider is that for this type of model to be valid, three conditions must be met:\n\nthe model residuals must follow a normal distribution\nhomoscedasticity (homogeneity of the variance of the residuals) must be respected\nthe residuals are independent\n\nThese conditions are systematically verified after modeling : the verification will be illustrated in the following example.\n\n\nData presentation and objectives\n\n\n\nAdelie Penguins from Petrel Island - Adelie Land - C. Cornec (IPEV/CNRS/CSM)\n\n\nIn this application example, we will use data from a study conducted by Dr.¬†Kristen Gorman, who studied the physical characteristics of three species of penguins in the Palmer Archipelago in Antarctica. The data was collected on three islands of the archipelago in 2007, 2008, and 2009.\nThe researcher noted the following characteristics in the individuals studied:\n\nspecies = species of individuals, qualitative variables, 3 levels (Adelie, Gentoo, Chinstrap)\nsex = sex of individuals, qualitative variables, 2 levels (male, female)\nbill_length_mm = bill length, quantitative variable\nbill_depth_mm = bill depth, quantitative variable\nflipper_length_mm = flipper length, quantitative variable\nbody_mass_g = body mass, quantitative variable\n\nWe also have information about the year of measurement and the island where the individuals live. We decide not to focus on these variables while studying the model. Indeed, we choose to focus our study on biological and morphological characteristics.\nWe will try to answer the following question : Which quantitative and qualitative variables can explain the variation in penguin body_mass_g?\nIn this case, the response variable is body_mass_g, and the other variables are assumed to be explanatory variables. We want to model the variable \\(Y\\) as a function of several qualitative and quantitative variables, therefore we do an ANCOVA.\nThe model can be build like this : model &lt;- lm (body_mass_g ~ ..., data = penguins)\n\n\n\nDATA IMPORTATION\nFirstly, we need to import the data, explore it, and see if there are any NA values, outliers, and so on. The data is accessible via the package palmerpenguins by Horst, Hill, and Gorman (2020).\n\n# Data importation \nlibrary(palmerpenguins) \n\n\nAttaching package: 'palmerpenguins'\n\n\nThe following objects are masked from 'package:datasets':\n\n    penguins, penguins_raw\n\ndata(\"penguins\") \n\n# Change categorical variables as factor \npenguins$sex&lt;-as.factor(penguins$sex) \npenguins$species&lt;-as.factor(penguins$species)\nstr(penguins)\n\ntibble [344 √ó 8] (S3: tbl_df/tbl/data.frame)\n $ species          : Factor w/ 3 levels \"Adelie\",\"Chinstrap\",..: 1 1 1 1 1 1 1 1 1 1 ...\n $ island           : Factor w/ 3 levels \"Biscoe\",\"Dream\",..: 3 3 3 3 3 3 3 3 3 3 ...\n $ bill_length_mm   : num [1:344] 39.1 39.5 40.3 NA 36.7 39.3 38.9 39.2 34.1 42 ...\n $ bill_depth_mm    : num [1:344] 18.7 17.4 18 NA 19.3 20.6 17.8 19.6 18.1 20.2 ...\n $ flipper_length_mm: int [1:344] 181 186 195 NA 193 190 181 195 193 190 ...\n $ body_mass_g      : int [1:344] 3750 3800 3250 NA 3450 3650 3625 4675 3475 4250 ...\n $ sex              : Factor w/ 2 levels \"female\",\"male\": 2 1 1 NA 1 2 1 2 NA NA ...\n $ year             : int [1:344] 2007 2007 2007 2007 2007 2007 2007 2007 2007 2007 ...\n\n\n\n\n          species            island    bill_length_mm     bill_depth_mm \n                0                 0                 2                 2 \nflipper_length_mm       body_mass_g               sex              year \n                2                 2                11                 0 \n\n\nfemale   male   NA's \n   165    168     11 \n\n\nThere are NA values in the dataset. 2 rows of the dataset contain missing values for all the studied variables, except species. Values are missing for the variable sex in 9 other rows. There are different ways to process NA values. In our case, we decide to delete the two rows with almost complete missing information. Then, an option would be to replace the other missing values for the sex variable by ‚Äúunknown‚Äù to specify that we don‚Äôt know if the individual is a male or a female and to create a new level for this variable. However, with this option, the group in which the sex is unknown would be under-represented compared to male and female group. As it seems interesting to test if being a female or a male has an influence on the body mass of penguins, having rows where the sex of individuals is unknown is not really useful and could add noise to the analysis. Therefore, we finally decide to delete all rows with NA values in the dataset. Moreover, the rows that include NA values only represented around 3% of the dataset.\n\n\n          species            island    bill_length_mm     bill_depth_mm \n                0                 0                 0                 0 \nflipper_length_mm       body_mass_g               sex              year \n                0                 0                 0                 0 \n\n\nWe now have handled NA values and we can continue to explore the data before implementing the model to answer our question.\n\n\nDATA EXPLORATION\nExploring the dataset is always the first step before analysis and model creation. This step is essential for identifying the structure of the variables and checking for outliers, correlations, or unbalanced distributions, mainly for qualitative variable categories, and assumptions.\n\n1. Outliers and distribution of the dependent variable (\\(Y\\))\n\n\n\n\n\n\n\n\n\nBased on the 3 first graphs (Boxplot, Cleveland plot and Histogram), it seems that there are no outliers in the \\(Y\\) variable body_mass_g. With the Q-Q plot, the data appears to follow a Gaussian distribution. However, \\(Y\\) normality is not a required assumption for our model. Keep in mind that we will need to check something about normality later on : the model residuals must follow a normal distribution in the case of a linear model.\n\n\n2. Outliers and Distributions of Quantitative Predictors (\\(X\\))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThere appear to be no outliers for any of the quantitative variables.\nLet‚Äôs describe what we observe. From the Cleveland plot, for the bill length variable, we can observe two distinct clusters which might be related to sexual dimorphism. For the bill depth, 3 clusters are observed on the Cleveland Plot : this variable might be related to the difference of bill depth between species. For flipper length, the Cleveland plot also reveals three distinct clusters. All these variables seem to follow a Gaussian distribution. Visualizing the distributions of the quantitative \\(X\\) variables allows us to formulate hypotheses regarding species differences and sexual dimorphism.\n\n\n3. Number of Levels and Individuals per Level of Qualitative Predictors (\\(X\\))\n\n\n   Adelie Chinstrap    Gentoo \n      146        68       119 \n\n\nfemale   male \n   165    168 \n\n\nFor the species variable, Chinstrap is a bit under-represented in comparison to other species. We will keep the variable for the model as it may capture important differences between groups. For the sex variable, the number of observations is almost equivalent for the male and female groups.\n\n\n4. Analysis of the Potential Relationships Between \\(Y\\) and the \\(Xs\\)\nNow, we can explore the potential relationship between the response variable \\(Y\\) (body_mass_g) and the \\(Xs\\) variables. Keep in mind that this part of the analysis is based on graphs and doesn‚Äôt tell us if the relationships between variables are significant or not.\n\n\n\n\n\n\n\n\n\nThere appears to be a positive linear relationship between body mass and other quantitative variables. A sexual dimorphism is observed : females tend to have a lower body mass than males. In addition, there may be species differences : Gentoo penguins appear to have higher body mass compared to Adelie and Chinstrap penguins, which have similar body mass measurements.\n\n\n5. Analysis of possible interactions between both independent variables\nThis section aims to check for potential interaction effects between the two qualitative variables. To do so, all combinations of their categories must be present in the data.\n\n\n           \n            female male\n  Adelie        73   73\n  Chinstrap     34   34\n  Gentoo        58   61\n\n\nAll categories are present and well balanced across the factors, allowing us to test for potential interactions between them.\n\n\n\n\n\n\n\n\n\nMales appear to have a higher body mass than females for the three species. The difference between males and females may vary a little depending on the species. There may be a small interaction between the tow factors sex and species.\nThen, we also check for potential interactions between explanatory quantitative variables and explanatory qualitative variables, using the following graphs.\n\n\n\n\n\n\n\n\n\nObservations regarding possible interactions :\nBill length and sex : there is a possible interaction. For some values of bill length, body mass is higher for males than females but for some values the opposite is true and females have a higher body mass than males.\nBill length and species : there are three color clusters that do not appear to mix on the graph. Individuals of the Gentoo species appear to have a higher body mass than the other species, but sometimes slightly lower depending on bill length values. A small interaction is possible.\nBill depth and sex : there appears to be no interaction between bill depth and sex. The relation between body mass and bill depth is the same for males and females and males body mass is higher than females body mass.\nBill depth and species : there appears to be no interaction between bill depth and species. The relation between body mass and bill depth observed previously during the data exploration is the same and the Gentoo species still stands out in terms of body mass : individuals of the Gentoo species still appear to have a higher body mass than the other species.\nFlipper length and sex : there is a possible interaction. Body mass appears to increase with flipper length but for some values of flipper length, females can have a higher body mass than males.\nFlipper length and species : there appears to be no interaction between flipper length and species. The relation between body mass and bill length observed previously during the data exploration is the same regardless the species and the Gentoo species still stands out in terms of body mass, which remains higher than the body of the other species on the graph.\nThese are only observations. For the moment, we don‚Äôt know which interactions are significant. This will be tested afterwards.\n\n\n6. Check for Collinearity Between Predictors (\\(Xs\\))\nCollinearity must be avoided in modeling. Indeed, collinearity can affect the modeling and significance of variables in the model, therefore the conclusions of the study are affected. Let‚Äôs check how the explanatory variables are related.\n\n\ncorrplot 0.95 loaded\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThis verification of collinearity between \\(Xs\\) revealed a positive correlation between Flipper Length and Bill Length. The coefficient is below the threshold of 0.7, so we will not exclude either of these variables.\nNote : In some cases, there may be a strong correlation between a specific variable and some other variables, with a high correlation coefficient (greater than 0.7, which is the threshold set in most cases). This situation can lead you to exclude this specific variable but you always need to justify your choice.\nConcerning the other variables : For bill length, bill depth and flipper length, we observe a small difference between males and females. It looks like Adelie penguins have a shorter bill length than to the two other species. It appears Gentoo penguins have a smaller bill depth and bigger flipper length than the other species.\n\n\n\nMODEL AND STATSTICAL ANALYSIS\nOnce the data exploration is done, we can focus on finding the model that is adapted to our study. First, we write a full model including all variables presented before and possible interactions between them. Then, the goal is to obtain a fitted model (candidate model) that we can analyze in order to identify the main effects on our response variable body_mass_g. This candidate model can be obtained thanks to a selection based on Akaike Information Criterion (AIC). After selection, the conditions of the linear model (i.e.¬†independence of residuals, normality of residuals and homoscedasticity ) must be validated before making interpretations and conclusions.\nFirstly, let‚Äôs write the full model, including all variables and possible interactions.\n\nmod_penguins&lt;-lm(body_mass_g ~ bill_length_mm\n        + bill_depth_mm\n        + flipper_length_mm\n        + species\n        + sex\n        + sex : species\n        + sex : bill_length_mm\n        + sex : bill_depth_mm\n        + sex : flipper_length_mm\n        + species : bill_length_mm\n        + species : bill_depth_mm\n        + species : flipper_length_mm\n        , data=penguins)\n\n#We check for significance\ndrop1(mod_penguins,test=\"F\")\n\nSingle term deletions\n\nModel:\nbody_mass_g ~ bill_length_mm + bill_depth_mm + flipper_length_mm + \n    species + sex + sex:species + sex:bill_length_mm + sex:bill_depth_mm + \n    sex:flipper_length_mm + species:bill_length_mm + species:bill_depth_mm + \n    species:flipper_length_mm\n                          Df Sum of Sq      RSS    AIC F value  Pr(&gt;F)  \n&lt;none&gt;                                 24459504 3767.1                  \nspecies:sex                2    489389 24948893 3769.7  3.1513 0.04415 *\nbill_length_mm:sex         1     11498 24471002 3765.2  0.1481 0.70064  \nbill_depth_mm:sex          1    265531 24725035 3768.7  3.4196 0.06536 .\nflipper_length_mm:sex      1     36725 24496229 3765.6  0.4730 0.49214  \nbill_length_mm:species     2      5327 24464832 3763.1  0.0343 0.96628  \nbill_depth_mm:species      2      5153 24464657 3763.1  0.0332 0.96737  \nflipper_length_mm:species  2    137527 24597032 3764.9  0.8856 0.41350  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nNow, we have to select the significant terms of the model, based on the AIC, with a forward-backward selection method.\n\nlibrary(MASS)\nmod_final &lt;- stepAIC(mod_penguins, direction = \"both\")\n\nStart:  AIC=3767.06\nbody_mass_g ~ bill_length_mm + bill_depth_mm + flipper_length_mm + \n    species + sex + sex:species + sex:bill_length_mm + sex:bill_depth_mm + \n    sex:flipper_length_mm + species:bill_length_mm + species:bill_depth_mm + \n    species:flipper_length_mm\n\n                            Df Sum of Sq      RSS    AIC\n- bill_depth_mm:species      2      5153 24464657 3763.1\n- bill_length_mm:species     2      5327 24464832 3763.1\n- flipper_length_mm:species  2    137527 24597032 3764.9\n- bill_length_mm:sex         1     11498 24471002 3765.2\n- flipper_length_mm:sex      1     36725 24496229 3765.6\n&lt;none&gt;                                   24459504 3767.1\n- bill_depth_mm:sex          1    265531 24725035 3768.7\n- species:sex                2    489389 24948893 3769.7\n\nStep:  AIC=3763.13\nbody_mass_g ~ bill_length_mm + bill_depth_mm + flipper_length_mm + \n    species + sex + species:sex + bill_length_mm:sex + bill_depth_mm:sex + \n    flipper_length_mm:sex + bill_length_mm:species + flipper_length_mm:species\n\n                            Df Sum of Sq      RSS    AIC\n- bill_length_mm:species     2      4294 24468950 3759.2\n- flipper_length_mm:species  2    160194 24624851 3761.3\n- bill_length_mm:sex         1     13815 24478472 3761.3\n- flipper_length_mm:sex      1     38162 24502818 3761.7\n&lt;none&gt;                                   24464657 3763.1\n- bill_depth_mm:sex          1    279275 24743932 3764.9\n- species:sex                2    493957 24958614 3765.8\n+ bill_depth_mm:species      2      5153 24459504 3767.1\n\nStep:  AIC=3759.19\nbody_mass_g ~ bill_length_mm + bill_depth_mm + flipper_length_mm + \n    species + sex + species:sex + bill_length_mm:sex + bill_depth_mm:sex + \n    flipper_length_mm:sex + flipper_length_mm:species\n\n                            Df Sum of Sq      RSS    AIC\n- flipper_length_mm:species  2    162193 24631143 3757.4\n- bill_length_mm:sex         1     17259 24486209 3757.4\n- flipper_length_mm:sex      1     37020 24505970 3757.7\n&lt;none&gt;                                   24468950 3759.2\n- bill_depth_mm:sex          1    279677 24748627 3761.0\n+ bill_length_mm:species     2      4294 24464657 3763.1\n+ bill_depth_mm:species      2      4119 24464832 3763.1\n- species:sex                2    713112 25182063 3764.8\n\nStep:  AIC=3757.39\nbody_mass_g ~ bill_length_mm + bill_depth_mm + flipper_length_mm + \n    species + sex + species:sex + bill_length_mm:sex + bill_depth_mm:sex + \n    flipper_length_mm:sex\n\n                            Df Sum of Sq      RSS    AIC\n- bill_length_mm:sex         1     10167 24641310 3755.5\n- flipper_length_mm:sex      1     29550 24660693 3755.8\n&lt;none&gt;                                   24631143 3757.4\n- bill_depth_mm:sex          1    266553 24897696 3759.0\n+ flipper_length_mm:species  2    162193 24468950 3759.2\n- species:sex                2    565896 25197039 3761.0\n+ bill_depth_mm:species      2     27765 24603378 3761.0\n+ bill_length_mm:species     2      6292 24624851 3761.3\n\nStep:  AIC=3755.53\nbody_mass_g ~ bill_length_mm + bill_depth_mm + flipper_length_mm + \n    species + sex + species:sex + bill_depth_mm:sex + flipper_length_mm:sex\n\n                            Df Sum of Sq      RSS    AIC\n- flipper_length_mm:sex      1     37776 24679085 3754.0\n&lt;none&gt;                                   24641310 3755.5\n- bill_depth_mm:sex          1    257321 24898631 3757.0\n+ bill_length_mm:sex         1     10167 24631143 3757.4\n+ flipper_length_mm:species  2    155101 24486209 3757.4\n+ bill_depth_mm:species      2     27924 24613386 3759.1\n+ bill_length_mm:species     2      6041 24635269 3759.4\n- bill_length_mm             1    569156 25210466 3761.1\n- species:sex                2   1469480 26110790 3770.8\n\nStep:  AIC=3754.04\nbody_mass_g ~ bill_length_mm + bill_depth_mm + flipper_length_mm + \n    species + sex + species:sex + bill_depth_mm:sex\n\n                            Df Sum of Sq      RSS    AIC\n&lt;none&gt;                                   24679085 3754.0\n- bill_depth_mm:sex          1    227028 24906114 3755.1\n+ flipper_length_mm:sex      1     37776 24641310 3755.5\n+ bill_length_mm:sex         1     18392 24660693 3755.8\n+ flipper_length_mm:species  2    144807 24534278 3756.1\n+ bill_depth_mm:species      2     29046 24650039 3757.6\n+ bill_length_mm:species     2      5566 24673520 3758.0\n- bill_length_mm             1    624289 25303375 3760.4\n- species:sex                2   1492684 26171770 3769.6\n- flipper_length_mm          1   2614245 27293330 3785.6\n\n\nWe can then use the coefficient given by the model :\n\nsummary(mod_final)\n\n\nCall:\nlm(formula = body_mass_g ~ bill_length_mm + bill_depth_mm + flipper_length_mm + \n    species + sex + species:sex + bill_depth_mm:sex, data = penguins)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-733.83 -172.09  -13.83  173.04  851.00 \n\nCoefficients:\n                          Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)              -2357.334    689.805  -3.417 0.000713 ***\nbill_length_mm              19.673      6.882   2.858 0.004534 ** \nbill_depth_mm              105.463     27.955   3.773 0.000192 ***\nflipper_length_mm           16.692      2.854   5.849 1.21e-08 ***\nspeciesChinstrap           -87.133     85.150  -1.023 0.306941    \nspeciesGentoo             1088.532    142.221   7.654 2.27e-13 ***\nsexmale                   1605.642    682.022   2.354 0.019159 *  \nspeciesChinstrap:sexmale  -360.629     82.067  -4.394 1.51e-05 ***\nspeciesGentoo:sexmale     -173.404    144.087  -1.203 0.229674    \nbill_depth_mm:sexmale      -64.106     37.190  -1.724 0.085708 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 276.4 on 323 degrees of freedom\nMultiple R-squared:  0.8854,    Adjusted R-squared:  0.8822 \nF-statistic: 277.1 on 9 and 323 DF,  p-value: &lt; 2.2e-16\n\n\nWe can write the full model :\n\\[ Body\\:mass = -2357,33 \\:+\\: 19,67.Bill\\:length\\:+\\: 105,46.Bill\\:depth\\\\ \\:+\\: 16,69.Flipper\\:length \\:-\\: 87,13.Species\\:Chinstrap \\:+\\: 1088,53.Species\\:Gentoo\\\\ \\:+\\: 1605,64.Sex\\:male \\:-\\: 360,63.Species\\:Chinstrap:Sex\\:male\\\\ \\:-\\: 173,40.Species\\:Gentoo:Sex\\:male \\:-\\: 63,11.Bill\\:depth:Sex\\:male\\]\nWe can explain the part of the variance explained by the model, by using the adjusted R^2^.\n\nsummary(mod_final)\n\n\nCall:\nlm(formula = body_mass_g ~ bill_length_mm + bill_depth_mm + flipper_length_mm + \n    species + sex + species:sex + bill_depth_mm:sex, data = penguins)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-733.83 -172.09  -13.83  173.04  851.00 \n\nCoefficients:\n                          Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)              -2357.334    689.805  -3.417 0.000713 ***\nbill_length_mm              19.673      6.882   2.858 0.004534 ** \nbill_depth_mm              105.463     27.955   3.773 0.000192 ***\nflipper_length_mm           16.692      2.854   5.849 1.21e-08 ***\nspeciesChinstrap           -87.133     85.150  -1.023 0.306941    \nspeciesGentoo             1088.532    142.221   7.654 2.27e-13 ***\nsexmale                   1605.642    682.022   2.354 0.019159 *  \nspeciesChinstrap:sexmale  -360.629     82.067  -4.394 1.51e-05 ***\nspeciesGentoo:sexmale     -173.404    144.087  -1.203 0.229674    \nbill_depth_mm:sexmale      -64.106     37.190  -1.724 0.085708 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 276.4 on 323 degrees of freedom\nMultiple R-squared:  0.8854,    Adjusted R-squared:  0.8822 \nF-statistic: 277.1 on 9 and 323 DF,  p-value: &lt; 2.2e-16\n\n\nThe value of the adjusted R^2^ is equal to 0.88. It means that 88% of the variance of the body mass of penguins is explained by the relation given by mod_final.\n\n\n\n\n\nReferences\n\nAbelMasson. n.d. https://github.com/AbelMasson.\n\n\nGorman, Tony D. AND Fraser, Kristen B. AND Williams. 2014. ‚ÄúEcological Sexual Dimorphism and Environmental Variability Within a Community of Antarctic Penguins (Genus Pygoscelis).‚Äù PLOS ONE 9 (3): 1‚Äì14. https://doi.org/10.1371/journal.pone.0090081.\n\n\nHorst, Allison Marie, Alison Presmanes Hill, and Kristen B Gorman. 2020. Palmerpenguins: Palmer Archipelago (Antarctica) Penguin Data. https://doi.org/10.5281/zenodo.3960218.\n\n\nOutreman, Yannick. n.d. https://sites.google.com/site/yannickoutreman/home."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Statistics to explore environmental questions",
    "section": "",
    "text": "This website is produced by the M2 MODE student during year 2025-2026 as part of their assignment in the Online Collaborative Resources course.\nThey were asked to produce collaboratively different illustrations on ecological data for different statistical and mathematical models.\nJust click on one of the three menus on top right side of this page to visit their work. They have used up to data version control workflows to produce this website using git Github, Pull Request, Code review. A set of good practices to help them producible research in the futur.\nThe website is fully generated using Continuous Integration (CI) based on Github Action."
  },
  {
    "objectID": "Penguins_chapter.html",
    "href": "Penguins_chapter.html",
    "title": "Exploration donn√©es sur les manchots",
    "section": "",
    "text": "Pourquoi manchot se traduit Penguins en anglais ?\n(O)&gt; ( ) W\n(O)&gt; ( ) W\n(O)&gt; ( ) W\n\nlibrary(tidyverse)\n\n‚îÄ‚îÄ Attaching core tidyverse packages ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ tidyverse 2.0.0 ‚îÄ‚îÄ\n‚úî dplyr     1.1.4     ‚úî readr     2.1.5\n‚úî forcats   1.0.0     ‚úî stringr   1.5.2\n‚úî ggplot2   4.0.0     ‚úî tibble    3.3.0\n‚úî lubridate 1.9.4     ‚úî tidyr     1.3.1\n‚úî purrr     1.1.0     \n‚îÄ‚îÄ Conflicts ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ tidyverse_conflicts() ‚îÄ‚îÄ\n‚úñ dplyr::filter() masks stats::filter()\n‚úñ dplyr::lag()    masks stats::lag()\n‚Ñπ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\nles magnifiques pingouins : (O)&gt; ( ) W\n\ndata &lt;- read.table(\"penguins_raw.csv\", sep = \",\" , header = TRUE)\n\nA citation Alston and Rick (2021)\n\nReferences\n\n\nAlston, Jesse M, and Jessica A Rick. 2021. ‚ÄúA Beginner‚Äôs Guide to Conducting Reproducible Research.‚Äù Bulletin of the Ecological Society of America 102 (2): 1‚Äì14."
  },
  {
    "objectID": "EDO_LOKTA_VOLTERA.html",
    "href": "EDO_LOKTA_VOLTERA.html",
    "title": "EDO pr√©dation",
    "section": "",
    "text": "## Packages\nsuppressPackageStartupMessages({\n  library(ggplot2)\n  library(dplyr)\n  library(tidyr)\n})\n\nMAIN QUESTION : How can we model the evolution of the dynamics between lynxes and hares ?\nINTRODUCTION :\nWhen having a dynamic system modeled by an Ordinary Differential Equation (ODE), we usually can‚Äôt find a mathematical solution. Thus, we have 2 options : a numerical approach and a qualitative one. Here, we will focus on the latter, that is to say qualitatively predict the evolution (in terms of behavior) of N(t) (the number of the population at time t), in particular asymptotically.\nLooking at lynx and hare pelts from the Hudson‚Äôs Bay Company‚Äôs (fur-collecting) trappers‚Äô hunts over a 90-year period, we see that the number of hare and lynx pelts is correlated. If we assume that the number of pelts collected is proportional to the total population, then we arrive at the conclusion that the hare and lynx population is correlated with a phase shift of a few years for the lynx (Elton & Nicholson, 1942).\nWhat is the intuition behind this? Lynxes need hares to survive, and so the lynx population can only grow if the hare population grows. There‚Äôs a time lag: when the lynx population is low, the hare population begins to grow. The lynxes then begin to have food again, and will then grow again and begin to massacre a large part of the hare population, only to run out of food. Then the cycle begins again.\n\n\n\n\n\n\n\n\n\nLogistic Prey-Predator model (in a limited environment) :\n\\[\n\\begin{cases}\n\\frac{dN}{dt}=r_1N(1-\\frac{N}{K})-b_1NP \\\\\n\\frac{dP}{dt}=-r_2P+b_2NP\n\\end{cases}\n\\]\nThe parameters are the following ones (they are all positive :) ) :\n\n\n\nParameters\nMeaning\n\n\n\n\n\\(r_{1}\\)\ngrowth rate of preys‚Äô population\n\n\n\\(r_{2}\\)\ndeath rate of predators‚Äô population\n\n\n\\(b_{1}\\)\npredation efficiency\n\n\n\\(b_{2}\\)\npredation yield\n\n\n\\({K}\\)\nbiotic capacity\n\n\n\nIn such conditions, we expect the populations dynamics to evolve in different ways according to parameters value and initials conditions (the size of both population). We can relatively easily assume that a big predator‚Äôs population paired with a high predation efficiency would lead prey‚Äôs population to go extinct and, shortly after, predator‚Äôs population is expected to follow the same dynamic. The question we may now ask ourselves is the following :\nHow would the system evolve according to parameters and initials conditions variation?\nThis is where qualitative analysis steps in. But first let‚Äôs do a little bit of math.\nEquilibrium points and isoclines\nLet‚Äôs start with a bit of vocabulary, in qualitative analysis we call equilibrium points all values of N for which the derivative is 0. Mathematically it‚Äôs expressed as following : \\[\n\\frac{dN}{dt}=0\\;\\Longleftrightarrow\\;f(N^{*})=0 \\\\\n\\]\n\\[\n\\text{with}\\;\\ \\frac{dN}{dt}=f(N)\n\\]\nFor equation system such as Lotka-Volterra it would be as following : \\[\n\\begin{cases} \\frac{dN_{1}}{dt}=0 \\\\ \\frac{dN_{2}}{dt}=0 \\end{cases} \\;\\Longleftrightarrow\\; \\begin{cases} f_{1}(N1^{*},N2^{*})=0 \\\\ f_{2}(N1^{*},N2^{*})=0 \\end{cases}\\\\\n\\]\n\\[\n\\text{with}\\;\\ \\begin{cases} \\frac{dN_{1}}{dt}=f_{1}(N1,N2) \\\\ \\frac{dN_{2}}{dt}=f_{2}(N1,N2) \\end{cases}\n\\] Those equilibrium points carry the information about the population sizes at which the system does not change. They can be either locally asymptotically stable (LAS), unstable (repeller) and in the case the system has more than one differential equation, saddle points may appear. Around LAS points, system will go towards the equilibrium, around repeller points, system will tend to move away from equilibrium. As for saddle points, depending on the area the system will go toward or away the equilibrium\nIn contrast to equilibrium points, where all derivative must be equal to zero, isoclines correspond to lines for which an equation of the system is individually equal to zero. Mathematically it‚Äôs expressed as following :\n\\[\n*\\text{Isoclines $N_{1}$ :} \\\\\n\\frac{dN_{1}}{dt}=0 \\;\\Longleftrightarrow\\; f_{1}(N1,N2)=0 \\\\\n\\]\n\\[\n\\text{Isoclines $N_{2}$ :}\\\\\n\\frac{dN_{2}}{dt}=0\\;\\Longleftrightarrow\\; f_{2}(N1,N2)=0 \\\\\n\\]\n\\[\n\\text{With}\\;\\begin{cases} \\frac{dN_{1}}{dt}=f_{1}(N1,N2) \\\\ \\frac{dN_{2}}{dt}=f_{2}(N1,N2) \\end{cases}\n\\]\nPlotting those isoclines on a phase plane allows us to identify some areas where the system may evolve in different ways. We can then examine the behavior of each population in the previously defined area , allowing to characterize the system overall behavior.\nAll of that is analytically calculable for some systems of differential equation system (including Lotka-Volterra logistic), but lazy as we are, we will focus on numerically approximate those solutions.\nNumerical approximation of equilibrium points and phase plane\nThe first step to numerical approximation of equilibrium points and drawing a phase plan is to define the function, following the syntaxe below. We also define some parameter values for our function.\n\nProiepred&lt;- function(t, y, parameters) {\n  # Here we define the initial condition from the vector\n  # The order of initial condition must be the following : y=c(prey,predator)\n  N &lt;- y[1]\n  P &lt;- y[2]\n  # Here we define the parameter from the vector\n  # The order must be the following : parameters=c(r1,r2,b1,b2,K)\n  r1 &lt;- parameters[1]\n  r2 &lt;- parameters[2]\n  b1 &lt;- parameters[3]\n  b2 &lt;- parameters[4]\n  K &lt;- parameters[5]\n  # On impl√©mente nos √©quations diff√©rentielles\n  dPop &lt;- numeric(2)\n  dPop[1] &lt;- r1*N*(1-N/K) - b1*N*P\n  dPop[2] &lt;- - r2*P + b2*N*P\n  list(dPop)\n}\n#On d√©finit nos param√®tres\nparameters1 &lt;- c(r1 = 0.5, r2 = 0.3, b1 = 0.02, b2 = 0.01,K=50)\n\nNow that the function is defined, we can use the package ‚ÄòphaseR‚Äô to draw a phase plan and draw the isocline using function flowField and nullclines.\n\n# Loading the library\nlibrary(phaseR)\n# Defining the limit for the studied window by flowField\nxlim &lt;- c(0, 50)\nylim &lt;- c(0, 50)  \n\n\n# Generating a phase plan for our equation \nflowField(\n  deriv = Proiepred,\n  xlim = xlim,\n  ylim = ylim,\n  parameters = parameters1,\n  system=\"two.dim\",\n  add=FALSE,\n  tend=100, xlab=\"Prey\", ylab=\"Predator\"\n  )\n# Generating the isoclines for our equation\nnullclines(Proiepred,xlim=c(-10,100),ylim=c(-10,100),parameters = parameters1, points = 500,add.legend = FALSE,add = TRUE)\ntrajectory(Proiepred,y0=c(40,40),tlim=c(0,100),parameters=parameters1)\n\n\n\n\n\n\n\n\n\nsimul_traj(N_0= 40,\n           P_0= 40,\n           t_end= 50,\n           pas= 1,\n           r1= 0.5,\n           b1= 0.02,\n           r2= 0.3,\n           b2= 0.01,\n           K= 50)\n\n\n\n\n\n\n\n\nFrom this graphic we could already interpret the isoclines and the equilibrium point. We can also use the function findEquilibrium to discuss those equilibrium points. We can approximate the equilibrium points from the graphic, looking at the intersect of isoclines.\n# Approximating the equilibrium point around the isocline intersection at (0,0)\neq0 &lt;- findEquilibrium(Proiepred, y0 = c(N=0, P=0), parameters = parameters1)\n# Approximating the equilibrium point around the isocline intersection at (30,15)\neq1 &lt;- findEquilibrium(Proiepred, y0 = c(N=30, P=15), parameters = parameters1)\n# Approximating the equilibrium point around the isocline intersection at (50,0)\neq2 &lt;- findEquilibrium(Proiepred, y0 = c(N=50, P=0), parameters = parameters1)\n\n\n$eq0_classification\n[1] \"Saddle\"\n\n$eq1_classification\n[1] \"Stable focus\"\n\n$eq2_classification\n[1] \"Saddle\"\n\n\nWe can now see that there is three equilibrium points for the Lotka-Volterra logistic function, two of them are saddle : (0,0) , (50, 0). The equilibrium points at (30,10) is a stable point, both population will tend to stabilize around the third equlibrium point as time goes on.\nWe may now question ourselves, what is the impact of initial parameters for our system?\nLet‚Äôs repeat the process but with different parameters values :)\n\n# Defining the limit for the studied window by flowField\nparameters2 &lt;- c(r1 = 0.5, r2 = 0.3, b1 = 0.02, b2 = 0.01,K=25)\nxlim &lt;- c(0, 50)  # N\nylim &lt;- c(0, 50)  # P\nflowField(\n  deriv = Proiepred,\n  xlim = xlim,\n  ylim = ylim,\n  parameters = parameters2,\n  system=\"two.dim\",\n  add=FALSE,\n  tend=100, xlab=\"Prey\", ylab=\"Predator\"\n  )\nnullclines(Proiepred,xlim=c(-10,100),ylim=c(-10,100),parameters = parameters2, points = 500,add.legend = FALSE,add = TRUE)\ntrajectory(Proiepred,y0=c(40,40),tlim=c(0,100),parameters=parameters2)\n\n\n\n\n\n\n\n\n\nsimul_traj(N_0= 40,\n           P_0= 40,\n           t_end= 50,\n           pas= 1,\n           r1= 0.5,\n           b1= 0.02,\n           r2= 0.3,\n           b2= 0.01,\n           K= 25)\n\n\n\n\n\n\n\n\nAfter changing the parameter values, it now appears that there is only two equilibrium points! But what about their stability?\n\neq0 &lt;- findEquilibrium(Proiepred, y0 = c(N=0, P=0), parameters = parameters2)\neq1 &lt;- findEquilibrium(Proiepred, y0 = c(N=25, P=0), parameters = parameters2)\n\n\n\n$eq0_classification\n[1] \"Saddle\"\n\n$eq1_classification\n[1] \"Stable node\"\n\n\nThe equilibrium point at (0,0) is still a saddle point, both population aren‚Äôt supposed to go extinct. But the second equilibrium point changed a lot, it is a saddle point, with predator going towards extinction.\nWhat truly change here?\nWhen going from the first set of parameters to the second we changed a ratio, we went from r2 &lt; K*b2 to r2&gt;K*b2. Phrased differently, we went from a situation where the natural loss in predator population was less than what is gained if the prey population is at the maximum of environmental capacity to a situation where the natural loss exceeds the gain.\nWhen doing numerical approximation of a system, it is important to consider the variation induced by the parameters values. In order to do so, the best way remain the analytic approach.\nBonus : We lied !! In the end, for those who are interested, we are going to describe the analytic approach.\nTo do so, we will introduce the Jacobian Matrix (Fun Fact : it was named after Carl Gustav Jacobi, an important 19th century mathematician who added huge contributions to the field of linear algebra).\nThis matrix is composed of the first-order partial derivatives of a multivariable function. The formula for the Jacobian Matrix is the following :\n\\[\n\\begin{equation}\nJac(N_1, N_2) =\n\\begin{pmatrix}\n\\frac{\\partial f_1}{\\partial N_1} & \\frac{\\partial f_1}{\\partial N_2} \\\\\n\\frac{\\partial f_2}{\\partial N_1} & \\frac{\\partial f_2}{\\partial N_2}\n\\end{pmatrix}\n\\end{equation}\n\\]\nIn contrast with the previous part where we had 2 equations, here we have 4 terms in the matrix, in particular 4 partial derivatives. After finding the fixed points, by resolving the equations detailed in the first part, now we can easily replace the values of \\(N1^{*}\\) and \\(N2^{*}\\) in the Jacobian Matrix and then study the stability of the fixed points.\nIn the analytic approach, the stability of a fixed point (\\(N1^{*}\\), \\(N2^{*}\\)) is related to the signs of the real parts of the eigenvalues ‚Äã‚Äãof \\(Jac(N1^{*},N2^{*})\\):\n\n(\\(N1^{*}\\), \\(N2^{*}\\)) is locally asymptotically stable (LAS) if all its eigenvalues are (with real parts) &lt;0\n(\\(N1^{*}\\), \\(N2^{*}\\)) is unstable otherwise, including:\nrepulsor if all eigenvalues ‚Äã‚Äãare (with real parts) &gt;0\nsaddle point if some eigenvalues are (with real parts) &lt;0 and the others (with real parts) &gt;0.\n\nBecause the matrix \\(Jac(N1^{*},N2^{*})\\) is of dimension 2, it has exactly two eigenvalues and we can calculate the Trace (sum of the eigenvalues ) and the Determinant (product of the eigenvalues) of the Jacobian Matrix which will help us to determine the stability of the fixed points. If a Jacobian Matrix is defined as followed :\n\\[\n\\begin{equation}\nJac(N_1^*, N_2^*) =\n\\begin{pmatrix}\na & b \\\\\nc & d\n\\end{pmatrix}\n\\end{equation}\n\\]\nThe Trace and the Determinant correspond to : ùëáùëüùëéùëêùëí = ùëé + ùëë and ùê∑ùëíùë° = ùëéùëë ‚àí ùëèùëê.\nIn particular,\n\n(\\(N1^{*}\\), \\(N2^{*}\\)) is locally asymptotically stable (LAS) if Trace &lt;0 and Det &gt;0.\n(\\(N1^{*}\\), \\(N2^{*}\\)) is repulsor if Trace &gt; 0 and Det &gt;0.\n(\\(N1^{*}\\), \\(N2^{*}\\)) is saddle point if Det &lt; 0 (whatever the Trace).\n\nLet‚Äôs apply the analytic approach to the logistic Prey-Predator Model, shall we ?\nOur system admits 3 fixed points : (\\({0}\\),\\({0}\\)), (\\({K}\\),\\({0}\\)) and (\\(N^{*}\\), \\(P^{*}\\)) where : \\[\n(N^*, P^*) =\n\\left(\n\\frac{r_2}{b_2},\\;\n\\frac{r_1}{b_1} \\left( 1 - \\frac{r_2}{b_2 K} \\right)\n\\right)\n\\]\nAfter calculating the partial derivatives in the Jacobian Matrix :\n\\[\n\\begin{equation}\nJac(N,P) =\n\\begin{pmatrix}\n(r_1(1 - \\frac{N}{K})-b_1P)-r_1\\frac{N}{K}  & -b_1N \\\\\nb_2P & -r_2 + b_2N\n\\end{pmatrix}\n\\end{equation}\n\\]\nNow we can obtain a Jacobian Matrix for each fixed point :\n\\[\n\\begin{equation}\nJac(0,0) =\n\\begin{pmatrix}\nr_1 & 0 \\\\\n0 & -r_2\n\\end{pmatrix}\n\\end{equation}\n\\]\nFor the first one, we can easily determine the eigenvalues because it is a diagonal matrix, so the eigenvalues are on the diagonal. \\({r_1}\\) &gt; 0 and \\({-r_2}\\) &lt;0, so (\\({0}\\),\\({0}\\)) is a saddle point.\n\\[\n\\begin{equation}\nJac(K,0) =\n\\begin{pmatrix}\n-r_1 & -b_1K \\\\\n0 & -r_2 + b_2K\n\\end{pmatrix}\n\\end{equation}\n\\]\nHere, we have a triangular matrix, so the eigenvalues are also on the diagonal. \\({-r_1}\\) &lt; 0 and \\({-r_2 + b_2K}\\) &lt; 0 if \\({r_2}\\) &gt; \\({b_2K}\\) which makes (\\({K}\\),\\({0}\\)) a LAS and a saddle point otherwise.\nFor the last fixed point (\\(N^{*}\\), \\(P^{*}\\)), \\(r_1(1 - \\frac{N^{*}}{K})-b_1P^{*}\\) = 0 (see the definition of the isocline \\(N\\) : \\(\\frac{dN}{dt} = 0\\) ) because \\({N^{*}}\\) is different from 0.\nThus, the last Jacobian matrix is written as :\n\\[\n\\begin{equation}\nJac(N^{*},P^{*}) =\n\\begin{pmatrix}\n-r_1\\frac{N^{*}}{K} & -b_1N^{*} \\\\\nb_2P & 0\n\\end{pmatrix}\n\\end{equation}\n\\]\nFinally, when calculating the trace and the determinant (see the definitions above), we find a negative trace and a positive determinant for \\(N^{*}\\) and \\(P^{*}\\) positive. So, (\\(N^{*}\\), \\(P^{*}\\)) is a LAS when it interests us.\nCONCLUSION :\nThrough this work, we presented a way to qualitatively analyse the dynamics of a Logistic Prey-Predator Model. Depending on the values of the parameters of the ODE, the nature of the fixed points changes and so the trajectories of the size of the populations do. We identified 3 main situations : the total extinction of both populations (unstable because the lower presence of prey allows the population to grow), survival of prey only at their capacity limit K (stable or unstable depending on the capacity of the predators to persist thanks to the potential gains) and the stable coexistence of the 2 species that only exists if predators can maintain themselves. To summarize, the dynamics of the model illustrate both the mutual dependence and ecological regulation between prey and predator.\nAs a doorway, we could also be interested in qualitatively predicting the solution of a system of more than 2 equations that could model more complex phenomenon (like epidemiological models SIR or SEIR). The definitions of LAS and unstable (repulsor and saddle points) would remain valid but the calculations would be more complicated. Also, we would look at the Routh-Hurwitz criteria in addition of the trace and the determinant and the representation of isoclines and field portraits would be less obvious."
  },
  {
    "objectID": "Linear_Model_2.html",
    "href": "Linear_Model_2.html",
    "title": "GENERALIZED LINEAR MIXED MODEL",
    "section": "",
    "text": "We present here a reminder sheet on Generalized Linear Mixed Models (GLMMs) and its specific features. Its use will be illustrated through a study applied on badgers from Walker et al. (2009) .\nRemark : the concepts covered are taken from our Master‚Äôs courses and tutorials, written and taught by AbelMasson (n.d.) and Outreman (n.d.) .\n\n\nGeneral Linear Models are used to describe the relationship between a continuous response \\(Y\\) and one or more explanatory variables \\(X_{1}\\),\\(X_{2}\\)‚Ä¶\\(X_{p}\\). They rely on three main assumptions : independence of residuals, normality of residuals and homogeneity of variances. However, in many cases, the response variable \\(Y\\) is discrete (for example, counts or binary outcomes).\nFor discrete responses, the variance of \\(Y\\) typically depends on its mean-variance relationship. As a result, the variance is not constant across observations, invalidating the assumption of homogeneity required by linear models. Moreover, fitting a General Linear Model to count data can lead to negative predicted values and non-normal residuals. In shorts, General Linear Models are not well-suited for discrete responses. Hence, we need specific tools to analyse discrete response data. These are Generalized Linear Models (GLMs).\n\n\n\nA GLM extends the classical linear model through three steps :\n\nAssumption of the distribution of the response variable \\(Y_{i}\\)\nThe specification of the systematic part; this is the linear function of the explanatory variables (the linear predictor called \\(\\eta\\))\nThe relationship between the mean value of \\(Y_{i}\\) and the systematic part. This is also called the link between the mean and the systematic part: the link function noted \\(g\\) .\n\nA Generalized Linear Model can be written as : \\[g(\\mu_{y})= \\alpha+ \\beta_{1}.X{i1}+ \\beta_{2}.X{i2}+\\beta_{3}.X{i3}+...\\beta_{p}.X{ip} = \\eta \\]\nThe linear predictor \\(\\eta\\), emerges from the linear model as a sum of the terms for each of the \\(p\\) parameters. This is not a value of \\(Y\\). The value of \\(\\eta\\) is obtained by transforming the value of \\(Y\\) by the link function, and the predicted value of \\(Y\\) is obtained by applying the inverse link function to \\(\\eta\\).\n\n\n\nDepending on the sampling design or the experimental set-up, independence of residuals is often not respected : some statistical units are related. To account for this dependence structure, we can include random effects in the model.\nThe resulting model, called Generalized Linear Mixed Model (GLMM) extends the GLM by adding these random effects alongside the fixed effects. Therefore, GLMMs allow us to model both the relationship between predictors and responses and the non-independence among observations.\n\n\n\n\n\n\n\nBadger picture from Scottish SPCA\n\n\n\n\n\nThe data used come from (Walker2009a?) and consist of signs of badger (Meles meles) activity around farms located in the southwest of England, where badger density is high. This study was carried out in the context of bovine tuberculosis and its possible transmission to cattle through badgers. Reducing the number of farm visits by badgers ‚Äî especially in places where they might come into contact with livestock ‚Äî could help limit the spread of the disease. Thus, the aim of this study is to predict the occurrence of badger activity signs on farms.\nBetween autumn 2003 and summer 2005, a survey was conducted on 36 different farms; the data are therefore longitudinal, since each farm was monitored over eight consecutive seasons. Within the same farm, observations may be temporally autocorrelated.\nThe response variable (presence or absence of signs of badger activity) is binary: it takes the value 1 when signs of activity were detected, and 0 otherwise. Signs of activity include the presence of feces, setts, or feeding traces.\nThe data are available in the file Badger.txt. The variables are:\n\nYear : studied year\nSeason : 1 = spring, 2 = summer, 3 = autumn, 4 = winter\nfarm_code_numeric : farm identifier\nSurvey : survey identifier (time indicator)\nSigns_in_yard : binary indicator of badger activity (response variable)\nNo_setts_in_fields : number of setts\nNo_active_setts_in_fields : number of actively occupied setts\nNo_buildings : number of buildings in the farm\nNo_cattle_in_buildings_yard : number of cattle in building yards\nAccessible_feed_store_present : presence / absence of an accessible feed store\nAccessible_cattle_house_present : presence / absence of a direct access to the cattle house\nAccessible_feed_present : presence / absence of accessible feed in the farm\nGrass_silage : presence / absence of grass silage\nCereal_silage : presence / absence of cereal silage\nHayStraw : presence / absence of hay and / or straw\nCereal_grains : presence / absence of cereal grains\nConcentrates : presence / absence of concentrates\nProteinblocks : presence / absence of protein blocks\nSugarbeet : presence / absence of sugar beet\nVegetables : presence / absence of vegetables\nMolasses : presence / absence of molasses :::\n\n\n\n\n\n# library import\nlibrary(corrplot)\n\ncorrplot 0.95 loaded\n\nlibrary(lme4)\n\nLoading required package: Matrix\n\nlibrary(rsq)\n\n\n# Dataset import\ndataBadger &lt;- read.table(\"Badger.txt\", dec=\".\", header = TRUE)\n\n# Reduce name and change categorical variables as factor\ndataBadger$Activity&lt;- dataBadger$signs_in_yard\ndataBadger$N_setts&lt;-dataBadger$N_setts_in_fields\ndataBadger$N_cattle&lt;-dataBadger$N_cattle_in_buildings_yard\ndataBadger$season&lt;-as.factor(dataBadger$season)\ndataBadger$feed_store&lt;-as.factor(dataBadger$accessible_feed_store_present)\ndataBadger$cattle_house&lt;-as.factor(dataBadger$accessible_cattle_house_present)\ndataBadger$feed&lt;-as.factor(dataBadger$accessible_feed_present)\ndataBadger$grass&lt;-as.factor(dataBadger$grass_silage)\ndataBadger$cereal&lt;-as.factor(dataBadger$cereal_silage)\ndataBadger$straw&lt;-as.factor(dataBadger$hay_straw)\ndataBadger$grains&lt;-as.factor(dataBadger$cereal_grains)\ndataBadger$concen&lt;-as.factor(dataBadger$concentrates)\ndataBadger$sugar&lt;-as.factor(dataBadger$sugar_beet)\ndataBadger$molasses&lt;-as.factor(dataBadger$molasses)\n\n# Check for presence of missing values\ncolSums(is.na(dataBadger))\n\n                             ID                            year \n                              0                               0 \n                         season                       farm_code \n                              0                               0 \n                         survey                   signs_in_yard \n                              0                               0 \n              N_setts_in_fields                     N_buildings \n                              0                               0 \n     N_cattle_in_buildings_yard   accessible_feed_store_present \n                              0                               0 \naccessible_cattle_house_present         accessible_feed_present \n                              0                               0 \n                   grass_silage                   cereal_silage \n                              0                               0 \n                      hay_straw                   cereal_grains \n                              0                               0 \n                   concentrates                      sugar_beet \n                              0                               0 \n                       molasses                        Activity \n                              0                               0 \n                        N_setts                        N_cattle \n                              0                               0 \n                     feed_store                    cattle_house \n                              0                               0 \n                           feed                           grass \n                              0                               0 \n                         cereal                           straw \n                              0                               0 \n                         grains                          concen \n                              0                               0 \n                          sugar \n                              0 \n\n# There is no missing value.\n\n\n\n\nBefore carrying out any statistical modeling, it is essential to perform a thorough data exploration. This step helps identify potential issues such as outliers, collinearity, or imbalanced distributions that could bias the results or invalidate model assumptions.\nBelow is a checklist of preliminary exploratory analyses to perform before modeling:\n\nCheck for outliers and distribution of the dependent variable ($Y$).\nCheck for outliers and distribution of the explicative variable ($X$). If $X$ is quantitative: assess the distribution and presence of outliers. If $X$ is qualitative: analyze the number of levels and the number of observations per level.\nExplore the potential relationships between $Y$ and each $X_i$.\nCheck for potential interactions between explanatory variables ($X_i$).\nAssess multicollinearity among the $X_i$ variables.\n\n\n\nSince $Y$ is a binary variable, it does not have a continuous distribution. Instead, we inspect the frequency of each category (0 and 1) to check for imbalance in the response variable.\n\n# Number of 0 and 1 in Y\ntable(dataBadger$Activity)\n\n\n  0   1 \n233  45 \n\n\n\n\n\nFor continuous independent variables, it is important to:\n\nDetect potential outliers (e.g., extreme or erroneous values)\nVisualize the shape of the distribution (e.g., normal, skewed, multimodal)\nAssess whether transformations (e.g., log, square root) might be needed before modeling\n\nThe following visualizations help achieve this:\n\nCleveland dot plots: to identify potential outliers\nHistograms: to visualize the overall distribution\nQ-Q plots: to assess normality assumptions\n\n\npar(mfrow=c(3,3))\n\n# Number of badger setts on farm\n# Cleveland plot\ndotchart(dataBadger$N_setts,pch=16,col='blue',xlab='Number of setts')\n# Histogram\nhist(dataBadger$N_setts,col='blue',xlab=\"Number of setts\",main=\"\")\n# Quantile-Quantile plot\nqqnorm(dataBadger$N_setts,pch=16,col='blue',xlab='')\nqqline(dataBadger$N_setts,col='red')\n\n# Number of buildings on farm\n# Cleveland plot\ndotchart(dataBadger$N_buildings,pch=16,col='blue',xlab='Number of buildings')\n# Histogram\nhist(dataBadger$N_buildings,col='blue',xlab=\"Number of buildings\",main=\"\")\n# Quantile-Quantile plot\nqqnorm(dataBadger$N_buildings,pch=16,col='blue',xlab='')\nqqline(dataBadger$N_buildings,col='red')\n\n# Number of cattle housed in buildings on farm\n# Cleveland plot\ndotchart(dataBadger$N_cattle,pch=16,col='blue',xlab='Number of cattle')\n# Histogram\nhist(dataBadger$N_cattle,col='blue',xlab=\"Number of cattle\",main=\"\")\n# Quantile-Quantile plot\nqqnorm(dataBadger$N_cattle,pch=16,col='blue',xlab='')\nqqline(dataBadger$N_cattle,col='red')\n\n\n\n\n\n\n\n\nThe exploratory plots show that all three quantitative variables (number of setts, number of buildings, and number of cattle) display right-skewed distributions, with most farms having relatively low values and a few having much higher ones. No extreme or abnormal outliers are clearly visible, although some high values are present, especially for the number of cattle. The Q-Q plots confirm that none of these variables follow a normal distribution.\n\n\n\nFor categorical (factor) variables, it is important to examine the number of levels (categories) and the number of observations in each level. This helps identify potential issues such as:\n\nLevels with very few observations (which may cause estimation problems in statistical models)\nHighly unbalanced distributions between categories\nUnexpected or erroneous category labels\n\nThe following code summarizes the distribution of individuals across levels for each categorical predictor:\n\n# Factor season\nsummary(dataBadger$season)\n\n 1  2  3  4 \n70 67 69 72 \n\n# Factor feed_store\nsummary(dataBadger$feed_store)\n\n  0   1 \n 49 229 \n\n# Factor cattle_house \nsummary(dataBadger$cattle_house )\n\n  0   1 \n 91 187 \n\n# Factor feed\nsummary(dataBadger$feed)\n\n  0   1 \n 47 231 \n\n# Factor grass\nsummary(dataBadger$grass)\n\n  0   1 \n171 107 \n\n# Factor cereal\nsummary(dataBadger$cereal)\n\n  0   1 \n199  79 \n\n# Factor straw\nsummary(dataBadger$straw)\n\n  0   1 \n107 171 \n\n# Factor grains\nsummary(dataBadger$grains)\n\n  0   1 \n165 113 \n\n# Factor concen\nsummary(dataBadger$concen)\n\n  0   1 \n142 136 \n\n# Factor sugar\nsummary(dataBadger$sugar)\n\n  0   1 \n255  23 \n\n\nThe categorical variables show that most factors are binary, with varying levels of balance between categories. For example, variables such as feed_store, cattle_house, and feed display moderate imbalance, with one category being more frequent than the other. The season variable has four well-represented levels, each containing a similar number of observations, which ensures adequate variability for analysis. Overall, the categorical predictors appear suitable for modeling.\n\n\n\nTo gain preliminary insight into the relationships between the response variable (Activity) and the predictors, both quantitative and categorical variables were explored graphically.\nScatterplots were used to visualize how badger activity varies with continuous predictors such as the number of setts, number of buildings and number of cattle housed. These visual analyses provide a first impression of potential patterns, dependencies, or nonlinear relationships that may influence badger activity on farms.\n\npar(mfrow=c(1,3))\n# Number of setts\nplot(dataBadger$Activity~dataBadger$N_setts,pch=16,col='blue',xlab='Number of setts',ylab='Presence of a sign of badger activity')\n\n# Number of buildings\nplot(dataBadger$Activity~dataBadger$N_buildings,pch=16,col='blue',xlab='Number of buildings',ylab='Presence of a sign of badger activity')\n\n# Number of cattle housed in buildings\nplot(dataBadger$Activity~dataBadger$N_cattle,pch=16,col='blue',xlab='Number of cattle',ylab='Presence of a sign of badger activity')\n\n\n\n\n\n\n\npar(mfrow=c(2,5))\n# Factor season\nmosaicplot(dataBadger$Activity~dataBadger$season\n           ,color=c('blue3','red2')\n           ,main=\"Activity & Season\")\n\n# Factor feed store\nmosaicplot(dataBadger$Activity~dataBadger$feed_store\n           ,color=c('blue3','red2')\n           ,main=\"Activity & Feed store\")\n\n# Factor cattle_house \nmosaicplot(dataBadger$Activity~dataBadger$cattle_house\n           ,color=c('blue3','red2')\n           ,main=\"Activity & cattle house\")\n\n# Factor feed\nmosaicplot(dataBadger$Activity~dataBadger$feed\n           ,color=c('blue3','red2')\n           ,main=\"Activity & feed\")\n# Factor grass\nmosaicplot(dataBadger$Activity~dataBadger$grass\n           ,color=c('blue3','red2')\n           ,main=\"Activity & Grass\")\n# Factor cereal\nmosaicplot(dataBadger$Activity~dataBadger$cereal\n           ,color=c('blue3','red2')\n           ,main=\"Activity & Cereal\")\n# Factor straw\nmosaicplot(dataBadger$Activity~dataBadger$straw\n           ,color=c('blue3','red2')\n           ,main=\"Activity & Straw\")\n# Factor grains\nmosaicplot(dataBadger$Activity~dataBadger$grains\n           ,color=c('blue3','red2')\n           ,main=\"Activity & Grains\")\n# Factor concen\nmosaicplot(dataBadger$Activity~dataBadger$concen\n           ,color=c('blue3','red2')\n           ,main=\"Activity & Concentrates\")\n# Factor sugar\nmosaicplot(dataBadger$Activity~dataBadger$sugar\n           ,color=c('blue3','red2')\n           ,main=\"Activity & Sugar Beet\")\n\n\n\n\n\n\n\n\nThese visual analyses provide an initial understanding of how badger activity may relate to farm characteristics. The scatterplots show that no clear linear relationship exists between badger activity and the number of setts, buildings, or cattle, although activity tends to occur slightly more often on farms with more setts or larger cattle numbers. The mosaic plots complement this by revealing possible associations between activity and certain categorical management factors, such as the presence of feed stores, cattle housing, or specific feeding practices.\n\n\n\nHere, given the large number of predictors, we will not include interactions in modelling\n\n\n\nTo avoid multicollinearity issues during modeling, the relationships among predictor variables were examined. This step includes:\n\nEvaluating correlations between the three quantitative variables\nAssessing potential overlap between categorical factors\nExploring whether categorical predictors influence quantitative ones through boxplots\n\nGiven the large number of predictors, only key results are summarized below.\n\n# Checking collinearity between the 3 quantitative independent variables\n\n# We represent plot for each X continuous covariate pairs\nplot(dataBadger[7:9],pch=16,col='blue')\n\n\n\n\n\n\n\n#We calculate correlation between each pair of X covariate\nM&lt;-cor(dataBadger[7:9])\ncorrplot.mixed(M,upper=\"square\",lower.col=\"black\", tl.col=\"black\",cl.cex = 0.8,tl.cex = 0.7,number.cex =0.8)\n\n\n\n\n\n\n\n# Checking collinearity between  categorical independent variables\n# produce all crossed tables between pairs of factors - not detailed here\n\n# Checking collinearity between categorical and quantitative independent variables\n# for each quantitative independent variable, use boxplot graphics to check whether factors influence it - not detailed here\n\nThe collinearity analysis indicates that the three quantitative variables are largely independent. A moderate positive correlation (r ‚âà 0.52) is observed between the number of buildings and the number of cattle in the yard, suggesting a slight interdependence between these two variables. In contrast, the number of setts in fields shows almost no correlation with the others (r close to 0). Overall, no strong collinearity is detected, allowing these predictors to be retained for further modelling without major redundancy concerns.\n\n\n\n\nBecause the response variable is binary, we will use a Generalized Linear Mixed Model (GLMM) to examine how the different predictors influence badger activity. We assume that badger activity follows a binomial distribution, and we will therefore use a logit link function. The farm code is included as a random effect, to take into account the temporal autocorrelation between observations.\n\n\nThe best model is identified using a backward selection procedure. This model selection method is based on the Akaike Information Criterion (AIC), which allows to take into account both the goodness of fit and the simplicity of the model. Starting with the full model, the function drop1 is used to evaluate each predictor‚Äôs contribution to the AIC. The predictor whose removal leads to the smallest AIC is then removed and the model is refitted without this variable. The selection stops when the candidate model has the lowest AIC.\n\nmod&lt;-glmer(Activity~N_setts\n              + N_buildings\n              + N_cattle\n              + season\n              + feed_store\n              + cattle_house\n              + feed\n              + grass\n              + cereal\n              + straw\n              + grains\n              + concen\n              + sugar\n              + (1|farm_code)\n              ,data=dataBadger\n              ,family=binomial)\n\nWarning in checkConv(attr(opt, \"derivs\"), opt$par, ctrl = control$checkConv, :\nModel failed to converge with max|grad| = 0.63965 (tol = 0.002, component 1)\n\n\n\n# Backward selection procedure based on AIC\ndrop1(mod,test=\"Chi\") # We remove season\n\nSingle term deletions\n\nModel:\nActivity ~ N_setts + N_buildings + N_cattle + season + feed_store + \n    cattle_house + feed + grass + cereal + straw + grains + concen + \n    sugar + (1 | farm_code)\n             npar    AIC     LRT  Pr(Chi)   \n&lt;none&gt;            183.86                    \nN_setts         1 191.63  9.7760 0.001768 **\nN_buildings     1 182.97  1.1161 0.290759   \nN_cattle        1 182.21  0.3496 0.554326   \nseason          3 179.14  1.2815 0.733535   \nfeed_store      1 182.62  0.7571 0.384246   \ncattle_house    1 182.06  0.2058 0.650093   \nfeed            1 181.84 -0.0124 1.000000   \ngrass           1 181.83 -0.0232 1.000000   \ncereal          1 182.29  0.4289 0.512509   \nstraw           1 183.04  1.1869 0.275951   \ngrains          1 182.28  0.4252 0.514352   \nconcen          1 181.98  0.1249 0.723745   \nsugar           1 183.06  1.2054 0.272248   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nmod1&lt;-glmer(Activity~N_setts\n              + N_buildings\n              + N_cattle\n              + feed_store\n              + cattle_house\n              + feed\n              + grass\n              + cereal\n              + straw\n              + grains\n              + concen\n              + sugar\n              + (1|farm_code)\n              ,data=dataBadger\n              ,family=binomial)\n\ndrop1(mod1,test=\"Chi\") # We remove concentration\n\nSingle term deletions\n\nModel:\nActivity ~ N_setts + N_buildings + N_cattle + feed_store + cattle_house + \n    feed + grass + cereal + straw + grains + concen + sugar + \n    (1 | farm_code)\n             npar    AIC     LRT  Pr(Chi)   \n&lt;none&gt;            179.14                    \nN_setts         1 187.01  9.8762 0.001674 **\nN_buildings     1 178.18  1.0424 0.307266   \nN_cattle        1 177.59  0.4509 0.501920   \nfeed_store      1 177.71  0.5744 0.448513   \ncattle_house    1 177.17  0.0291 0.864544   \nfeed            1 177.16  0.0228 0.879894   \ngrass           1 177.15  0.0057 0.940075   \ncereal          1 177.65  0.5057 0.477006   \nstraw           1 178.56  1.4247 0.232635   \ngrains          1 177.38  0.2417 0.622987   \nconcen          1 177.14 -0.0003 1.000000   \nsugar           1 178.32  1.1765 0.278070   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nmod2&lt;-glmer(Activity~N_setts\n              + N_buildings\n              + N_cattle\n              + feed_store\n              + cattle_house\n              + feed\n              + grass\n              + cereal\n              + straw\n              + grains\n              + sugar\n              + (1|farm_code)\n              ,data=dataBadger\n              ,family=binomial)\n\ndrop1(mod2,test=\"Chi\") # We remove feed\n\nSingle term deletions\n\nModel:\nActivity ~ N_setts + N_buildings + N_cattle + feed_store + cattle_house + \n    feed + grass + cereal + straw + grains + sugar + (1 | farm_code)\n             npar    AIC    LRT Pr(Chi)   \n&lt;none&gt;            177.14                  \nN_setts         1 185.06 9.9260 0.00163 **\nN_buildings     1 176.23 1.0887 0.29677   \nN_cattle        1 175.68 0.5408 0.46209   \nfeed_store      1 175.73 0.5926 0.44143   \ncattle_house    1 175.34 0.2050 0.65075   \nfeed            1 175.19 0.0564 0.81231   \ngrass           1 175.24 0.0960 0.75669   \ncereal          1 175.67 0.5270 0.46789   \nstraw           1 176.57 1.4362 0.23075   \ngrains          1 175.45 0.3088 0.57844   \nsugar           1 176.47 1.3289 0.24900   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nmod3&lt;-glmer(Activity~N_setts\n              + N_buildings\n              + N_cattle\n              + feed_store\n              + cattle_house\n              + grass\n              + cereal\n              + straw\n              + grains\n              + sugar\n              + (1|farm_code)\n              ,data=dataBadger\n              ,family=binomial)\n\ndrop1(mod3,test=\"Chi\") # We remove grass\n\nSingle term deletions\n\nModel:\nActivity ~ N_setts + N_buildings + N_cattle + feed_store + cattle_house + \n    grass + cereal + straw + grains + sugar + (1 | farm_code)\n             npar    AIC    LRT  Pr(Chi)   \n&lt;none&gt;            175.19                   \nN_setts         1 182.95 9.7543 0.001789 **\nN_buildings     1 174.16 0.9674 0.325328   \nN_cattle        1 173.54 0.3478 0.555348   \nfeed_store      1 174.31 1.1196 0.290000   \ncattle_house    1 173.33 0.1325 0.715902   \ngrass           1 173.30 0.1044 0.746582   \ncereal          1 173.70 0.5039 0.477772   \nstraw           1 174.69 1.4910 0.222067   \ngrains          1 173.37 0.1773 0.673699   \nsugar           1 174.34 1.1420 0.285240   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nmod4&lt;-glmer(Activity~N_setts\n              + N_buildings\n              + N_cattle\n              + feed_store\n              + cattle_house\n              + cereal\n              + straw\n              + grains\n              + sugar\n              + (1|farm_code)\n              ,data=dataBadger\n              ,family=binomial)\n\ndrop1(mod4,test=\"Chi\") # We remove cattle house\n\nSingle term deletions\n\nModel:\nActivity ~ N_setts + N_buildings + N_cattle + feed_store + cattle_house + \n    cereal + straw + grains + sugar + (1 | farm_code)\n             npar    AIC     LRT  Pr(Chi)   \n&lt;none&gt;            173.30                    \nN_setts         1 181.04  9.7457 0.001797 **\nN_buildings     1 172.29  0.9936 0.318860   \nN_cattle        1 171.72  0.4227 0.515570   \nfeed_store      1 172.31  1.0085 0.315266   \ncattle_house    1 171.24 -0.0602 1.000000   \ncereal          1 171.66  0.3578 0.549755   \nstraw           1 172.71  1.4087 0.235273   \ngrains          1 171.38  0.0761 0.782711   \nsugar           1 172.43  1.1252 0.288803   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nmod5&lt;-glmer(Activity~N_setts\n              + N_buildings\n              + N_cattle\n              + feed_store\n              + cereal\n              + straw\n              + grains\n              + sugar\n              + (1|farm_code)\n              ,data=dataBadger\n              ,family=binomial)\n\ndrop1(mod5,test=\"Chi\") # We remove grains\n\nSingle term deletions\n\nModel:\nActivity ~ N_setts + N_buildings + N_cattle + feed_store + cereal + \n    straw + grains + sugar + (1 | farm_code)\n            npar    AIC     LRT   Pr(Chi)    \n&lt;none&gt;           171.24                      \nN_setts        1 180.22 10.9805 0.0009207 ***\nN_buildings    1 170.49  1.2509 0.2633739    \nN_cattle       1 169.74  0.5023 0.4784721    \nfeed_store     1 170.34  1.1036 0.2934846    \ncereal         1 169.82  0.5805 0.4461350    \nstraw          1 170.70  1.4594 0.2270195    \ngrains         1 169.55  0.3147 0.5747814    \nsugar          1 170.58  1.3400 0.2470283    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nmod6&lt;-glmer(Activity~N_setts\n              + N_buildings\n              + N_cattle\n              + feed_store\n              + cereal\n              + straw\n              + sugar\n              + (1|farm_code)\n              ,data=dataBadger\n              ,family=binomial)\n\ndrop1(mod6,test=\"Chi\") # We remove cereal\n\nSingle term deletions\n\nModel:\nActivity ~ N_setts + N_buildings + N_cattle + feed_store + cereal + \n    straw + sugar + (1 | farm_code)\n            npar    AIC     LRT   Pr(Chi)    \n&lt;none&gt;           169.55                      \nN_setts        1 178.56 11.0067 0.0009078 ***\nN_buildings    1 168.98  1.4289 0.2319453    \nN_cattle       1 168.25  0.6961 0.4040841    \nfeed_store     1 168.67  1.1201 0.2898895    \ncereal         1 168.16  0.6100 0.4347724    \nstraw          1 168.92  1.3646 0.2427384    \nsugar          1 168.66  1.1102 0.2920361    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nmod7&lt;-glmer(Activity~N_setts\n              + N_buildings\n              + N_cattle\n              + feed_store\n              + straw\n              + sugar\n              + (1|farm_code)\n              ,data=dataBadger\n              ,family=binomial)\n\ndrop1(mod7,test=\"Chi\") # We remove N_cattle\n\nSingle term deletions\n\nModel:\nActivity ~ N_setts + N_buildings + N_cattle + feed_store + straw + \n    sugar + (1 | farm_code)\n            npar    AIC     LRT  Pr(Chi)   \n&lt;none&gt;           168.16                    \nN_setts        1 176.90 10.7317 0.001053 **\nN_buildings    1 167.30  1.1334 0.287048   \nN_cattle       1 166.72  0.5593 0.454547   \nfeed_store     1 167.22  1.0613 0.302921   \nstraw          1 167.35  1.1842 0.276493   \nsugar          1 167.58  1.4143 0.234341   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nmod8&lt;-glmer(Activity~N_setts\n              + N_buildings\n              + feed_store\n              + straw\n              + sugar\n              + (1|farm_code)\n              ,data=dataBadger\n              ,family=binomial)\n\ndrop1(mod8,test=\"Chi\") # We remove feed_store (same AIC as straw, but higher p value)\n\nSingle term deletions\n\nModel:\nActivity ~ N_setts + N_buildings + feed_store + straw + sugar + \n    (1 | farm_code)\n            npar    AIC     LRT   Pr(Chi)    \n&lt;none&gt;           166.72                      \nN_setts        1 175.95 11.2267 0.0008063 ***\nN_buildings    1 166.85  2.1303 0.1444105    \nfeed_store     1 165.75  1.0249 0.3113523    \nstraw          1 165.75  1.0319 0.3097180    \nsugar          1 166.00  1.2738 0.2590508    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nmod9&lt;-glmer(Activity~N_setts\n              + N_buildings\n              + straw\n              + sugar\n              + (1|farm_code)\n              ,data=dataBadger\n              ,family=binomial)\n\ndrop1(mod9,test=\"Chi\") # We remove straw\n\nSingle term deletions\n\nModel:\nActivity ~ N_setts + N_buildings + straw + sugar + (1 | farm_code)\n            npar    AIC     LRT   Pr(Chi)    \n&lt;none&gt;           165.75                      \nN_setts        1 176.27 12.5238 0.0004018 ***\nN_buildings    1 166.38  2.6306 0.1048194    \nstraw          1 164.11  0.3589 0.5490935    \nsugar          1 164.94  1.1864 0.2760633    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nmod10&lt;-glmer(Activity~N_setts\n              + N_buildings\n              + sugar\n              + (1|farm_code)\n              ,data=dataBadger\n              ,family=binomial)\n\ndrop1(mod10,test=\"Chi\") # We remove sugar\n\nSingle term deletions\n\nModel:\nActivity ~ N_setts + N_buildings + sugar + (1 | farm_code)\n            npar    AIC     LRT   Pr(Chi)    \n&lt;none&gt;           164.11                      \nN_setts        1 174.41 12.3001 0.0004529 ***\nN_buildings    1 164.63  2.5277 0.1118629    \nsugar          1 163.44  1.3299 0.2488179    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nmod11&lt;-glmer(Activity~N_setts\n              + N_buildings\n              + (1|farm_code)\n              ,data=dataBadger\n              ,family=binomial)\n\ndrop1(mod11,test=\"Chi\") # We remove N_buildings\n\nSingle term deletions\n\nModel:\nActivity ~ N_setts + N_buildings + (1 | farm_code)\n            npar    AIC     LRT   Pr(Chi)    \n&lt;none&gt;           163.44                      \nN_setts        1 174.13 12.6888 0.0003679 ***\nN_buildings    1 163.38  1.9409 0.1635723    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nmod12&lt;-glmer(Activity~N_setts\n              + (1|farm_code)\n              ,data=dataBadger\n              ,family=binomial)\n\ndrop1(mod12,test=\"Chi\") # mod12 is the best model\n\nSingle term deletions\n\nModel:\nActivity ~ N_setts + (1 | farm_code)\n        npar    AIC    LRT   Pr(Chi)    \n&lt;none&gt;       163.38                     \nN_setts    1 174.57 13.197 0.0002804 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nThere are convergence issues with the first few models, which may be due to their complexity. The best model only retains the number of setts as a fixed effect.\n\n\n\n\nsummary(mod12)\n\nGeneralized linear mixed model fit by maximum likelihood (Laplace\n  Approximation) [glmerMod]\n Family: binomial  ( logit )\nFormula: Activity ~ N_setts + (1 | farm_code)\n   Data: dataBadger\n\n      AIC       BIC    logLik -2*log(L)  df.resid \n    163.4     174.3     -78.7     157.4       275 \n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-2.0216 -0.2384 -0.1102 -0.0841  6.4681 \n\nRandom effects:\n Groups    Name        Variance Std.Dev.\n farm_code (Intercept) 4.868    2.206   \nNumber of obs: 278, groups:  farm_code, 36\n\nFixed effects:\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)  -5.0705     0.9509  -5.332  9.7e-08 ***\nN_setts       0.3809     0.1077   3.537 0.000405 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n        (Intr)\nN_setts -0.766\n\n\nThe model summary details both the fixed and the random effects. The model can be written as: \\[  logit(presence\\:of\\:badger\\:activity) = -5.07 + 0.38 \\times number\\:of\\:setts\\] The variance associated with the random effect (which corresponds to the variance between farms) is 4.87.\n\n\n\nThe significance of the random effect is tested via a bootstrap method: the likelihood of the model including the random effect is compared to the likelihood of 1000 models without the random effect.\n\nnBoot &lt;- 1000 # number of simulations\nlrStat &lt;- rep(NA, nBoot) # initializes a vector of size 1000 to store the likelihood ratio statistic\nft.null &lt;-glm(Activity~N_setts,data=dataBadger,family=binomial(link=logit)) # fits the null model (without the random effect)\nft.alt &lt;- glmer(Activity~N_setts+(1|farm_code),data=dataBadger,family=binomial) # fits the alternate model (with the random effect)\nlrObs &lt;- 2 * logLik(ft.alt) - 2 * logLik(ft.null) # computes the observed likelihood ratio statistic \n\nfor (iBoot in 1:nBoot) # for each simulation\n{\n  dataBadger$ActivitySim &lt;- unlist(simulate(ft.null)) # badger activity is simulated from the distribution corresponding to the null model\n  tryCatch(\n    { # in case the glmm does not converge\n      bNull &lt;-glm(ActivitySim ~ N_setts,data=dataBadger,family=binomial(link=logit)) # fits the null model to the simulated data\n      bAlt &lt;- glmer(ActivitySim ~ N_setts+(1|farm_code),data=dataBadger,family=binomial) # fits the alternate model to the simulated data\n      lrStat[iBoot] &lt;- 2 * logLik(bAlt) - 2 * logLik(bNull) # computes the likelihood ratio statistic for the resampled data\n    },\n    warning = function(war) { # if there is a warning or an error, the likelihood ratio statistic is NA (to ensure the loop does not stop)\n      lrStat[iBoot] &lt;- NA\n    },\n    error = function(err) {\n      lrStat[iBoot] &lt;- NA\n    }\n  )\n}\n\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\n\nmean(lrStat &gt; lrObs, na.rm = TRUE) # Proportion of bootstrap likelihood ratio statistic superior to the observed statistic\n\n[1] 0\n\n# It corresponds to the p value\n\nhist(lrStat,xlim = c(0,40), col='blue', main = \"Histogram of the likelihood ratio statistic\", xlab = \"Likelihood ratio statistic\") # Histogram of the 1000 values of likelihood of the simulated model\nabline(v = lrObs, col=\"red\", lwd=3, lty=2) # Vertical red line representing the likelihood of the model including the random factor\n\n\n\n\n\n\n\n\nAll simulations lead to a likelihood ratio statistic lower than the observed statistic, which suggests that the random effect is highly significant.\n\n\n\nThe function rsq from the package rsq computes three pseudo \\(R^2\\), allowing us to separate the variance explained by the fixed effect from the variance explained by the random effect.\n\n# Estimates of deviance explained (library 'rsq')\nrsq(mod12)\n\n$model\n[1] 0.5939386\n\n$fixed\n[1] 0.2102993\n\n$random\n[1] 0.3836392\n\n\nThe model explains about 59% of the variance of the data, with 21% due to the fixed effect (the number of setts) and 38% due to the random effect (each individual farm).\n\n\n\nA GLMM does not require normality of residuals or homogeneity of variance, and the dependance in the data has already been taken into account with the random effect. However, analyzing the residuals allows us to detect an eventual trend which could indicate a problem with the modelization. Pearson residuals are used because they take into account variance heterogeneity.\n\nresid&lt;-residuals(mod12, type=\"pearson\")\n\npar(mfrow=c(1,2))\n# Plotting the residuals against the fitted data\nplot(resid~fitted(mod12)\n      , col='dodgerblue4'\n      , pch=16)\nabline(h = 0)\n\n# Plotting the residuals against the number of setts\nplot(resid~ dataBadger$N_setts, \n         pch=16,\n         col=\"dodgerblue4\",\n         ylab = \"Residuals\",\n         xlab = \"Number of Setts\",\n         main = \"\")\nabline(h = 0)\n\n\n\n\n\n\n\n\nIn a binomial GLMM, residuals are often difficult to interpret. No defined trend can be identified here.\n\n\n\nWe can check if the model is able to accurately predict the presence / absence of activity signs based on the number of setts.\n\nset.seed(9)\nN    &lt;- nrow(dataBadger) # number of observations in the dataset\nPi   &lt;- fitted(mod12) # predicted probabilities that activity = 1\ndataBadger$Ysim &lt;- rbinom(N, size = 1, Pi) # generates a binary outcome for badger activity, drawn from a binomial distribution with Pi as a success probability\n\n# Confusion matrix\nZ &lt;- table(dataBadger$Activity, dataBadger$Ysim) / N\nrownames(Z) &lt;- c(\"Observed 0\", \"Observed 1\")\ncolnames(Z) &lt;- c(\"Predicted 0\", \"Predicted 1\")\nZ\n\n            \n             Predicted 0 Predicted 1\n  Observed 0  0.77338129  0.06474820\n  Observed 1  0.07553957  0.08633094\n\n# Accuracy = proportion of correctly classified observations\nsum(diag(Z))\n\n[1] 0.8597122\n\n# To get an average confusion matrix over mutliple predictions, we can repeat for 1000 simulations\nNSim &lt;- 1000                           \ndiagZ &lt;- numeric(NSim) # we store one accuracy value per simulation\nfor (i in 1:NSim) { # for each simulation\n  Ysim &lt;- rbinom(N, size = 1, Pi) # a new simulated response is generated\n  Z&lt;- table(dataBadger$Activity, Ysim) / N # creates the confusion matrix for this simulation\n  diagZ[i]&lt;-sum(diag(Z)) # computes and stores the accuracy\n  }\n# Boxplot of the accuracy and average accuracy\nboxplot(diagZ, col='dodgerblue4',ylab='#Rate of farms well-classified')\n\n\n\n\n\n\n\nmean(diagZ)\n\n[1] 0.8821763\n\n\nEach cell of the confusion matrix represents a proportion of the total observations.\n\nThe true negative rate is 77%: it corresponds to farms without badger activity where no activity was predicted\nThe false positive rate is 6.5%: it corresponds to farms without badger activity where activity was incorrectly predicted\nThe true positive rate is 8.6%: it corresponds to farms with badger activity where activity was predicted\nThe false negative rate is 7.6%: it corresponds to farms with badger activity where no activity was predicted\n\nFor this prediction, the overall accuracy was 0.86, which means that 86% of predictions were correct. The average accuracy over 1000 simulations is 0.88."
  },
  {
    "objectID": "Linear_Model_2.html#data-presentation",
    "href": "Linear_Model_2.html#data-presentation",
    "title": "GENERALIZED LINEAR MIXED MODEL",
    "section": "",
    "text": "The data used come from (Walker2009a?) and consist of signs of badger (Meles meles) activity around farms located in the southwest of England, where badger density is high. This study was carried out in the context of bovine tuberculosis and its possible transmission to cattle through badgers. Reducing the number of farm visits by badgers ‚Äî especially in places where they might come into contact with livestock ‚Äî could help limit the spread of the disease. Thus, the aim of this study is to predict the occurrence of badger activity signs on farms.\nBetween autumn 2003 and summer 2005, a survey was conducted on 36 different farms; the data are therefore longitudinal, since each farm was monitored over eight consecutive seasons. Within the same farm, observations may be temporally autocorrelated.\nThe response variable (presence or absence of signs of badger activity) is binary: it takes the value 1 when signs of activity were detected, and 0 otherwise. Signs of activity include the presence of feces, setts, or feeding traces.\nThe data are available in the file Badger.txt. The variables are:\n\nYear : studied year\nSeason : 1 = spring, 2 = summer, 3 = autumn, 4 = winter\nfarm_code_numeric : farm identifier\nSurvey : survey identifier (time indicator)\nSigns_in_yard : binary indicator of badger activity (response variable)\nNo_setts_in_fields : number of setts\nNo_active_setts_in_fields : number of actively occupied setts\nNo_buildings : number of buildings in the farm\nNo_cattle_in_buildings_yard : number of cattle in building yards\nAccessible_feed_store_present : presence / absence of an accessible feed store\nAccessible_cattle_house_present : presence / absence of a direct access to the cattle house\nAccessible_feed_present : presence / absence of accessible feed in the farm\nGrass_silage : presence / absence of grass silage\nCereal_silage : presence / absence of cereal silage\nHayStraw : presence / absence of hay and / or straw\nCereal_grains : presence / absence of cereal grains\nConcentrates : presence / absence of concentrates\nProteinblocks : presence / absence of protein blocks\nSugarbeet : presence / absence of sugar beet\nVegetables : presence / absence of vegetables\nMolasses : presence / absence of molasses :::"
  },
  {
    "objectID": "Linear_Model_2.html#dataset-import",
    "href": "Linear_Model_2.html#dataset-import",
    "title": "GENERALIZED LINEAR MIXED MODEL",
    "section": "",
    "text": "# library import\nlibrary(corrplot)\n\ncorrplot 0.95 loaded\n\nlibrary(lme4)\n\nLoading required package: Matrix\n\nlibrary(rsq)\n\n\n# Dataset import\ndataBadger &lt;- read.table(\"Badger.txt\", dec=\".\", header = TRUE)\n\n# Reduce name and change categorical variables as factor\ndataBadger$Activity&lt;- dataBadger$signs_in_yard\ndataBadger$N_setts&lt;-dataBadger$N_setts_in_fields\ndataBadger$N_cattle&lt;-dataBadger$N_cattle_in_buildings_yard\ndataBadger$season&lt;-as.factor(dataBadger$season)\ndataBadger$feed_store&lt;-as.factor(dataBadger$accessible_feed_store_present)\ndataBadger$cattle_house&lt;-as.factor(dataBadger$accessible_cattle_house_present)\ndataBadger$feed&lt;-as.factor(dataBadger$accessible_feed_present)\ndataBadger$grass&lt;-as.factor(dataBadger$grass_silage)\ndataBadger$cereal&lt;-as.factor(dataBadger$cereal_silage)\ndataBadger$straw&lt;-as.factor(dataBadger$hay_straw)\ndataBadger$grains&lt;-as.factor(dataBadger$cereal_grains)\ndataBadger$concen&lt;-as.factor(dataBadger$concentrates)\ndataBadger$sugar&lt;-as.factor(dataBadger$sugar_beet)\ndataBadger$molasses&lt;-as.factor(dataBadger$molasses)\n\n# Check for presence of missing values\ncolSums(is.na(dataBadger))\n\n                             ID                            year \n                              0                               0 \n                         season                       farm_code \n                              0                               0 \n                         survey                   signs_in_yard \n                              0                               0 \n              N_setts_in_fields                     N_buildings \n                              0                               0 \n     N_cattle_in_buildings_yard   accessible_feed_store_present \n                              0                               0 \naccessible_cattle_house_present         accessible_feed_present \n                              0                               0 \n                   grass_silage                   cereal_silage \n                              0                               0 \n                      hay_straw                   cereal_grains \n                              0                               0 \n                   concentrates                      sugar_beet \n                              0                               0 \n                       molasses                        Activity \n                              0                               0 \n                        N_setts                        N_cattle \n                              0                               0 \n                     feed_store                    cattle_house \n                              0                               0 \n                           feed                           grass \n                              0                               0 \n                         cereal                           straw \n                              0                               0 \n                         grains                          concen \n                              0                               0 \n                          sugar \n                              0 \n\n# There is no missing value."
  },
  {
    "objectID": "Linear_Model_2.html#data-exploration",
    "href": "Linear_Model_2.html#data-exploration",
    "title": "GENERALIZED LINEAR MIXED MODEL",
    "section": "",
    "text": "Before carrying out any statistical modeling, it is essential to perform a thorough data exploration. This step helps identify potential issues such as outliers, collinearity, or imbalanced distributions that could bias the results or invalidate model assumptions.\nBelow is a checklist of preliminary exploratory analyses to perform before modeling:\n\nCheck for outliers and distribution of the dependent variable ($Y$).\nCheck for outliers and distribution of the explicative variable ($X$). If $X$ is quantitative: assess the distribution and presence of outliers. If $X$ is qualitative: analyze the number of levels and the number of observations per level.\nExplore the potential relationships between $Y$ and each $X_i$.\nCheck for potential interactions between explanatory variables ($X_i$).\nAssess multicollinearity among the $X_i$ variables.\n\n\n\nSince $Y$ is a binary variable, it does not have a continuous distribution. Instead, we inspect the frequency of each category (0 and 1) to check for imbalance in the response variable.\n\n# Number of 0 and 1 in Y\ntable(dataBadger$Activity)\n\n\n  0   1 \n233  45 \n\n\n\n\n\nFor continuous independent variables, it is important to:\n\nDetect potential outliers (e.g., extreme or erroneous values)\nVisualize the shape of the distribution (e.g., normal, skewed, multimodal)\nAssess whether transformations (e.g., log, square root) might be needed before modeling\n\nThe following visualizations help achieve this:\n\nCleveland dot plots: to identify potential outliers\nHistograms: to visualize the overall distribution\nQ-Q plots: to assess normality assumptions\n\n\npar(mfrow=c(3,3))\n\n# Number of badger setts on farm\n# Cleveland plot\ndotchart(dataBadger$N_setts,pch=16,col='blue',xlab='Number of setts')\n# Histogram\nhist(dataBadger$N_setts,col='blue',xlab=\"Number of setts\",main=\"\")\n# Quantile-Quantile plot\nqqnorm(dataBadger$N_setts,pch=16,col='blue',xlab='')\nqqline(dataBadger$N_setts,col='red')\n\n# Number of buildings on farm\n# Cleveland plot\ndotchart(dataBadger$N_buildings,pch=16,col='blue',xlab='Number of buildings')\n# Histogram\nhist(dataBadger$N_buildings,col='blue',xlab=\"Number of buildings\",main=\"\")\n# Quantile-Quantile plot\nqqnorm(dataBadger$N_buildings,pch=16,col='blue',xlab='')\nqqline(dataBadger$N_buildings,col='red')\n\n# Number of cattle housed in buildings on farm\n# Cleveland plot\ndotchart(dataBadger$N_cattle,pch=16,col='blue',xlab='Number of cattle')\n# Histogram\nhist(dataBadger$N_cattle,col='blue',xlab=\"Number of cattle\",main=\"\")\n# Quantile-Quantile plot\nqqnorm(dataBadger$N_cattle,pch=16,col='blue',xlab='')\nqqline(dataBadger$N_cattle,col='red')\n\n\n\n\n\n\n\n\nThe exploratory plots show that all three quantitative variables (number of setts, number of buildings, and number of cattle) display right-skewed distributions, with most farms having relatively low values and a few having much higher ones. No extreme or abnormal outliers are clearly visible, although some high values are present, especially for the number of cattle. The Q-Q plots confirm that none of these variables follow a normal distribution.\n\n\n\nFor categorical (factor) variables, it is important to examine the number of levels (categories) and the number of observations in each level. This helps identify potential issues such as:\n\nLevels with very few observations (which may cause estimation problems in statistical models)\nHighly unbalanced distributions between categories\nUnexpected or erroneous category labels\n\nThe following code summarizes the distribution of individuals across levels for each categorical predictor:\n\n# Factor season\nsummary(dataBadger$season)\n\n 1  2  3  4 \n70 67 69 72 \n\n# Factor feed_store\nsummary(dataBadger$feed_store)\n\n  0   1 \n 49 229 \n\n# Factor cattle_house \nsummary(dataBadger$cattle_house )\n\n  0   1 \n 91 187 \n\n# Factor feed\nsummary(dataBadger$feed)\n\n  0   1 \n 47 231 \n\n# Factor grass\nsummary(dataBadger$grass)\n\n  0   1 \n171 107 \n\n# Factor cereal\nsummary(dataBadger$cereal)\n\n  0   1 \n199  79 \n\n# Factor straw\nsummary(dataBadger$straw)\n\n  0   1 \n107 171 \n\n# Factor grains\nsummary(dataBadger$grains)\n\n  0   1 \n165 113 \n\n# Factor concen\nsummary(dataBadger$concen)\n\n  0   1 \n142 136 \n\n# Factor sugar\nsummary(dataBadger$sugar)\n\n  0   1 \n255  23 \n\n\nThe categorical variables show that most factors are binary, with varying levels of balance between categories. For example, variables such as feed_store, cattle_house, and feed display moderate imbalance, with one category being more frequent than the other. The season variable has four well-represented levels, each containing a similar number of observations, which ensures adequate variability for analysis. Overall, the categorical predictors appear suitable for modeling.\n\n\n\nTo gain preliminary insight into the relationships between the response variable (Activity) and the predictors, both quantitative and categorical variables were explored graphically.\nScatterplots were used to visualize how badger activity varies with continuous predictors such as the number of setts, number of buildings and number of cattle housed. These visual analyses provide a first impression of potential patterns, dependencies, or nonlinear relationships that may influence badger activity on farms.\n\npar(mfrow=c(1,3))\n# Number of setts\nplot(dataBadger$Activity~dataBadger$N_setts,pch=16,col='blue',xlab='Number of setts',ylab='Presence of a sign of badger activity')\n\n# Number of buildings\nplot(dataBadger$Activity~dataBadger$N_buildings,pch=16,col='blue',xlab='Number of buildings',ylab='Presence of a sign of badger activity')\n\n# Number of cattle housed in buildings\nplot(dataBadger$Activity~dataBadger$N_cattle,pch=16,col='blue',xlab='Number of cattle',ylab='Presence of a sign of badger activity')\n\n\n\n\n\n\n\npar(mfrow=c(2,5))\n# Factor season\nmosaicplot(dataBadger$Activity~dataBadger$season\n           ,color=c('blue3','red2')\n           ,main=\"Activity & Season\")\n\n# Factor feed store\nmosaicplot(dataBadger$Activity~dataBadger$feed_store\n           ,color=c('blue3','red2')\n           ,main=\"Activity & Feed store\")\n\n# Factor cattle_house \nmosaicplot(dataBadger$Activity~dataBadger$cattle_house\n           ,color=c('blue3','red2')\n           ,main=\"Activity & cattle house\")\n\n# Factor feed\nmosaicplot(dataBadger$Activity~dataBadger$feed\n           ,color=c('blue3','red2')\n           ,main=\"Activity & feed\")\n# Factor grass\nmosaicplot(dataBadger$Activity~dataBadger$grass\n           ,color=c('blue3','red2')\n           ,main=\"Activity & Grass\")\n# Factor cereal\nmosaicplot(dataBadger$Activity~dataBadger$cereal\n           ,color=c('blue3','red2')\n           ,main=\"Activity & Cereal\")\n# Factor straw\nmosaicplot(dataBadger$Activity~dataBadger$straw\n           ,color=c('blue3','red2')\n           ,main=\"Activity & Straw\")\n# Factor grains\nmosaicplot(dataBadger$Activity~dataBadger$grains\n           ,color=c('blue3','red2')\n           ,main=\"Activity & Grains\")\n# Factor concen\nmosaicplot(dataBadger$Activity~dataBadger$concen\n           ,color=c('blue3','red2')\n           ,main=\"Activity & Concentrates\")\n# Factor sugar\nmosaicplot(dataBadger$Activity~dataBadger$sugar\n           ,color=c('blue3','red2')\n           ,main=\"Activity & Sugar Beet\")\n\n\n\n\n\n\n\n\nThese visual analyses provide an initial understanding of how badger activity may relate to farm characteristics. The scatterplots show that no clear linear relationship exists between badger activity and the number of setts, buildings, or cattle, although activity tends to occur slightly more often on farms with more setts or larger cattle numbers. The mosaic plots complement this by revealing possible associations between activity and certain categorical management factors, such as the presence of feed stores, cattle housing, or specific feeding practices.\n\n\n\nHere, given the large number of predictors, we will not include interactions in modelling\n\n\n\nTo avoid multicollinearity issues during modeling, the relationships among predictor variables were examined. This step includes:\n\nEvaluating correlations between the three quantitative variables\nAssessing potential overlap between categorical factors\nExploring whether categorical predictors influence quantitative ones through boxplots\n\nGiven the large number of predictors, only key results are summarized below.\n\n# Checking collinearity between the 3 quantitative independent variables\n\n# We represent plot for each X continuous covariate pairs\nplot(dataBadger[7:9],pch=16,col='blue')\n\n\n\n\n\n\n\n#We calculate correlation between each pair of X covariate\nM&lt;-cor(dataBadger[7:9])\ncorrplot.mixed(M,upper=\"square\",lower.col=\"black\", tl.col=\"black\",cl.cex = 0.8,tl.cex = 0.7,number.cex =0.8)\n\n\n\n\n\n\n\n# Checking collinearity between  categorical independent variables\n# produce all crossed tables between pairs of factors - not detailed here\n\n# Checking collinearity between categorical and quantitative independent variables\n# for each quantitative independent variable, use boxplot graphics to check whether factors influence it - not detailed here\n\nThe collinearity analysis indicates that the three quantitative variables are largely independent. A moderate positive correlation (r ‚âà 0.52) is observed between the number of buildings and the number of cattle in the yard, suggesting a slight interdependence between these two variables. In contrast, the number of setts in fields shows almost no correlation with the others (r close to 0). Overall, no strong collinearity is detected, allowing these predictors to be retained for further modelling without major redundancy concerns."
  },
  {
    "objectID": "Linear_Model_2.html#generalized-linear-mixed-model-glmm",
    "href": "Linear_Model_2.html#generalized-linear-mixed-model-glmm",
    "title": "GENERALIZED LINEAR MIXED MODEL",
    "section": "",
    "text": "Because the response variable is binary, we will use a Generalized Linear Mixed Model (GLMM) to examine how the different predictors influence badger activity. We assume that badger activity follows a binomial distribution, and we will therefore use a logit link function. The farm code is included as a random effect, to take into account the temporal autocorrelation between observations.\n\n\nThe best model is identified using a backward selection procedure. This model selection method is based on the Akaike Information Criterion (AIC), which allows to take into account both the goodness of fit and the simplicity of the model. Starting with the full model, the function drop1 is used to evaluate each predictor‚Äôs contribution to the AIC. The predictor whose removal leads to the smallest AIC is then removed and the model is refitted without this variable. The selection stops when the candidate model has the lowest AIC.\n\nmod&lt;-glmer(Activity~N_setts\n              + N_buildings\n              + N_cattle\n              + season\n              + feed_store\n              + cattle_house\n              + feed\n              + grass\n              + cereal\n              + straw\n              + grains\n              + concen\n              + sugar\n              + (1|farm_code)\n              ,data=dataBadger\n              ,family=binomial)\n\nWarning in checkConv(attr(opt, \"derivs\"), opt$par, ctrl = control$checkConv, :\nModel failed to converge with max|grad| = 0.63965 (tol = 0.002, component 1)\n\n\n\n# Backward selection procedure based on AIC\ndrop1(mod,test=\"Chi\") # We remove season\n\nSingle term deletions\n\nModel:\nActivity ~ N_setts + N_buildings + N_cattle + season + feed_store + \n    cattle_house + feed + grass + cereal + straw + grains + concen + \n    sugar + (1 | farm_code)\n             npar    AIC     LRT  Pr(Chi)   \n&lt;none&gt;            183.86                    \nN_setts         1 191.63  9.7760 0.001768 **\nN_buildings     1 182.97  1.1161 0.290759   \nN_cattle        1 182.21  0.3496 0.554326   \nseason          3 179.14  1.2815 0.733535   \nfeed_store      1 182.62  0.7571 0.384246   \ncattle_house    1 182.06  0.2058 0.650093   \nfeed            1 181.84 -0.0124 1.000000   \ngrass           1 181.83 -0.0232 1.000000   \ncereal          1 182.29  0.4289 0.512509   \nstraw           1 183.04  1.1869 0.275951   \ngrains          1 182.28  0.4252 0.514352   \nconcen          1 181.98  0.1249 0.723745   \nsugar           1 183.06  1.2054 0.272248   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nmod1&lt;-glmer(Activity~N_setts\n              + N_buildings\n              + N_cattle\n              + feed_store\n              + cattle_house\n              + feed\n              + grass\n              + cereal\n              + straw\n              + grains\n              + concen\n              + sugar\n              + (1|farm_code)\n              ,data=dataBadger\n              ,family=binomial)\n\ndrop1(mod1,test=\"Chi\") # We remove concentration\n\nSingle term deletions\n\nModel:\nActivity ~ N_setts + N_buildings + N_cattle + feed_store + cattle_house + \n    feed + grass + cereal + straw + grains + concen + sugar + \n    (1 | farm_code)\n             npar    AIC     LRT  Pr(Chi)   \n&lt;none&gt;            179.14                    \nN_setts         1 187.01  9.8762 0.001674 **\nN_buildings     1 178.18  1.0424 0.307266   \nN_cattle        1 177.59  0.4509 0.501920   \nfeed_store      1 177.71  0.5744 0.448513   \ncattle_house    1 177.17  0.0291 0.864544   \nfeed            1 177.16  0.0228 0.879894   \ngrass           1 177.15  0.0057 0.940075   \ncereal          1 177.65  0.5057 0.477006   \nstraw           1 178.56  1.4247 0.232635   \ngrains          1 177.38  0.2417 0.622987   \nconcen          1 177.14 -0.0003 1.000000   \nsugar           1 178.32  1.1765 0.278070   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nmod2&lt;-glmer(Activity~N_setts\n              + N_buildings\n              + N_cattle\n              + feed_store\n              + cattle_house\n              + feed\n              + grass\n              + cereal\n              + straw\n              + grains\n              + sugar\n              + (1|farm_code)\n              ,data=dataBadger\n              ,family=binomial)\n\ndrop1(mod2,test=\"Chi\") # We remove feed\n\nSingle term deletions\n\nModel:\nActivity ~ N_setts + N_buildings + N_cattle + feed_store + cattle_house + \n    feed + grass + cereal + straw + grains + sugar + (1 | farm_code)\n             npar    AIC    LRT Pr(Chi)   \n&lt;none&gt;            177.14                  \nN_setts         1 185.06 9.9260 0.00163 **\nN_buildings     1 176.23 1.0887 0.29677   \nN_cattle        1 175.68 0.5408 0.46209   \nfeed_store      1 175.73 0.5926 0.44143   \ncattle_house    1 175.34 0.2050 0.65075   \nfeed            1 175.19 0.0564 0.81231   \ngrass           1 175.24 0.0960 0.75669   \ncereal          1 175.67 0.5270 0.46789   \nstraw           1 176.57 1.4362 0.23075   \ngrains          1 175.45 0.3088 0.57844   \nsugar           1 176.47 1.3289 0.24900   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nmod3&lt;-glmer(Activity~N_setts\n              + N_buildings\n              + N_cattle\n              + feed_store\n              + cattle_house\n              + grass\n              + cereal\n              + straw\n              + grains\n              + sugar\n              + (1|farm_code)\n              ,data=dataBadger\n              ,family=binomial)\n\ndrop1(mod3,test=\"Chi\") # We remove grass\n\nSingle term deletions\n\nModel:\nActivity ~ N_setts + N_buildings + N_cattle + feed_store + cattle_house + \n    grass + cereal + straw + grains + sugar + (1 | farm_code)\n             npar    AIC    LRT  Pr(Chi)   \n&lt;none&gt;            175.19                   \nN_setts         1 182.95 9.7543 0.001789 **\nN_buildings     1 174.16 0.9674 0.325328   \nN_cattle        1 173.54 0.3478 0.555348   \nfeed_store      1 174.31 1.1196 0.290000   \ncattle_house    1 173.33 0.1325 0.715902   \ngrass           1 173.30 0.1044 0.746582   \ncereal          1 173.70 0.5039 0.477772   \nstraw           1 174.69 1.4910 0.222067   \ngrains          1 173.37 0.1773 0.673699   \nsugar           1 174.34 1.1420 0.285240   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nmod4&lt;-glmer(Activity~N_setts\n              + N_buildings\n              + N_cattle\n              + feed_store\n              + cattle_house\n              + cereal\n              + straw\n              + grains\n              + sugar\n              + (1|farm_code)\n              ,data=dataBadger\n              ,family=binomial)\n\ndrop1(mod4,test=\"Chi\") # We remove cattle house\n\nSingle term deletions\n\nModel:\nActivity ~ N_setts + N_buildings + N_cattle + feed_store + cattle_house + \n    cereal + straw + grains + sugar + (1 | farm_code)\n             npar    AIC     LRT  Pr(Chi)   \n&lt;none&gt;            173.30                    \nN_setts         1 181.04  9.7457 0.001797 **\nN_buildings     1 172.29  0.9936 0.318860   \nN_cattle        1 171.72  0.4227 0.515570   \nfeed_store      1 172.31  1.0085 0.315266   \ncattle_house    1 171.24 -0.0602 1.000000   \ncereal          1 171.66  0.3578 0.549755   \nstraw           1 172.71  1.4087 0.235273   \ngrains          1 171.38  0.0761 0.782711   \nsugar           1 172.43  1.1252 0.288803   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nmod5&lt;-glmer(Activity~N_setts\n              + N_buildings\n              + N_cattle\n              + feed_store\n              + cereal\n              + straw\n              + grains\n              + sugar\n              + (1|farm_code)\n              ,data=dataBadger\n              ,family=binomial)\n\ndrop1(mod5,test=\"Chi\") # We remove grains\n\nSingle term deletions\n\nModel:\nActivity ~ N_setts + N_buildings + N_cattle + feed_store + cereal + \n    straw + grains + sugar + (1 | farm_code)\n            npar    AIC     LRT   Pr(Chi)    \n&lt;none&gt;           171.24                      \nN_setts        1 180.22 10.9805 0.0009207 ***\nN_buildings    1 170.49  1.2509 0.2633739    \nN_cattle       1 169.74  0.5023 0.4784721    \nfeed_store     1 170.34  1.1036 0.2934846    \ncereal         1 169.82  0.5805 0.4461350    \nstraw          1 170.70  1.4594 0.2270195    \ngrains         1 169.55  0.3147 0.5747814    \nsugar          1 170.58  1.3400 0.2470283    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nmod6&lt;-glmer(Activity~N_setts\n              + N_buildings\n              + N_cattle\n              + feed_store\n              + cereal\n              + straw\n              + sugar\n              + (1|farm_code)\n              ,data=dataBadger\n              ,family=binomial)\n\ndrop1(mod6,test=\"Chi\") # We remove cereal\n\nSingle term deletions\n\nModel:\nActivity ~ N_setts + N_buildings + N_cattle + feed_store + cereal + \n    straw + sugar + (1 | farm_code)\n            npar    AIC     LRT   Pr(Chi)    \n&lt;none&gt;           169.55                      \nN_setts        1 178.56 11.0067 0.0009078 ***\nN_buildings    1 168.98  1.4289 0.2319453    \nN_cattle       1 168.25  0.6961 0.4040841    \nfeed_store     1 168.67  1.1201 0.2898895    \ncereal         1 168.16  0.6100 0.4347724    \nstraw          1 168.92  1.3646 0.2427384    \nsugar          1 168.66  1.1102 0.2920361    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nmod7&lt;-glmer(Activity~N_setts\n              + N_buildings\n              + N_cattle\n              + feed_store\n              + straw\n              + sugar\n              + (1|farm_code)\n              ,data=dataBadger\n              ,family=binomial)\n\ndrop1(mod7,test=\"Chi\") # We remove N_cattle\n\nSingle term deletions\n\nModel:\nActivity ~ N_setts + N_buildings + N_cattle + feed_store + straw + \n    sugar + (1 | farm_code)\n            npar    AIC     LRT  Pr(Chi)   \n&lt;none&gt;           168.16                    \nN_setts        1 176.90 10.7317 0.001053 **\nN_buildings    1 167.30  1.1334 0.287048   \nN_cattle       1 166.72  0.5593 0.454547   \nfeed_store     1 167.22  1.0613 0.302921   \nstraw          1 167.35  1.1842 0.276493   \nsugar          1 167.58  1.4143 0.234341   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nmod8&lt;-glmer(Activity~N_setts\n              + N_buildings\n              + feed_store\n              + straw\n              + sugar\n              + (1|farm_code)\n              ,data=dataBadger\n              ,family=binomial)\n\ndrop1(mod8,test=\"Chi\") # We remove feed_store (same AIC as straw, but higher p value)\n\nSingle term deletions\n\nModel:\nActivity ~ N_setts + N_buildings + feed_store + straw + sugar + \n    (1 | farm_code)\n            npar    AIC     LRT   Pr(Chi)    \n&lt;none&gt;           166.72                      \nN_setts        1 175.95 11.2267 0.0008063 ***\nN_buildings    1 166.85  2.1303 0.1444105    \nfeed_store     1 165.75  1.0249 0.3113523    \nstraw          1 165.75  1.0319 0.3097180    \nsugar          1 166.00  1.2738 0.2590508    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nmod9&lt;-glmer(Activity~N_setts\n              + N_buildings\n              + straw\n              + sugar\n              + (1|farm_code)\n              ,data=dataBadger\n              ,family=binomial)\n\ndrop1(mod9,test=\"Chi\") # We remove straw\n\nSingle term deletions\n\nModel:\nActivity ~ N_setts + N_buildings + straw + sugar + (1 | farm_code)\n            npar    AIC     LRT   Pr(Chi)    \n&lt;none&gt;           165.75                      \nN_setts        1 176.27 12.5238 0.0004018 ***\nN_buildings    1 166.38  2.6306 0.1048194    \nstraw          1 164.11  0.3589 0.5490935    \nsugar          1 164.94  1.1864 0.2760633    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nmod10&lt;-glmer(Activity~N_setts\n              + N_buildings\n              + sugar\n              + (1|farm_code)\n              ,data=dataBadger\n              ,family=binomial)\n\ndrop1(mod10,test=\"Chi\") # We remove sugar\n\nSingle term deletions\n\nModel:\nActivity ~ N_setts + N_buildings + sugar + (1 | farm_code)\n            npar    AIC     LRT   Pr(Chi)    \n&lt;none&gt;           164.11                      \nN_setts        1 174.41 12.3001 0.0004529 ***\nN_buildings    1 164.63  2.5277 0.1118629    \nsugar          1 163.44  1.3299 0.2488179    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nmod11&lt;-glmer(Activity~N_setts\n              + N_buildings\n              + (1|farm_code)\n              ,data=dataBadger\n              ,family=binomial)\n\ndrop1(mod11,test=\"Chi\") # We remove N_buildings\n\nSingle term deletions\n\nModel:\nActivity ~ N_setts + N_buildings + (1 | farm_code)\n            npar    AIC     LRT   Pr(Chi)    \n&lt;none&gt;           163.44                      \nN_setts        1 174.13 12.6888 0.0003679 ***\nN_buildings    1 163.38  1.9409 0.1635723    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nmod12&lt;-glmer(Activity~N_setts\n              + (1|farm_code)\n              ,data=dataBadger\n              ,family=binomial)\n\ndrop1(mod12,test=\"Chi\") # mod12 is the best model\n\nSingle term deletions\n\nModel:\nActivity ~ N_setts + (1 | farm_code)\n        npar    AIC    LRT   Pr(Chi)    \n&lt;none&gt;       163.38                     \nN_setts    1 174.57 13.197 0.0002804 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nThere are convergence issues with the first few models, which may be due to their complexity. The best model only retains the number of setts as a fixed effect.\n\n\n\n\nsummary(mod12)\n\nGeneralized linear mixed model fit by maximum likelihood (Laplace\n  Approximation) [glmerMod]\n Family: binomial  ( logit )\nFormula: Activity ~ N_setts + (1 | farm_code)\n   Data: dataBadger\n\n      AIC       BIC    logLik -2*log(L)  df.resid \n    163.4     174.3     -78.7     157.4       275 \n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-2.0216 -0.2384 -0.1102 -0.0841  6.4681 \n\nRandom effects:\n Groups    Name        Variance Std.Dev.\n farm_code (Intercept) 4.868    2.206   \nNumber of obs: 278, groups:  farm_code, 36\n\nFixed effects:\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)  -5.0705     0.9509  -5.332  9.7e-08 ***\nN_setts       0.3809     0.1077   3.537 0.000405 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n        (Intr)\nN_setts -0.766\n\n\nThe model summary details both the fixed and the random effects. The model can be written as: \\[  logit(presence\\:of\\:badger\\:activity) = -5.07 + 0.38 \\times number\\:of\\:setts\\] The variance associated with the random effect (which corresponds to the variance between farms) is 4.87.\n\n\n\nThe significance of the random effect is tested via a bootstrap method: the likelihood of the model including the random effect is compared to the likelihood of 1000 models without the random effect.\n\nnBoot &lt;- 1000 # number of simulations\nlrStat &lt;- rep(NA, nBoot) # initializes a vector of size 1000 to store the likelihood ratio statistic\nft.null &lt;-glm(Activity~N_setts,data=dataBadger,family=binomial(link=logit)) # fits the null model (without the random effect)\nft.alt &lt;- glmer(Activity~N_setts+(1|farm_code),data=dataBadger,family=binomial) # fits the alternate model (with the random effect)\nlrObs &lt;- 2 * logLik(ft.alt) - 2 * logLik(ft.null) # computes the observed likelihood ratio statistic \n\nfor (iBoot in 1:nBoot) # for each simulation\n{\n  dataBadger$ActivitySim &lt;- unlist(simulate(ft.null)) # badger activity is simulated from the distribution corresponding to the null model\n  tryCatch(\n    { # in case the glmm does not converge\n      bNull &lt;-glm(ActivitySim ~ N_setts,data=dataBadger,family=binomial(link=logit)) # fits the null model to the simulated data\n      bAlt &lt;- glmer(ActivitySim ~ N_setts+(1|farm_code),data=dataBadger,family=binomial) # fits the alternate model to the simulated data\n      lrStat[iBoot] &lt;- 2 * logLik(bAlt) - 2 * logLik(bNull) # computes the likelihood ratio statistic for the resampled data\n    },\n    warning = function(war) { # if there is a warning or an error, the likelihood ratio statistic is NA (to ensure the loop does not stop)\n      lrStat[iBoot] &lt;- NA\n    },\n    error = function(err) {\n      lrStat[iBoot] &lt;- NA\n    }\n  )\n}\n\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\nboundary (singular) fit: see help('isSingular')\n\nmean(lrStat &gt; lrObs, na.rm = TRUE) # Proportion of bootstrap likelihood ratio statistic superior to the observed statistic\n\n[1] 0\n\n# It corresponds to the p value\n\nhist(lrStat,xlim = c(0,40), col='blue', main = \"Histogram of the likelihood ratio statistic\", xlab = \"Likelihood ratio statistic\") # Histogram of the 1000 values of likelihood of the simulated model\nabline(v = lrObs, col=\"red\", lwd=3, lty=2) # Vertical red line representing the likelihood of the model including the random factor\n\n\n\n\n\n\n\n\nAll simulations lead to a likelihood ratio statistic lower than the observed statistic, which suggests that the random effect is highly significant.\n\n\n\nThe function rsq from the package rsq computes three pseudo \\(R^2\\), allowing us to separate the variance explained by the fixed effect from the variance explained by the random effect.\n\n# Estimates of deviance explained (library 'rsq')\nrsq(mod12)\n\n$model\n[1] 0.5939386\n\n$fixed\n[1] 0.2102993\n\n$random\n[1] 0.3836392\n\n\nThe model explains about 59% of the variance of the data, with 21% due to the fixed effect (the number of setts) and 38% due to the random effect (each individual farm).\n\n\n\nA GLMM does not require normality of residuals or homogeneity of variance, and the dependance in the data has already been taken into account with the random effect. However, analyzing the residuals allows us to detect an eventual trend which could indicate a problem with the modelization. Pearson residuals are used because they take into account variance heterogeneity.\n\nresid&lt;-residuals(mod12, type=\"pearson\")\n\npar(mfrow=c(1,2))\n# Plotting the residuals against the fitted data\nplot(resid~fitted(mod12)\n      , col='dodgerblue4'\n      , pch=16)\nabline(h = 0)\n\n# Plotting the residuals against the number of setts\nplot(resid~ dataBadger$N_setts, \n         pch=16,\n         col=\"dodgerblue4\",\n         ylab = \"Residuals\",\n         xlab = \"Number of Setts\",\n         main = \"\")\nabline(h = 0)\n\n\n\n\n\n\n\n\nIn a binomial GLMM, residuals are often difficult to interpret. No defined trend can be identified here.\n\n\n\nWe can check if the model is able to accurately predict the presence / absence of activity signs based on the number of setts.\n\nset.seed(9)\nN    &lt;- nrow(dataBadger) # number of observations in the dataset\nPi   &lt;- fitted(mod12) # predicted probabilities that activity = 1\ndataBadger$Ysim &lt;- rbinom(N, size = 1, Pi) # generates a binary outcome for badger activity, drawn from a binomial distribution with Pi as a success probability\n\n# Confusion matrix\nZ &lt;- table(dataBadger$Activity, dataBadger$Ysim) / N\nrownames(Z) &lt;- c(\"Observed 0\", \"Observed 1\")\ncolnames(Z) &lt;- c(\"Predicted 0\", \"Predicted 1\")\nZ\n\n            \n             Predicted 0 Predicted 1\n  Observed 0  0.77338129  0.06474820\n  Observed 1  0.07553957  0.08633094\n\n# Accuracy = proportion of correctly classified observations\nsum(diag(Z))\n\n[1] 0.8597122\n\n# To get an average confusion matrix over mutliple predictions, we can repeat for 1000 simulations\nNSim &lt;- 1000                           \ndiagZ &lt;- numeric(NSim) # we store one accuracy value per simulation\nfor (i in 1:NSim) { # for each simulation\n  Ysim &lt;- rbinom(N, size = 1, Pi) # a new simulated response is generated\n  Z&lt;- table(dataBadger$Activity, Ysim) / N # creates the confusion matrix for this simulation\n  diagZ[i]&lt;-sum(diag(Z)) # computes and stores the accuracy\n  }\n# Boxplot of the accuracy and average accuracy\nboxplot(diagZ, col='dodgerblue4',ylab='#Rate of farms well-classified')\n\n\n\n\n\n\n\nmean(diagZ)\n\n[1] 0.8821763\n\n\nEach cell of the confusion matrix represents a proportion of the total observations.\n\nThe true negative rate is 77%: it corresponds to farms without badger activity where no activity was predicted\nThe false positive rate is 6.5%: it corresponds to farms without badger activity where activity was incorrectly predicted\nThe true positive rate is 8.6%: it corresponds to farms with badger activity where activity was predicted\nThe false negative rate is 7.6%: it corresponds to farms with badger activity where no activity was predicted\n\nFor this prediction, the overall accuracy was 0.86, which means that 86% of predictions were correct. The average accuracy over 1000 simulations is 0.88."
  },
  {
    "objectID": "r_chapter.html",
    "href": "r_chapter.html",
    "title": "Basic overview of Markdown potentials with R and Quarto",
    "section": "",
    "text": "This chapter is a simple example using R\nYou can import R package using the code\n\nlibrary(tidyverse)\n\n‚îÄ‚îÄ Attaching core tidyverse packages ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ tidyverse 2.0.0 ‚îÄ‚îÄ\n‚úî dplyr     1.1.4     ‚úî readr     2.1.5\n‚úî forcats   1.0.0     ‚úî stringr   1.5.2\n‚úî ggplot2   4.0.0     ‚úî tibble    3.3.0\n‚úî lubridate 1.9.4     ‚úî tidyr     1.3.1\n‚úî purrr     1.1.0     \n‚îÄ‚îÄ Conflicts ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ tidyverse_conflicts() ‚îÄ‚îÄ\n‚úñ dplyr::filter() masks stats::filter()\n‚úñ dplyr::lag()    masks stats::lag()\n‚Ñπ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\nand then describe the purpose of your chapter as well as executing R command.\nYou can also add images\n![Gentoo penguins](images/6123849122_b66af201ea_c.jpg}\nFor example a basic summary of a dataset is given by\n\ndf &lt;- read.table(\"https://gist.githubusercontent.com/slopp/ce3b90b9168f2f921784de84fa445651/raw/4ecf3041f0ed4913e7c230758733948bc561f434/penguins.csv\", sep = \",\" , header = TRUE)\n\nand produce a graph\n\ndf %&gt;% ggplot() +\n    aes(x=species, y = body_mass_g) +\n    geom_boxplot()  \n\nWarning: Removed 2 rows containing non-finite outside the scale range\n(`stat_boxplot()`).\n\n\n\n\n\n\n\n\n\nJust for curiosity, you could add an image of Gentoo penguins\nYou can also add images\n\n\n\n\n\n\nFigure¬†1: Gentoo penguins\n\n\n\nYou can refer to one image using cross-reference. For example, Figure¬†1 is a photo of a gentoo penguin with chicks by Liam Quinn.\nYou can also add reference associated with models. For example, if you want to study how the body mass differ between species you should use a one way analysis of variance as described in Equation¬†1\n\\[Y_{sk} = \\mu + \\alpha_s + E_{sk},\n\\tag{1}\\]\nwhere \\(s\\) standes for species and \\(k\\) denotes each individual.\nA useful citation about reproducible reserach Alston and Rick (2021)\n\n\n\n\nReferences\n\nAlston, Jesse M, and Jessica A Rick. 2021. ‚ÄúA Beginner‚Äôs Guide to Conducting Reproducible Research.‚Äù Bulletin of the Ecological Society of America 102 (2): 1‚Äì14."
  }
]