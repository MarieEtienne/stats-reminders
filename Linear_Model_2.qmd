---
title: "GENERALIZED LINEAR MIXED MODEL"
subtitle: "BADGER EXAMPLE"
format: html
editor: visual
bibliography: references.bib
---

# GENERAL INTRODUCTION

We present here a reminder sheet on Generalized Linear Mixed Models (GLMMs) and its specific features. Its use will be illustrated through a study applied on badgers from @Walker2009 .

Remark : the concepts covered are taken from our Master's courses and tutorials, written and taught by A. Masson and Y. Outreman.

### Generalities

General Linear Models are used to describe the relationship between a continuous response $Y$ and one or more explanatory variables $X_{1}$,$X_{2}$...$X_{p}$. They rely on three main assumptions : *independence of residuals*, *normality of residuals* and *homogeneity of variances*. However, in many cases, the response variable $Y$ is **discrete** (for example, counts or binary outcomes).

For discrete responses, the variance of $Y$ typically depends on its mean-variance relationship. As a result, the variance is not constant across observations, invalidating the assumption of homogeneity required by linear models. Moreover, fitting a General Linear Model to count data can lead to negative predicted values and non-normal residuals. In shorts, General Linear Models are not well-suited for discrete responses. Hence, we need specific tools to analyse discrete response data. These are **Generalized Linear Models (GLMs)**.

### Structure of a Generalized Linear Model

A GLM extends the classical linear model through three steps :

1.  Assumption of the distribution of the response variable $Y_{i}$

2.  The specification of the systematic part; this is the linear function of the explanatory variables (the linear predictor called $\eta$)

3.  The relationship between the mean value of $Y_{i}$ and the systematic part. This is also called the link between the mean and the systematic part: **the link function noted** $g$ .

A Generalized Linear Model can be written as : $$g(\mu_{y})= \alpha+ \beta_{1}.X{i1}+ \beta_{2}.X{i2}+\beta_{3}.X{i3}+...\beta_{p}.X{ip} = \eta $$

The linear predictor $\eta$, emerges from the linear model as a sum of the terms for each of the $p$ parameters. This is not a value of $Y$. The value of $\eta$ is obtained by transforming the value of $Y$ by the link function, and the predicted value of $Y$ is obtained by applying the inverse link function to $\eta$.

### From GLM to GLMM

Depending on the sampling design or the experimental set-up, independence of residuals is often not respected : some statistical units are related. To account for this dependence structure, we can include **random effects** in the model.

The resulting model, called Generalized Linear Mixed Model (GLMM) extends the GLM by adding these random effects alongside the fixed effects. Therefore, GLMMs allow us to model both the relationship between predictors and responses and the non-independence among observations.

[![Badger picture from Scottish SPCA](images/Badger-wild-sett-2.jpg){fig-align="center"}](https://www.scottishspca.org/advice/badger/badger-sett/)

## Data presentation

The data used come from @Walker2009a and consist of signs of badger (*Meles meles*) activity around farms located in the southwest of England, where badger density is high. This study was carried out in the context of bovine tuberculosis and its possible transmission to cattle through badgers. Reducing the number of farm visits by badgers — especially in places where they might come into contact with livestock — could help limit the spread of the disease. Thus, the aim of this study is to predict the occurrence of badger activity signs on farms.

Between autumn 2003 and summer 2005, a survey was conducted on 36 different farms; the data are therefore longitudinal, since each farm was monitored over eight consecutive seasons. Within the same farm, observations may be temporally autocorrelated.

The response variable (presence or absence of signs of badger activity) is binary: it takes the value 1 when signs of activity were detected, and 0 otherwise. Signs of activity include the presence of feces, setts, or feeding traces.

The data are available in the file `BadgersFarmSurveysNoNA.txt`. The variables are:

-   `Year` : studied year
-   `Season` : 1 = spring, 2 = summer, 3 = autumn, 4 = winter
-   `farm_code_numeric` : farm identifier
-   `Survey` : survey identifier (time indicator)
-   `Signs_in_yard` : binary indicator of badger activity (response variable)
-   `No_setts_in_fields` : number of setts
-   `No_active_setts_in_fields` : number of actively occupied setts
-   `No_buildings` : number of buildings in the farm
-   `No_cattle_in_buildings_yard` : number of cattle in building yards
-   `Accessible_feed_store_present` : presence / absence of an accessible feed store
-   `Accessible_cattle_house_present` : presence / absence of a direct access to the cattle house
-   `Accessible_feed_present` : presence / absence of accessible feed in the farm
-   `Grass_silage` : presence / absence of grass silage
-   `Cereal_silage` : presence / absence of cereal silage
-   `HayStraw` : presence / absence of hay and / or straw
-   `Cereal_grains` : presence / absence of cereal grains
-   `Concentrates` : presence / absence of concentrates
-   `Proteinblocks` : presence / absence of protein blocks
-   `Sugarbeet` : presence / absence of sugar beet
-   `Vegetables` : presence / absence of vegetables
-   `Molasses` : presence / absence of molasses :::

## DATASET IMPORT

```{r}
# library import
library(corrplot)
library(lme4)
library(rsq)
```

```{r global data, include=TRUE,echo=TRUE}
# Dataset import
dataBadger <- read.table("Badger.txt", dec=".", header = TRUE)

# Reduce name and change categorical variables as factor
dataBadger$Activity<- dataBadger$signs_in_yard
dataBadger$N_setts<-dataBadger$N_setts_in_fields
dataBadger$N_cattle<-dataBadger$N_cattle_in_buildings_yard
dataBadger$season<-as.factor(dataBadger$season)
dataBadger$feed_store<-as.factor(dataBadger$accessible_feed_store_present)
dataBadger$cattle_house<-as.factor(dataBadger$accessible_cattle_house_present)
dataBadger$feed<-as.factor(dataBadger$accessible_feed_present)
dataBadger$grass<-as.factor(dataBadger$grass_silage)
dataBadger$cereal<-as.factor(dataBadger$cereal_silage)
dataBadger$straw<-as.factor(dataBadger$hay_straw)
dataBadger$grains<-as.factor(dataBadger$cereal_grains)
dataBadger$concen<-as.factor(dataBadger$concentrates)
dataBadger$sugar<-as.factor(dataBadger$sugar_beet)
dataBadger$molasses<-as.factor(dataBadger$molasses)

# Check for presence of missing values
colSums(is.na(dataBadger))
# There is no missing value.
```

## **DATA EXPLORATION**

Before carrying out any statistical modeling, it is essential to perform a thorough **data exploration**. This step helps identify potential issues such as outliers, collinearity, or imbalanced distributions that could bias the results or invalidate model assumptions.

Below is a checklist of preliminary exploratory analyses to perform before modeling:

1.  **Check for outliers and distribution of the dependent variable (\$Y\$).**

2.  **Check for outliers and distribution of the explicative variable (\$X\$). If \$X\$ is quantitative:** assess the distribution and presence of outliers. **If \$X\$ is qualitative:** analyze the number of levels and the number of observations per level.

3.  **Explore the potential relationships between \$Y\$ and each \$X_i\$.**

4.  **Check for potential interactions between explanatory variables (\$X_i\$).**

5.  **Assess multicollinearity among the \$X_i\$ variables.**

### **1. Outliers and Distribution in \$Y\$**

Since \$Y\$ is a binary variable, it does not have a continuous distribution. Instead, we inspect the frequency of each category (0 and 1) to check for imbalance in the response variable.

```{r dataY, include=TRUE}
# Number of 0 and 1 in Y
table(dataBadger$Activity)
```

### **2. Outliers and Distributions of Quantitative Predictors (\$X\$)**

For continuous independent variables, it is important to:

-   Detect potential **outliers** (e.g., extreme or erroneous values)

-   Visualize the **shape of the distribution** (e.g., normal, skewed, multimodal)

-   Assess whether **transformations** (e.g., log, square root) might be needed before modeling

The following visualizations help achieve this:

-   **Cleveland dot plots**: to identify potential outliers

-   **Histograms**: to visualize the overall distribution

-   **Q-Q plots**: to assess normality assumptions

```{r dataCov, include=TRUE, fig.height=8, fig.width=8}
par(mfrow=c(3,3))

# Number of badger setts on farm
# Cleveland plot
dotchart(dataBadger$N_setts,pch=16,col='blue',xlab='Number of setts')
# Histogram
hist(dataBadger$N_setts,col='blue',xlab="Number of setts",main="")
# Quantile-Quantile plot
qqnorm(dataBadger$N_setts,pch=16,col='blue',xlab='')
qqline(dataBadger$N_setts,col='red')

# Number of buildings on farm
# Cleveland plot
dotchart(dataBadger$N_buildings,pch=16,col='blue',xlab='Number of buildings')
# Histogram
hist(dataBadger$N_buildings,col='blue',xlab="Number of buildings",main="")
# Quantile-Quantile plot
qqnorm(dataBadger$N_buildings,pch=16,col='blue',xlab='')
qqline(dataBadger$N_buildings,col='red')

# Number of cattle housed in buildings on farm
# Cleveland plot
dotchart(dataBadger$N_cattle,pch=16,col='blue',xlab='Number of cattle')
# Histogram
hist(dataBadger$N_cattle,col='blue',xlab="Number of cattle",main="")
# Quantile-Quantile plot
qqnorm(dataBadger$N_cattle,pch=16,col='blue',xlab='')
qqline(dataBadger$N_cattle,col='red')
```


The exploratory plots show that all three quantitative variables (number of setts, number of buildings, and number of cattle) display right-skewed distributions, with most farms having relatively low values and a few having much higher ones. No extreme or abnormal outliers are clearly visible, although some high values are present, especially for the number of cattle. The Q-Q plots confirm that none of these variables follow a normal distribution.

### **2. Categorical Variables: Number of Levels and Individuals per Level**

For categorical (factor) variables, it is important to examine the number of levels (categories) and the number of observations in each level. This helps identify potential issues such as:

-   Levels with very few observations (which may cause estimation problems in statistical models)

-   Highly unbalanced distributions between categories

-   Unexpected or erroneous category labels

The following code summarizes the distribution of individuals across levels for each categorical predictor:

```{r datafact, include=TRUE}
# Factor season
summary(dataBadger$season)
# Factor feed_store
summary(dataBadger$feed_store)
# Factor cattle_house 
summary(dataBadger$cattle_house )
# Factor feed
summary(dataBadger$feed)
# Factor grass
summary(dataBadger$grass)
# Factor cereal
summary(dataBadger$cereal)
# Factor straw
summary(dataBadger$straw)
# Factor grains
summary(dataBadger$grains)
# Factor concen
summary(dataBadger$concen)
# Factor sugar
summary(dataBadger$sugar)
```

The categorical variables show that most factors are **binary**, with varying levels of balance between categories. For example, variables such as feed_store, cattle_house, and feed display moderate imbalance, with one category being more frequent than the other. The season variable has four well-represented levels, each containing a similar number of observations, which ensures adequate variability for analysis. Overall, the categorical predictors appear suitable for modeling.

### **3. Analysis of the Potential Relationships Between \$Y\$ and the \$X\$s**

To gain preliminary insight into the relationships between the response variable (Activity) and the predictors, both quantitative and categorical variables were explored graphically.

Scatterplots were used to visualize how badger activity varies with continuous predictors such as the number of setts, number of buildings and number of cattle housed. These visual analyses provide a first impression of potential patterns, dependencies, or nonlinear relationships that may influence badger activity on farms.

```{r datagraph, include=TRUE, fig.height=5, fig.width=10}

par(mfrow=c(1,3))
# Number of setts
plot(dataBadger$Activity~dataBadger$N_setts,pch=16,col='blue',xlab='Number of setts',ylab='Presence of a sign of badger activity')

# Number of buildings
plot(dataBadger$Activity~dataBadger$N_buildings,pch=16,col='blue',xlab='Number of buildings',ylab='Presence of a sign of badger activity')

# Number of cattle housed in buildings
plot(dataBadger$Activity~dataBadger$N_cattle,pch=16,col='blue',xlab='Number of cattle',ylab='Presence of a sign of badger activity')

par(mfrow=c(2,5))
# Factor season
mosaicplot(dataBadger$Activity~dataBadger$season
           ,color=c('blue3','red2')
           ,main="Activity & Season")

# Factor feed store
mosaicplot(dataBadger$Activity~dataBadger$feed_store
           ,color=c('blue3','red2')
           ,main="Activity & Feed store")

# Factor cattle_house 
mosaicplot(dataBadger$Activity~dataBadger$cattle_house
           ,color=c('blue3','red2')
           ,main="Activity & cattle house")

# Factor feed
mosaicplot(dataBadger$Activity~dataBadger$feed
           ,color=c('blue3','red2')
           ,main="Activity & feed")
# Factor grass
mosaicplot(dataBadger$Activity~dataBadger$grass
           ,color=c('blue3','red2')
           ,main="Activity & Grass")
# Factor cereal
mosaicplot(dataBadger$Activity~dataBadger$cereal
           ,color=c('blue3','red2')
           ,main="Activity & Cereal")
# Factor straw
mosaicplot(dataBadger$Activity~dataBadger$straw
           ,color=c('blue3','red2')
           ,main="Activity & Straw")
# Factor grains
mosaicplot(dataBadger$Activity~dataBadger$grains
           ,color=c('blue3','red2')
           ,main="Activity & Grains")
# Factor concen
mosaicplot(dataBadger$Activity~dataBadger$concen
           ,color=c('blue3','red2')
           ,main="Activity & Concentrates")
# Factor sugar
mosaicplot(dataBadger$Activity~dataBadger$sugar
           ,color=c('blue3','red2')
           ,main="Activity & Sugar Beet")
```

These visual analyses provide an initial understanding of how badger activity may relate to farm characteristics. The scatterplots show that no clear linear relationship exists between badger activity and the number of setts, buildings, or cattle, although activity tends to occur slightly more often on farms with more setts or larger cattle numbers. The mosaic plots complement this by revealing possible associations between activity and certain categorical management factors, such as the presence of feed stores, cattle housing, or specific feeding practices.

### 4. Analysis of possible interactions between both independent variables

Here, given the large number of predictors, we will not include interactions in modelling

### **5. Check for Collinearity Between Predictors (\$X\$s)**

To avoid multicollinearity issues during modeling, the relationships among predictor variables were examined. This step includes:

1.  Evaluating **correlations between the three quantitative variables**

2.  Assessing **potential overlap between categorical factors**

3.  Exploring whether **categorical predictors influence quantitative ones** through boxplots

Given the large number of predictors, only key results are summarized below.

```{r datacolin, include=TRUE, fig.height=5, fig.width=5}

# Checking collinearity between the 3 quantitative independent variables

# We represent plot for each X continuous covariate pairs
plot(dataBadger[7:9],pch=16,col='blue')

#We calculate correlation between each pair of X covariate
M<-cor(dataBadger[7:9])
corrplot.mixed(M,upper="square",lower.col="black", tl.col="black",cl.cex = 0.8,tl.cex = 0.7,number.cex =0.8)

# Checking collinearity between  categorical independent variables
# produce all crossed tables between pairs of factors - not detailed here

# Checking collinearity between categorical and quantitative independent variables
# for each quantitative independent variable, use boxplot graphics to check whether factors influence it - not detailed here
```

The collinearity analysis indicates that the three quantitative variables are largely independent. A moderate positive correlation (r ≈ 0.52) is observed between the number of buildings and the number of cattle in the yard, suggesting a slight interdependence between these two variables. In contrast, the number of setts in fields shows almost no correlation with the others (r close to 0). Overall, no strong collinearity is detected, allowing these predictors to be retained for further modelling without major redundancy concerns.

## Generalized Linear Mixed Model (GLMM)

### Building the model

```{r fullmodel, include = TRUE}
mod<-glmer(Activity~N_setts
              + N_buildings
              + N_cattle
              + season
              + feed_store
              + cattle_house
              + feed
              + grass
              + cereal
              + straw
              + grains
              + concen
              + sugar
              + (1|farm_code)
              ,data=dataBadger
              ,family=binomial)
```

```{r backwardselection, include = TRUE, warning = FALSE}
# Backward selection procedure based on AIC
drop1(mod,test="Chi") # We remove season
mod1<-glmer(Activity~N_setts
              + N_buildings
              + N_cattle
              + feed_store
              + cattle_house
              + feed
              + grass
              + cereal
              + straw
              + grains
              + concen
              + sugar
              + (1|farm_code)
              ,data=dataBadger
              ,family=binomial)

drop1(mod1,test="Chi") # We remove concentration
mod2<-glmer(Activity~N_setts
              + N_buildings
              + N_cattle
              + feed_store
              + cattle_house
              + feed
              + grass
              + cereal
              + straw
              + grains
              + sugar
              + (1|farm_code)
              ,data=dataBadger
              ,family=binomial)

drop1(mod2,test="Chi") # We remove feed
mod3<-glmer(Activity~N_setts
              + N_buildings
              + N_cattle
              + feed_store
              + cattle_house
              + grass
              + cereal
              + straw
              + grains
              + sugar
              + (1|farm_code)
              ,data=dataBadger
              ,family=binomial)

drop1(mod3,test="Chi") # We remove grass
mod4<-glmer(Activity~N_setts
              + N_buildings
              + N_cattle
              + feed_store
              + cattle_house
              + cereal
              + straw
              + grains
              + sugar
              + (1|farm_code)
              ,data=dataBadger
              ,family=binomial)

drop1(mod4,test="Chi") # We remove cattle house
mod5<-glmer(Activity~N_setts
              + N_buildings
              + N_cattle
              + feed_store
              + cereal
              + straw
              + grains
              + sugar
              + (1|farm_code)
              ,data=dataBadger
              ,family=binomial)

drop1(mod5,test="Chi") # We remove grains
mod6<-glmer(Activity~N_setts
              + N_buildings
              + N_cattle
              + feed_store
              + cereal
              + straw
              + sugar
              + (1|farm_code)
              ,data=dataBadger
              ,family=binomial)

drop1(mod6,test="Chi") # We remove cereal
mod7<-glmer(Activity~N_setts
              + N_buildings
              + N_cattle
              + feed_store
              + straw
              + sugar
              + (1|farm_code)
              ,data=dataBadger
              ,family=binomial)

drop1(mod7,test="Chi") # We remove N_cattle
mod8<-glmer(Activity~N_setts
              + N_buildings
              + feed_store
              + straw
              + sugar
              + (1|farm_code)
              ,data=dataBadger
              ,family=binomial)

drop1(mod8,test="Chi") # We remove feed_store (same AIC as straw, but higher p value)
mod9<-glmer(Activity~N_setts
              + N_buildings
              + straw
              + sugar
              + (1|farm_code)
              ,data=dataBadger
              ,family=binomial)

drop1(mod9,test="Chi") # We remove straw
mod10<-glmer(Activity~N_setts
              + N_buildings
              + sugar
              + (1|farm_code)
              ,data=dataBadger
              ,family=binomial)

drop1(mod10,test="Chi") # We remove sugar
mod11<-glmer(Activity~N_setts
              + N_buildings
              + (1|farm_code)
              ,data=dataBadger
              ,family=binomial)

drop1(mod11,test="Chi") # We remove N_buildings
mod12<-glmer(Activity~N_setts
              + (1|farm_code)
              ,data=dataBadger
              ,family=binomial)

drop1(mod12,test="Chi") # mod12 is the best model
```

### Model coefficients

```{r coefficients, include = TRUE}
summary(mod12)
```

### Significance of the random effect

```{r boot random, echo=TRUE,fig.height=4, fig.width=4, warning=FALSE}
nBoot <- 1000
lrStat <- rep(NA, nBoot)
ft.null <-glm(Activity~N_setts,data=dataBadger,family=binomial(link=logit)) # null model
ft.alt <- glmer(Activity~N_setts+(1|farm_code),data=dataBadger,family=binomial) # alternate model
lrObs <- 2 * logLik(ft.alt) - 2 * logLik(ft.null) # observed test stat

for (iBoot in 1:nBoot)
{
  dataBadger$ActivitySim <- unlist(simulate(ft.null)) # resampled data
  tryCatch(
    { # sometimes the glmer code doesn't converge
      bNull <-glm(ActivitySim ~ N_setts,data=dataBadger,family=binomial(link=logit)) # null model
      bAlt <- glmer(ActivitySim ~ N_setts+(1|farm_code),data=dataBadger,family=binomial)# alternate model
      lrStat[iBoot] <- 2 * logLik(bAlt) - 2 * logLik(bNull) # resampled test stat
    },
    warning = function(war) {
      lrStat[iBoot] <- NA
    },
    error = function(err) {
      lrStat[iBoot] <- NA
    }
  ) # if code doesn't converge skip sim
}

mean(lrStat > lrObs) # P-value for test of the random effect

hist(lrStat,xlim = c(0,40), col='blue') # Histogram of the 1000 values of likelihood of the simulated model
abline(v = lrObs, col="red", lwd=3, lty=2) # Vertical red line representing the likelihood of the observed model including the random factor
```

### Part of the variance explained by the model

```{r devianceGLMM, include=TRUE}
# Estimates of deviance explained (library 'rsq')
rsq(mod12)
```

### Residual analysis

```{r ResidNB, include=TRUE, fig.height=4, fig.width=5}

resid<-residuals(mod12, type="pearson")

par(mfrow=c(1,2))
# residuals vs fitted
plot(resid~fitted(mod2)
      , col='dodgerblue4'
      , pch=16)
abline(h = 0)

# residuals against Number of mites
plot(resid~ dataBadger$N_setts, 
         pch=16,
         col="dodgerblue4",
         ylab = "Residuals",
         xlab = "Number of Setts",
         main = "")
abline(h = 0)
```

### Model predictions

```{r Simul, include=TRUE, fig.height=4, fig.width=4}

# We could do a simulation
N    <- nrow(dataBadger)
Pi   <- fitted(mod2)
dataBadger$Ysim <- rbinom(N, size = 1, Pi)
# Classification table
Z <- table(dataBadger$Activity, dataBadger$Ysim) / N
rownames(Z) <- c("Observed 0", "Observed 1")
colnames(Z) <- c("Predicted 0", "Predicted 1")
Z
#Correctly classified:
sum(diag(Z))

# And repeat this 1000 times, store the results and calculate an average classification table

Pi   <- fitted(mod2)
N    <- nrow(dataBadger)					
NSim <- 1000                           
diagZ<- matrix(nrow = N, ncol = NSim)
for (i in 1:NSim) {
  Ysim <- rbinom(N, size = 1, Pi)
  Z<- table(dataBadger$Activity, Ysim) / N
  diagZ[,i]<-sum(diag(Z))
  }
#Average rate of individuals well-classified by the model
boxplot(diagZ[2,], col='dodgerblue4',ylab='#Rate of farms well-classified')
mean(diagZ[2,])
```

